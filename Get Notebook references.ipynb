{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import json\n",
    "import csv\n",
    "from nested_lookup import nested_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class notebook:\n",
    "    \"\"\"Define a notebook class with URL and a list of doc references\"\"\"\n",
    "    def __init__(self, url, path):\n",
    "        self.path = path\n",
    "        self.url = url\n",
    "        self.ref_urls = []\n",
    "        self.description = \"\"\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return iter([self.url, self.ref_urls, self.description])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get URLs of all notebooks\n",
    "\n",
    "def get_urls():\n",
    "    \"\"\"Walk the sample notebook repo and get all ipynb files, then build urls for each one.\"\"\"\n",
    "    notebooks = []\n",
    "    for root, dirs, files in os.walk(\"c:\\\\github\\\\amazon-sagemaker-examples\"):\n",
    "        for file in files:\n",
    "            if file.endswith(\".ipynb\"):\n",
    "                raw_path = (os.path.join(root, file)).split(\"amazon-sagemaker-examples\")[1]\n",
    "                url = \"https://github.com/awslabs/amazon-sagemaker-examples/blob/master\" + raw_path.replace(\"\\\\\", \"/\")\n",
    "                notebooks.append(notebook(url, os.path.join(root, file)))\n",
    "    return notebooks\n",
    "                                                                                                         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_url_base = \"https://docs.aws.amazon.com/sagemaker/latest/dg/\"\n",
    "def get_refs(notebooks):\n",
    "    \"\"\"Iterate through notebooks and doc markdown to find all topics that reference a notebook.\"\"\"\n",
    "    search_path = pathlib.Path(r'c:\\github\\amazon-sagemaker-developer-guide\\doc_source')\n",
    "    for this_notebook in notebooks:\n",
    "        for file in os.scandir(path=search_path):\n",
    "            #print(file)\n",
    "            with open(search_path / file, 'r', encoding='utf-8') as f:\n",
    "                if this_notebook.url in f.read():\n",
    "                    this_notebook.ref_urls.append(ref_url_base + get_ref_url(file.name))\n",
    "                   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ref_url(filename):\n",
    "    \"\"\"Convert file names into doc urls\"\"\"\n",
    "    ref_url = (filename.rsplit( \".\", 1 )[ 0 ] + '.html' )\n",
    "    return ref_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_description(notebooks):\n",
    "    \"\"\"Get the first markdown block of the notebook\"\"\"\n",
    "    for this_notebook in notebooks:\n",
    "        with open(this_notebook.path, mode= 'r', encoding ='utf-8') as nb_json:\n",
    "            nb = json.loads(nb_json.read())\n",
    "            intro = str(nested_lookup('source', nb)[0])\n",
    "            intro_no_nl = intro.replace(\"\\\\n\", \"\")\n",
    "            intro_clean = intro_no_nl.replace(\",\", \"\")\n",
    "            print(intro_clean)\n",
    "            this_notebook.description = intro_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_csv(notebooks):\n",
    "    \"\"\"Write the collection of notebooks to a csv file\"\"\"\n",
    "    with open('notebooks.csv', mode= 'w', newline='\\n') as f:\n",
    "        writer = csv.writer(f)\n",
    "        headers = ['Notebook URL', 'Doc references', 'Description' , 'Algorithm', 'Framework']\n",
    "        writer.writerow(headers)\n",
    "        for nb in notebooks:\n",
    "            writer.writerow(list(nb))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['# AutoGluon Tabular with SageMaker' '' '[AutoGluon](https://github.com/awslabs/autogluon) automates machine learning tasks enabling you to easily achieve strong predictive performance in your applications. With just a few lines of code you can train and deploy high-accuracy deep learning models on tabular image and text data.' 'This notebook shows how to use AutoGluon-Tabular with Amazon SageMaker by creating custom containers.']\n",
      "['# Taking Full Advantage of Parallelism With Data Distribution' \"_**Using Amazon SageMaker's Managed Distributed Training with Different Data Distribution Methods**_\" '' '---' '' '---' '' '## Contents' '' '1. [Background](#Background)' '1. [Setup](#Setup)' '1. [Data](#Data)' '  1. [Scaling](#Scaling)' '1. [Train](#Train)' '  1. [Timing](#Timing)' '1. [Host](#Host)' '  1. [Evaluate](#Evaluate)' '1. [Extensions](#Extensions)' '' '' '## Background' '' 'Amazon SageMaker makes it easy to train machine learning models across a large number of machines.  This a non-trivial process but Amazon SageMaker Algorithms and pre-built MXNet and TensorFlow containers hide most of the complexity from you.  Nevertheless there are decisions on how a user structures their data which will have an implication on how the distributed training is carried out.  This notebook will walk through details on setting up your data to take full advantage of distributed processing.' '' '---' '# Setup' '' '_This notebook was created and tested on an ml.m4.xlarge notebook instance._' '' \"Let's start by specifying:\" '' '- The S3 bucket and prefix that you want to use for training and model data.  This should be within the same region as the Notebook Instance training and hosting.' '- The IAM role arn used to give training and hosting access to your data. See the documentation for how to create these.  Note if more than one role is required for notebook instances training and/or hosting please replace the boto regexp with a the appropriate full IAM role arn string(s).']\n",
      "['# Distirbuted Training of Mask-RCNN in Amazon SageMaker using EFS' '' 'This notebook is a step-by-step tutorial on distributed tranining of [Mask R-CNN](https://arxiv.org/abs/1703.06870) implemented in [TensorFlow](https://www.tensorflow.org/) framework. Mask R-CNN is also referred to as heavy weight object detection model and it is part of [MLPerf](https://www.mlperf.org/training-results-0-6/).' '' 'Concretely we will describe the steps for training [TensorPack Faster-RCNN/Mask-RCNN](https://github.com/tensorpack/tensorpack/tree/master/examples/FasterRCNN) and [AWS Samples Mask R-CNN](https://github.com/aws-samples/mask-rcnn-tensorflow) in [Amazon SageMaker](https://aws.amazon.com/sagemaker/) using [Amazon EFS](https://aws.amazon.com/efs/) file-system as data source.' '' 'The outline of steps is as follows:' '' '1. Stage COCO 2017 dataset in [Amazon S3](https://aws.amazon.com/s3/)' '2. Copy COCO 2017 dataset from S3 to Amazon EFS file-system mounted on this notebook instance' '3. Build Docker training image and push it to [Amazon ECR](https://aws.amazon.com/ecr/)' '4. Configure data input channels' '5. Configure hyper-prarameters' '6. Define training metrics' '7. Define training job and start training' '' 'Before we get started let us initialize two python variables ```aws_region``` and ```s3_bucket``` that we will use throughout the notebook:']\n",
      "['# Amazon SageMaker Experiment Trials for Distirbuted Training of Mask-RCNN' '' 'This notebook is a step-by-step tutorial on Amazon SageMaker Experiment Trials for distributed tranining of [Mask R-CNN](https://arxiv.org/abs/1703.06870) implemented in [TensorFlow](https://www.tensorflow.org/) framework. ' '' 'Concretely we will describe the steps for SagerMaker Experiment Trials for training [TensorPack Faster-RCNN/Mask-RCNN](https://github.com/tensorpack/tensorpack/tree/master/examples/FasterRCNN) and [AWS Samples Mask R-CNN](https://github.com/aws-samples/mask-rcnn-tensorflow) in [Amazon SageMaker](https://aws.amazon.com/sagemaker/) using [Amazon S3](https://aws.amazon.com/s3/) as data source.' '' 'The outline of steps is as follows:' '' '1. Stage COCO 2017 dataset in [Amazon S3](https://aws.amazon.com/s3/)' '2. Build SageMaker training image and push it to [Amazon ECR](https://aws.amazon.com/ecr/)' '3. Configure data input channels' '4. Configure hyper-prarameters' '5. Define training metrics' '6. Define training job ' '7. Define SageMaker Experiment Trials to start the training jobs' '' 'Before we get started let us initialize two python variables ```aws_region``` and ```s3_bucket``` that we will use throughout the notebook:']\n",
      "['# Distirbuted Training of Mask-RCNN in Amazon SageMaker using FSx' '' 'This notebook is a step-by-step tutorial on distributed tranining of [Mask R-CNN]( https://arxiv.org/abs/1703.06870) implemented in [TensorFlow](https://www.tensorflow.org/) framework. Mask R-CNN is also referred to as heavy weight object detection model and it is part of [MLPerf](https://www.mlperf.org/training-results-0-6/).' '' 'Concretely we will describe the steps for training [TensorPack Faster-RCNN/Mask-RCNN](https://github.com/tensorpack/tensorpack/tree/master/examples/FasterRCNN) and [AWS Samples Mask R-CNN](https://github.com/aws-samples/mask-rcnn-tensorflow) in [Amazon SageMaker](https://aws.amazon.com/sagemaker/) using [Amazon FSx for Lustre](https://aws.amazon.com/fsx/lustre/) file-system as data source.' '' 'The outline of steps is as follows:' '' '1. Stage COCO 2017 dataset in [Amazon S3](https://aws.amazon.com/s3/)' '2. Create Amazon FSx Lustre file-system and import data into the file-system from S3' '3. Build Docker training image and push it to [Amazon ECR](https://aws.amazon.com/ecr/)' '4. Configure data input channels' '5. Configure hyper-prarameters' '6. Define training metrics' '7. Define training job and start training' '' 'Before we get started let us initialize two python variables ```aws_region``` and ```s3_bucket``` that we will use throughout the notebook:']\n",
      "['# Mask-RCNN Model Inference in Amazon SageMaker' '' 'This notebook is a step-by-step tutorial on [Mask R-CNN](https://arxiv.org/abs/1703.06870) model inference using [Amazon SageMaker model deployment hosting service](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-hosting.html).' '' 'To get started we initialize an Amazon execution role and initialize a `boto3` session to find our AWS region name.']\n",
      "['# Distirbuted Training of Mask-RCNN in Amazon SageMaker using S3' '' 'This notebook is a step-by-step tutorial on distributed tranining of [Mask R-CNN](https://arxiv.org/abs/1703.06870) implemented in [TensorFlow](https://www.tensorflow.org/) framework. Mask R-CNN is also referred to as heavy weight object detection model and it is part of [MLPerf](https://www.mlperf.org/training-results-0-6/).' '' 'Concretely we will describe the steps for training [TensorPack Faster-RCNN/Mask-RCNN](https://github.com/tensorpack/tensorpack/tree/master/examples/FasterRCNN) and [AWS Samples Mask R-CNN](https://github.com/aws-samples/mask-rcnn-tensorflow) in [Amazon SageMaker](https://aws.amazon.com/sagemaker/) using [Amazon S3](https://aws.amazon.com/s3/) as data source.' '' 'The outline of steps is as follows:' '' '1. Stage COCO 2017 dataset in [Amazon S3](https://aws.amazon.com/s3/)' '2. Build SageMaker training image and push it to [Amazon ECR](https://aws.amazon.com/ecr/)' '3. Configure data input channels' '4. Configure hyper-prarameters' '5. Define training metrics' '6. Define training job and start training' '' 'Before we get started let us initialize two python variables ```aws_region``` and ```s3_bucket``` that we will use throughout the notebook:']\n",
      "['# FAIRSeq in Amazon SageMaker: Translation task - German to English - Distributed / multi machine training']\n",
      "['# Fairseq in Amazon SageMaker: Pre-trained English to French translation model' '' 'In this notebook we will show you how to serve an English to French translation model using pre-trained model provided by the [Fairseq toolkit](https://github.com/pytorch/fairseq)' '' '## Permissions' '' \"Running this notebook requires permissions in addition to the regular SageMakerFullAccess permissions. This is because it creates new repositories in Amazon ECR. The easiest way to add these permissions is simply to add the managed policy AmazonEC2ContainerRegistryFullAccess to the role that you used to start your notebook instance. There's no need to restart your notebook instance when you do this the new permissions will be available immediately.\" '' '## Download pre-trained model' '' 'Fairseq maintains their pre-trained models [here](https://github.com/pytorch/fairseq/blob/master/examples/translation/README.md). We will use the model that was pre-trained on the [WMT14 English-French](http://statmt.org/wmt14/translation-task.html#Download) dataset. As the models are archived in .bz2 format we need to convert them to .tar.gz as this is the format supported by Amazon SageMaker.' '' '### Convert archive']\n",
      "['# Fairseq in Amazon SageMaker: Translation task - German to English']\n",
      "['# Fairseq in Amazon SageMaker: Translation task - English to French']\n",
      "['# fastai: lesson 1 - Pets example with Amazon SageMaker' '' '## Pre-requisites' '' \"This notebook shows how to use the SageMaker Python SDK to run your fastai library based model in a local container before deploying to SageMaker's managed training or hosting environments.  This can speed up iterative testing and debugging while using the same familiar Python SDK interface.  Just change your estimator's `train_instance_type` to `local`. \" '' \"In order to use this feature you'll need to install docker-compose (and nvidia-docker if training with a GPU).\" '' '**Note you can only run a single local notebook at one time.**']\n",
      "['# SageMaker and AWS KMS–Managed Keys' '_**End-to-end encryption using SageMaker and KMS-Managed keys**_' '' '---' '' '## Contents' '' '1. [Background](#Background)' '1. [Setup](#Setup)' '1. [Optionally upload encrypted data files for training](#Optionally-upload-encrypted-data-files-for-training)' '1. [Training the XGBoost model](#Training-the-XGBoost-model)' '1. [Set up hosting for the model](#Set-up-hosting-for-the-model)' '1. [Validate the model for use](#Validate-the-model-for-use)' '1. [Run batch prediction using batch transform](#Run-batch-prediction-using-batch-transform)' '' '---' '## Background' '' 'AWS Key Management Service ([AWS KMS](http://docs.aws.amazon.com/AmazonS3/latest/dev/UsingKMSEncryption.html)) enables ' 'Server-side encryption to protect your data at rest. Amazon SageMaker training works with KMS encrypted data if the IAM role used for S3 access has permissions to encrypt and decrypt data with the KMS key. Further a KMS key can also be used to encrypt the model artifacts at rest using Amazon S3 server-side encryption. Additionally a KMS key can also be used to encrypt the storage volume attached to training endpoint and transform instances. In this notebook we demonstrate SageMaker encryption capabilities using KMS-managed keys. ' '' '---' '' '## Setup' '' '### Prerequisites' '' 'In order to successfully run this notebook you must first:' '' '1. Have an existing KMS key from AWS IAM console or create one ([learn more](http://docs.aws.amazon.com/kms/latest/developerguide/create-keys.html)).' '2. Allow the IAM role used for SageMaker to encrypt and decrypt data with this key from within applications and when using AWS services integrated with KMS ([learn more](http://docs.aws.amazon.com/console/kms/key-users)).' '3. Allow the IAM role for this notebook to create grants with this key ([learn more](https://docs.aws.amazon.com/sagemaker/latest/dg/api-permissions-reference.html)).' '' 'We use the `key-id` from the KMS key ARN `arn:aws:kms:region:acct-id:key/key-id`.' '' '### General Setup' \"Let's start by specifying:\" '* AWS region.' '* The IAM role arn used to give learning and hosting access to your data. See the documentation for how to specify these.' '* The KMS key arn that you want to use for encryption.' '* The S3 bucket that you want to use for training and model data.']\n",
      "['# Feature processing with Spark training with BlazingText and deploying as Inference Pipeline' '' 'Typically a Machine Learning (ML) process consists of few steps: gathering data with various ETL jobs pre-processing the data featurizing the dataset by incorporating standard techniques or prior knowledge and finally training an ML model using an algorithm.' '' 'In many cases when the trained model is used for processing real time or batch prediction requests the model receives data in a format which needs to pre-processed (e.g. featurized) before it can be passed to the algorithm. In the following notebook we will demonstrate how you can build your ML Pipeline leveraging Spark Feature Transformers and SageMaker BlazingText algorithm & after the model is trained deploy the Pipeline (Feature Transformer and BlazingText) as an Inference Pipeline behind a single Endpoint for real-time inference and for batch inferences using Amazon SageMaker Batch Transform.' '' 'In this notebook we use Amazon Glue to run serverless Spark. Though the notebook demonstrates the end-to-end flow on a small dataset the setup can be seamlessly used to scale to larger datasets.']\n",
      "['# Feature processing with Spark training with XGBoost and deploying as Inference Pipeline' '' 'Typically a Machine Learning (ML) process consists of few steps: gathering data with various ETL jobs pre-processing the data featurizing the dataset by incorporating standard techniques or prior knowledge and finally training an ML model using an algorithm.' '' 'In many cases when the trained model is used for processing real time or batch prediction requests the model receives data in a format which needs to pre-processed (e.g. featurized) before it can be passed to the algorithm. In the following notebook we will demonstrate how you can build your ML Pipeline leveraging Spark Feature Transformers and SageMaker XGBoost algorithm & after the model is trained deploy the Pipeline (Feature Transformer and XGBoost) as an Inference Pipeline behind a single Endpoint for real-time inference and for batch inferences using Amazon SageMaker Batch Transform.' '' 'In this notebook we use Amazon Glue to run serverless Spark. Though the notebook demonstrates the end-to-end flow on a small dataset the setup can be seamlessly used to scale to larger datasets.']\n",
      "['# Deploy Apache Spark pre-processing and post-processing with XGBoost for real-time prediction requests in Amazon SageMaker using Inference Pipelines' ' ' 'You deploy Inference Pipelines in Amazon SageMaker to execute a sequence of pre-processing inference and post-processing steps on real-time and batch inference requests. This makes it easy to build and deploy feature preprocessing pipelines with a suite of feature transformers available in the new SparkML and scikit-learn containers in Amazon SageMaker. You can write your data processing code once and reuse it for training and inference which provides consistency in your machine learning workflows and easier management of your models. You can deploy upto five steps in your inference pipeline and they all execute on the same instance so there is minimal latency impact. The same inference pipeline can be used for real-time and batch inferences.' ' ' 'In this example we’ll use the [Car Evaluation Data Set](https://archive.ics.uci.edu/ml/datasets/Car+Evaluation) from [UCI’s Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php). Our goal is to predict the acceptability of a specific car amongst the values of: `unacc` `acc` `good` and `vgood`. At the core it is a classification problem and we will train a machine learning model using Amazon SageMaker’s built-in XGBoost algorithm. However the dataset only contains six categorical string features - `buying` `maint` `doors` `persons` `lug_boot` and `safety` and XGBoost can only process data that is in numerical format. Therefore we will pre-process the input data using [SparkML](https://spark.apache.org/docs/1.2.2/ml-guide.html) [StringIndexer](https://spark.apache.org/docs/latest/ml-features.html#stringindexer) followed by [OneHotEncoder](https://spark.apache.org/docs/latest/ml-features.html#onehotencoderestimator) to convert it to numerical format. We will also apply a post-processing step on the prediction result using SparkML [IndexToString](https://spark.apache.org/docs/latest/ml-features.html#indextostring) to convert our inference output back to their original labels that correspond to the predicted condition of the car.' ' ' 'We’ll write our SparkML pre-processing and post-processing scripts once and apply them for processing training data using AWS Glue. Then we will serialize and capture the SparkML artifacts produced by AWS Glue to Amazon S3 using [MLeap](http://mleap-docs.combust.ml/). This is so that they can be reused during inference for real-time requests using the SparkML Serving container that Amazon SageMaker provides. Finally we will deploy the pre-processing inference and post-processing steps in an inference pipeline and will execute these steps in order for each real-time inference request.']\n",
      "['# Bring Your Own Model (k-means)' '_**Hosting a Pre-Trained Model in Amazon SageMaker Algorithm Containers**_' '' '---' '' '---' '' '## Contents' '' '1. [Background](#Background)' '1. [Setup](#Setup)' '1. [(Optional)](#Optional)' '  1. [Data](#Data)' '  1. [Train Locally](#Train Locally)' '1. [Convert](#Convert)' '1. [Host](#Host)' '  1. [Confirm](#Confirm)' '1. [Extensions](#Extensions)' '' '---' '## Background' '' 'Amazon SageMaker includes functionality to support a hosted notebook environment distributed managed training and real-time hosting.  We think it works best when all three of these services are used together but they can also be used independently.  Some use cases may only require hosting.  Maybe the model was trained prior to Amazon SageMaker existing in a different service.' '' 'This notebook shows how to use a pre-existing model with an Amazon SageMaker Algorithm container to quickly create a hosted endpoint for that model.' '' '---' '## Setup' '' '_This notebook was created and tested on an ml.m4.xlarge notebook instance._' '' \"Let's start by specifying:\" '' '- The S3 bucket and prefix that you want to use for training and model data.  This should be within the same region as the Notebook Instance training and hosting.' '- The IAM role arn used to give training and hosting access to your data. See the documentation for how to create these.  Note if more than one role is required for notebook instances training and/or hosting please replace the boto regexp with a the appropriate full IAM role arn string(s).']\n",
      "['# Amazon SageMaker Multi-Model Endpoints using your own algorithm container' 'With [Amazon SageMaker multi-model endpoints](https://docs.aws.amazon.com/sagemaker/latest/dg/multi-model-endpoints.html) customers can create an endpoint that seamlessly hosts up to thousands of models. These endpoints are well suited to use cases where any one of a large number of models which can be served from a common inference container needs to be invokable on-demand and where it is acceptable for infrequently invoked models to incur some additional latency. For applications which require consistently low inference latency a traditional endpoint is still the best choice.' '' 'At a high level Amazon SageMaker manages the loading and unloading of models for a multi-model endpoint as they are needed. When an invocation request is made for a particular model Amazon SageMaker routes the request to an instance assigned to that model downloads the model artifacts from S3 onto that instance and initiates loading of the model into the memory of the container. As soon as the loading is complete Amazon SageMaker performs the requested invocation and returns the result. If the model is already loaded in memory on the selected instance the downloading and loading steps are skipped and the invocation is performed immediately.' '' 'For the inference container to serve multiple models in a multi-model endpoint it must implement [additional APIs](https://docs.aws.amazon.com/sagemaker/latest/dg/build-multi-model-build-container.html) in order to load list get unload and invoke specific models. This notebook demonstrates how to build your own inference container that implements these APIs.' '' '---' '' '### Contents' '' '1. [Introduction to Multi Model Server (MMS)](#Introduction-to-Multi-Model-Server-(MMS))' '  1. [Handling Out Of Memory conditions](#Handling-Out-Of-Memory-conditions)' '  1. [SageMaker Inference Toolkit](#SageMaker-Inference-Toolkit)' '1. [Building and registering a container using MMS](#Building-and-registering-a-container-using-MMS)' '1. [Set up the environment](#Set-up-the-environment)' '1. [Upload model artifacts to S3](#Upload-model-artifacts-to-S3)' '1. [Create a multi-model endpoint](#Create-a-multi-model-endpoint)' '  1. [Import models into hosting](#Import-models-into-hosting)' '  1. [Create endpoint configuration](#Create-endpoint-configuration)' '  1. [Create endpoint](#Create-endpoint)' '1. [Invoke models](#Invoke-models)' '  1. [Add models to the endpoint](#Add-models-to-the-endpoint)' '  1. [Updating a model](#Updating-a-model)' '1. [(Optional) Delete the hosting resources](#(Optional)-Delete-the-hosting-resources)']\n",
      "['# Amazon SageMaker Multi-Model Endpoints using Scikit Learn' 'With [Amazon SageMaker multi-model endpoints](https://docs.aws.amazon.com/sagemaker/latest/dg/multi-model-endpoints.html) customers can create an endpoint that seamlessly hosts up to thousands of models. These endpoints are well suited to use cases where any one of a large number of models which can be served from a common inference container needs to be invokable on-demand and where it is acceptable for infrequently invoked models to incur some additional latency. For applications which require consistently low inference latency a traditional endpoint is still the best choice.' '' 'At a high level Amazon SageMaker manages the loading and unloading of models for a multi-model endpoint as they are needed. When an invocation request is made for a particular model Amazon SageMaker routes the request to an instance assigned to that model downloads the model artifacts from S3 onto that instance and initiates loading of the model into the memory of the container. As soon as the loading is complete Amazon SageMaker performs the requested invocation and returns the result. If the model is already loaded in memory on the selected instance the downloading and loading steps are skipped and the invocation is performed immediately.' '' 'To demonstrate how multi-model endpoints are created and used this notebook provides an example using a set of Scikit Learn models that each predict housing prices for a single location. This domain is used as a simple example to easily experiment with multi-model endpoints.' '' 'The Amazon SageMaker multi-model endpoint capability is designed to work across all machine learning frameworks and algorithms including those where you bring your own container.']\n",
      "['# Amazon SageMaker Multi-Model Endpoints using XGBoost' 'With [Amazon SageMaker multi-model endpoints](https://docs.aws.amazon.com/sagemaker/latest/dg/multi-model-endpoints.html) customers can create an endpoint that seamlessly hosts up to thousands of models. These endpoints are well suited to use cases where any one of a large number of models which can be served from a common inference container needs to be invokable on-demand and where it is acceptable for infrequently invoked models to incur some additional latency. For applications which require consistently low inference latency a traditional endpoint is still the best choice.' '' 'At a high level Amazon SageMaker manages the loading and unloading of models for a multi-model endpoint as they are needed. When an invocation request is made for a particular model Amazon SageMaker routes the request to an instance assigned to that model downloads the model artifacts from S3 onto that instance and initiates loading of the model into the memory of the container. As soon as the loading is complete Amazon SageMaker performs the requested invocation and returns the result. If the model is already loaded in memory on the selected instance the downloading and loading steps are skipped and the invocation is performed immediately.' '' 'To demonstrate how multi-model endpoints are created and used this notebook provides an example using a set of XGBoost models that each predict housing prices for a single location. This domain is used as a simple example to easily experiment with multi-model endpoints.' '' 'The Amazon SageMaker multi-model endpoint capability is designed to work across all machine learning frameworks and algorithms including those where you bring your own container.']\n",
      "['# Mxnet BYOM: Train locally and deploy on SageMaker.' '' '1. [Introduction](#Introduction)' '2. [Prerequisites and Preprocessing](#Prequisites-and-Preprocessing)' '    1. [Permissions and environment variables](#Permissions-and-environment-variables)' '    2. [Data Setup](#Data-setup)' '3. [Training the network locally](#Training)' '4. [Set up hosting for the model](#Set-up-hosting-for-the-model)' '    1. [Export from MXNet](#Export-the-model-from-mxnet)' '    2. [Import model into SageMaker](#Import-model-into-SageMaker)' '    3. [Create endpoint](#Create-endpoint) ' '5. [Validate the endpoint for use](#Validate-the-endpoint-for-use)' '' '' '__Note__: Compare this with the [tensorflow bring your own model example](../tensorflow_iris_byom/tensorflow_BYOM_iris.ipynb)']\n",
      "['# Converting the Parquet data format to recordIO-wrapped protobuf' '' '---' '' '---' '## Contents' '' '1. [Introduction](#Introduction)' '1. [Optional data ingestion](#Optional-data-ingestion)' '    1. [Download the data](#Download-the-data)' '    1. [Convert into Parquet format](#Convert-into-Parquet-format)' '1. [Data conversion](#Data-conversion)' '    1. [Convert to recordIO protobuf format](#Convert-to-recordIO-protobuf-format)' '    1. [Upload to S3](#Upload-to-S3)' '1. [Training the linear model](#Training-the-linear-model)' '' '' '## Introduction' \"In this notebook we illustrate how to convert a Parquet data format into the recordIO-protobuf format that many SageMaker algorithms consume. For the demonstration first we'll convert the publicly available MNIST dataset into the Parquet format. Subsequently it is converted into the recordIO-protobuf format and uploaded to S3 for consumption by the linear learner algorithm. \"]\n",
      "['# Bring Your Own Pipe-mode Algorithm' '_**Create a Docker container for training SageMaker algorithms using Pipe-mode**_' '' '---' '' '---' '' '## Contents' '' '1. [Overview](#Overview)' '1. [Preparation](#Preparation)' '  1. [Permissions](#Permissions)' '1. [Code](#Code)' '  1. [train.py](#train.py)' '  1. [Dockerfile](#Dockerfile)' '1. [Publish](#Publish)' '1. [Train](#Train)' '1. [Conclusion](#Conclusion)' '' '' '---' '## Overview' '' 'SageMaker Training supports two different mechanisms with which to transfer training data to a training algorithm: File-mode and Pipe-mode.' '' 'In File-mode training data is downloaded to an encrypted EBS volume prior to commencing training. Once downloaded the training algorithm simply trains by reading the downloaded training data files.' '' 'On the other hand in Pipe-mode the input data is transferred to the algorithm while it is training. This poses a few significant advantages over File-mode:' '' '' '*  In File-mode training startup time is proportional to size of the input data. In Pipe-mode the startup delay is constant independent of the size of the input data. This translates to much faster training startup for training jobs with large GB/PB-scale training datasets.' '* You do not need to allocate (and pay for) a large disk volume to be able to download the dataset.' '* Throughput on IO-bound Pipe-mode algorithms can be multiple times faster than on equivalent File-mode algorithms.' '' 'However these advantages come at a cost - a more complicated programming model than simply reading from files on a disk. This notebook aims to clarify what you need to do in order to use Pipe-mode in your custom training algorithm.' '' '' '---' '## Preparation' '' '_This notebook was created and tested on an ml.t2.medium notebook instance._' '' \"Let's start by specifying:\" '' '- S3 URIs `s3_training_input` and `s3_model_output` that you want to use for training input and model data respectively.  These should be within the same region as the Notebook Instance training and hosting. Since the \"algorithm\" we\\'re building here doesn\\'t really have any specific data-format feel free to point `s3_training_input` to any s3 dataset you have the bigger the dataset the better to test the raw IO throughput performance.' '- The `training_instance_type` to use for training. More powerful instance types have more CPU and bandwidth which would result in higher throughput.' '- The IAM role arn used to give training access to your data.' '' '### Permissions' '' \"Running this notebook requires permissions in addition to the normal `SageMakerFullAccess` permissions. This is because we'll be creating a new repository in Amazon ECR. The easiest way to add these permissions is simply to add the managed policy `AmazonEC2ContainerRegistryFullAccess` to the role that you used to start your notebook instance. There's no need to restart your notebook instance when you do this the new permissions will be available immediately.\"]\n",
      "['# Bring Your Own Pipe-mode Algorithm' '_**Create a Docker container for training SageMaker algorithms using Pipe-mode**_' '' '---' '' '---' '' '## Contents' '' '1. [Overview](#Overview)' '1. [Preparation](#Preparation)' '  1. [Permissions](#Permissions)' '1. [Code](#Code)' '  1. [train.py](#train.py)' '  1. [Dockerfile](#Dockerfile)' '1. [Publish](#Publish)' '1. [Train](#Train)' '1. [Conclusion](#Conclusion)' '' '' '---' '## Overview' '' 'SageMaker Training supports two different mechanisms with which to transfer training data to a training algorithm: File-mode and Pipe-mode.' '' 'In File-mode training data is downloaded to an encrypted EBS volume prior to commencing training. Once downloaded the training algorithm simply trains by reading the downloaded training data files.' '' 'On the other hand in Pipe-mode the input data is transferred to the algorithm while it is training. This poses a few significant advantages over File-mode:' '' '' '*  In File-mode training startup time is proportional to size of the input data. In Pipe-mode the startup delay is constant independent of the size of the input data. This translates to much faster training startup for training jobs with large GB/PB-scale training datasets.' '* You do not need to allocate (and pay for) a large disk volume to be able to download the dataset.' '* Throughput on IO-bound Pipe-mode algorithms can be multiple times faster than on equivalent File-mode algorithms.' '' 'However these advantages come at a cost - a more complicated programming model than simply reading from files on a disk. This notebook aims to clarify what you need to do in order to use Pipe-mode in your custom training algorithm.' '' '' '---' '## Preparation' '' '_This notebook was created and tested on an ml.t2.medium notebook instance._' '' \"Let's start by specifying:\" '' '- S3 URIs `s3_training_input` and `s3_model_output` that you want to use for training input and model data respectively.  These should be within the same region as the Notebook Instance training and hosting. Since the \"algorithm\" we\\'re building here doesn\\'t really have any specific data-format feel free to point `s3_training_input` to any s3 dataset you have the bigger the dataset the better to test the raw IO throughput performance.' '- The `training_instance_type` to use for training. More powerful instance types have more CPU and bandwidth which would result in higher throughput.' '- The IAM role arn used to give training access to your data.' '' '### Permissions' '' \"Running this notebook requires permissions in addition to the normal `SageMakerFullAccess` permissions. This is because we'll be creating a new repository in Amazon ECR. The easiest way to add these permissions is simply to add the managed policy `AmazonEC2ContainerRegistryFullAccess` to the role that you used to start your notebook instance. There's no need to restart your notebook instance when you do this the new permissions will be available immediately.\"]\n",
      "['# Extending our PyTorch containers' '' 'With Amazon SageMaker you can package your own algorithms that can then be trained and deployed in the SageMaker environment. This notebook guides you through an example on how to extend one of our existing and predefined SageMaker deep learning framework containers.' '' 'By packaging an algorithm in a container you can bring almost any code to the Amazon SageMaker environment regardless of programming language environment framework or dependencies. ' '' '1. [Extending our PyTorch containers](#Extending-our-pytorch-containers)' '  1. [When should I extend a SageMaker container?](#When-should-I-extend-a-SageMaker-container?)' '  1. [Permissions](#Permissions)' '  1. [The example](#The-example)' '  1. [The presentation](#The-presentation)' '1. [Part 1: Packaging and Uploading your Algorithm for use with Amazon SageMaker](#Part-1:-Packaging-and-Uploading-your-Algorithm-for-use-with-Amazon-SageMaker)' '    1. [An overview of Docker](#An-overview-of-Docker)' '    1. [How Amazon SageMaker runs your Docker container](#How-Amazon-SageMaker-runs-your-Docker-container)' '      1. [Running your container during training](#Running-your-container-during-training)' '        1. [The input](#The-input)' '        1. [The output](#The-output)' '      1. [Running your container during hosting](#Running-your-container-during-hosting)' '    1. [The parts of the sample container](#The-parts-of-the-sample-container)' '    1. [The Dockerfile](#The-Dockerfile)' '    1. [Building and registering the container](#Building-and-registering-the-container)' '  1. [Testing your algorithm on your local machine](#Testing-your-algorithm-on-your-local-machine)' '  1. [Download the CIFAR-10 dataset](#Download-the-CIFAR-10-dataset)' '  1. [SageMaker Python SDK Local Training](#SageMaker-Python-SDK-Local-Training)' '  1. [Fit Deploy Predict](#Fit-Deploy-Predict)' '  1. [Making predictions using Python SDK](#Making-predictions-using-Python-SDK)' '1. [Part 2: Training and Hosting your Algorithm in Amazon SageMaker](#Part-2:-Training-and-Hosting-your-Algorithm-in-Amazon-SageMaker)' '  1. [Set up the environment](#Set-up-the-environment)' '  1. [Create the session](#Create-the-session)' '  1. [Upload the data for training](#Upload-the-data-for-training)' '  1. [Training On SageMaker](#Training-on-SageMaker)' '  1. [Optional cleanup](#Optional-cleanup)  ' '1. [Reference](#Reference)' '' \"_or_ I'm impatient just [let me see the code](#The-Dockerfile)!\" '' '## When should I extend a SageMaker container?' '' 'You may not need to create a container to bring your own code to Amazon SageMaker. When you are using a framework such as [TensorFlow](https://github.com/aws/sagemaker-tensorflow-container) [MXNet](https://github.com/aws/sagemaker-mxnet-container) [PyTorch](https://github.com/aws/sagemaker-pytorch-container) or [Chainer](https://github.com/aws/sagemaker-chainer-container) that has direct support in SageMaker you can simply supply the Python code that implements your algorithm using the SDK entry points for that framework.' '' 'Even if there is direct SDK support for your environment or framework you may want to add additional functionality or configure your container environment differently while utilizing our container to use on SageMaker.' '' '**Some of the reasons to extend a SageMaker deep learning framework container are:**' \"1. Install additional dependencies. (E.g. I want to install a specific Python library that the current SageMaker containers don't install.)\" '2. Configure your environment. (E.g. I want to add an environment variable to my container.)' '' '**Although it is possible to extend any of our framework containers as a parent image the example this notebook covers is currently only intended to work with our PyTorch (0.4.0+) and Chainer (4.1.0+) containers.**' '' 'This walkthrough shows that it is quite straightforward to extend one of our containers to build your own custom container for PyTorch or Chainer.' '' '## Permissions' '' \"Running this notebook requires permissions in addition to the normal `SageMakerFullAccess` permissions. This is because it creates new repositories in Amazon ECR. The easiest way to add these permissions is simply to add the managed policy `AmazonEC2ContainerRegistryFullAccess` to the role that you used to start your notebook instance. There's no need to restart your notebook instance when you do this the new permissions will be available immediately.\" '' '## The example' '' 'In this example we show how to package a PyTorch container extending the SageMaker PyTorch container with a Python example which works with the CIFAR-10 dataset. By extending the SageMaker PyTorch container we can utilize the existing training and hosting solution made to work on SageMaker. By comparison if one were to build their own custom framework container from scratch they would need to implement a training and hosting solution in order to use SageMaker. Here is an example showing [how to create a SageMaker TensorFlow container from scratch](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/advanced_functionality/tensorflow_bring_your_own/tensorflow_bring_your_own.ipynb).' '' 'In this example we use a single image to support training and hosting. This simplifies the procedure because we only need to manage one image for both tasks. Sometimes you may want separate images for training and hosting because they have different requirements. In this case separate the parts discussed below into separate Dockerfiles and build two images. Choosing whether to use a single image or two images is a matter of what is most convenient for you to develop and manage.' '' \"If you're only using Amazon SageMaker for training or hosting but not both only the functionality used needs to be built into your container.\" '' '[CIFAR-10]: http://www.cs.toronto.edu/~kriz/cifar.html' '' '## The presentation' '' 'This presentation is divided into two parts: _building_ the container and _using_ the container.']\n",
      "['# Bring Your Own R Algorithm' '_**Create a Docker container for training R algorithms and hosting R models**_' '' '---' '' '---' '' '## Contents' '' '1. [Background](#Background)' '1. [Preparation](#Preparation)' '1. [Code](#Code)' '  1. [Fit](#Fit)' '  1. [Serve](#Serve)' '  1. [Dockerfile](#Dockerfile)' '  1. [Publish](#Publish)' '1. [Data](#Data)' '1. [Train](#Train)' '1. [Host](#Host)' '1. [Predict](#Predict)' '1. [Extensions](#Extensions)' '' '---' '## Background' '' \"R is a popular open source statistical programming language with a lengthy history in Data Science and Machine Learning.  The breadth of algorithms available as an R package is impressive which fuels a growing community of users.  The R kernel can be installed into Amazon SageMaker Notebooks and Docker containers which use R can be used to take advantage of Amazon SageMaker's flexible training and hosting functionality.  This notebook illustrates a simple use case for creating an R container and then using it to train and host a model.  In order to take advantage of boto we'll use Python within the notebook but this could be done 100% in R by invoking command line arguments.\" '' '---' '## Preparation' '' '_This notebook was created and tested on an ml.m4.xlarge notebook instance._' '' \"Let's start by specifying:\" '' '- The S3 bucket and prefix that you want to use for training and model data.  This should be within the same region as the Notebook Instance training and hosting.' '- The IAM role arn used to give training and hosting access to your data. See the documentation for how to create these.  Note if more than one role is required for notebook instances training and/or hosting please replace the boto regexp with a the appropriate full IAM role arn string(s).']\n",
      "['# Example R Notebook' '' 'A simple R example in the Notebook to test the installation of the R kernel functioned properly.']\n",
      "['<h1>Using R with Amazon SageMaker</h1>' '' 'This sample Notebook describes how to train deploy and retrieve predictions from a machine learning (ML) model using [Amazon SageMaker](https://aws.amazon.com/sagemaker/) and [R](https://www.r-project.org/). The model predicts abalone age as measured by the number of rings in the shell. The [reticulate](https://rstudio.github.io/reticulate/) package will be used as an R interface to [Amazon SageMaker Python SDK](https://sagemaker.readthedocs.io/en/latest/index.html) to make API calls to Amazon SageMaker. The `reticulate` package translates between R and Python objects and Amazon SageMaker provides a serverless data science environment to train and deploy ML models at scale.']\n",
      "['# Building your own algorithm container' '' 'With Amazon SageMaker you can package your own algorithms that can than be trained and deployed in the SageMaker environment. This notebook will guide you through an example that shows you how to build a Docker container for SageMaker and use it for training and inference.' '' 'By packaging an algorithm in a container you can bring almost any code to the Amazon SageMaker environment regardless of programming language environment framework or dependencies. ' '' '_**Note:**_ SageMaker now includes a [pre-built scikit container](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/sagemaker-python-sdk/scikit_learn_iris/Scikit-learn%20Estimator%20Example%20With%20Batch%20Transform.ipynb).  We recommend the pre-built container be used for almost all cases requiring a scikit algorithm.  However this example remains relevant as an outline for bringing in other libraries to SageMaker as your own container.' '' '1. [Building your own algorithm container](#Building-your-own-algorithm-container)' '  1. [When should I build my own algorithm container?](#When-should-I-build-my-own-algorithm-container%3F)' '  1. [Permissions](#Permissions)' '  1. [The example](#The-example)' '  1. [The presentation](#The-presentation)' '1. [Part 1: Packaging and Uploading your Algorithm for use with Amazon SageMaker](#Part-1%3A-Packaging-and-Uploading-your-Algorithm-for-use-with-Amazon-SageMaker)' '    1. [An overview of Docker](#An-overview-of-Docker)' '    1. [How Amazon SageMaker runs your Docker container](#How-Amazon-SageMaker-runs-your-Docker-container)' '      1. [Running your container during training](#Running-your-container-during-training)' '        1. [The input](#The-input)' '        1. [The output](#The-output)' '      1. [Running your container during hosting](#Running-your-container-during-hosting)' '    1. [The parts of the sample container](#The-parts-of-the-sample-container)' '    1. [The Dockerfile](#The-Dockerfile)' '    1. [Building and registering the container](#Building-and-registering-the-container)' '  1. [Testing your algorithm on your local machine or on an Amazon SageMaker notebook instance](#Testing-your-algorithm-on-your-local-machine-or-on-an-Amazon-SageMaker-notebook-instance)' '1. [Part 2: Using your Algorithm in Amazon SageMaker](#Part-2%3A-Using-your-Algorithm-in-Amazon-SageMaker)' '  1. [Set up the environment](#Set-up-the-environment)' '  1. [Create the session](#Create-the-session)' '  1. [Upload the data for training](#Upload-the-data-for-training)' '  1. [Create an estimator and fit the model](#Create-an-estimator-and-fit-the-model)' '  1. [Hosting your model](#Hosting-your-model)' '    1. [Deploy the model](#Deploy-the-model)' '    2. [Choose some data and use it for a prediction](#Choose-some-data-and-use-it-for-a-prediction)' '    3. [Optional cleanup](#Optional-cleanup)' '  1. [Run Batch Transform Job](#Run-Batch-Transform-Job)' '    1. [Create a Transform Job](#Create-a-Transform-Job)' '    2. [View Output](#View-Output)' '' \"_or_ I'm impatient just [let me see the code](#The-Dockerfile)!\" '' '## When should I build my own algorithm container?' '' 'You may not need to create a container to bring your own code to Amazon SageMaker. When you are using a framework (such as Apache MXNet or TensorFlow) that has direct support in SageMaker you can simply supply the Python code that implements your algorithm using the SDK entry points for that framework. This set of frameworks is continually expanding so we recommend that you check the current list if your algorithm is written in a common machine learning environment.' '' 'Even if there is direct SDK support for your environment or framework you may find it more effective to build your own container. If the code that implements your algorithm is quite complex on its own or you need special additions to the framework building your own container may be the right choice.' '' \"If there isn't direct SDK support for your environment don't worry. You'll see in this walk-through that building your own container is quite straightforward.\" '' '## Permissions' '' \"Running this notebook requires permissions in addition to the normal `SageMakerFullAccess` permissions. This is because we'll creating new repositories in Amazon ECR. The easiest way to add these permissions is simply to add the managed policy `AmazonEC2ContainerRegistryFullAccess` to the role that you used to start your notebook instance. There's no need to restart your notebook instance when you do this the new permissions will be available immediately.\" '' '## The example' '' \"Here we'll show how to package a simple Python example which showcases the [decision tree][] algorithm from the widely used [scikit-learn][] machine learning package. The example is purposefully fairly trivial since the point is to show the surrounding structure that you'll want to add to your own code so you can train and host it in Amazon SageMaker.\" '' \"The ideas shown here will work in any language or environment. You'll need to choose the right tools for your environment to serve HTTP requests for inference but good HTTP environments are available in every language these days.\" '' \"In this example we use a single image to support training and hosting. This is easy because it means that we only need to manage one image and we can set it up to do everything. Sometimes you'll want separate images for training and hosting because they have different requirements. Just separate the parts discussed below into separate Dockerfiles and build two images. Choosing whether to have a single image or two images is really a matter of which is more convenient for you to develop and manage.\" '' \"If you're only using Amazon SageMaker for training or hosting but not both there is no need to build the unused functionality into your container.\" '' '[scikit-learn]: http://scikit-learn.org/stable/' '[decision tree]: http://scikit-learn.org/stable/modules/tree.html' '' '## The presentation' '' 'This presentation is divided into two parts: _building_ the container and _using_ the container.']\n",
      "['# Managing ML Experimentation using Amazon SageMaker Search' '_**Organize track and evaluate model training runs**_' '' '1. [Introduction](#Introduction)' '2. [Prerequisites and Preprocessing](#Prequisites-and-Preprocessing)' '  1. [Permissions and environment variables](#Permissions-and-environment-variables)' '  2. [Data ingestion](#Data-ingestion)' '  3. [Data inspection](#Data-inspection)' '  4. [Data conversion](#Data-conversion)' '3. [Training the linear model](#Training-the-linear-model)' '  1. [Conduct first model training experiment](#Conduct-first-model-training-experiment)' '  2. [Conduct second model training experiment](#Conduct-second-model-training-experiment)' '  3. [Conduct third model training experiment](#Conduct-third-model-training-experiment)' '4. [Use Amazon SageMaker Search to organize and evaluate experiments](#Use-Amazon-SageMaker-Search-to-organize-and-evaluate-experiments)' '    1. [Visualize the leaderboard](#Visualize-the-leaderboard)' '5. [Set up hosting for the model](#Set-up-hosting-for-the-model)' '6. [Validate the model for use](#Validate-the-model-for-use)' '7. [Tracing the lineage of a model starting from an endpoint](#Tracing-the-lineage-of-a-model-starting-from-an-endpoint)' '    1. [Visualize the training job details](#Visualize-the-training-job-details)']\n",
      "['# Building your own TensorFlow container' '' 'With Amazon SageMaker you can package your own algorithms that can then be trained and deployed in the SageMaker environment. This notebook guides you through an example using TensorFlow that shows you how to build a Docker container for SageMaker and use it for training and inference.' '' 'By packaging an algorithm in a container you can bring almost any code to the Amazon SageMaker environment regardless of programming language environment framework or dependencies. ' '' '1. [Building your own TensorFlow container](#Building-your-own-tensorflow-container)' '  1. [When should I build my own algorithm container?](#When-should-I-build-my-own-algorithm-container?)' '  1. [Permissions](#Permissions)' '  1. [The example](#The-example)' '  1. [The presentation](#The-presentation)' '1. [Part 1: Packaging and Uploading your Algorithm for use with Amazon SageMaker](#Part-1:-Packaging-and-Uploading-your-Algorithm-for-use-with-Amazon-SageMaker)' '    1. [An overview of Docker](#An-overview-of-Docker)' '    1. [How Amazon SageMaker runs your Docker container](#How-Amazon-SageMaker-runs-your-Docker-container)' '      1. [Running your container during training](#Running-your-container-during-training)' '        1. [The input](#The-input)' '        1. [The output](#The-output)' '      1. [Running your container during hosting](#Running-your-container-during-hosting)' '    1. [The parts of the sample container](#The-parts-of-the-sample-container)' '    1. [The Dockerfile](#The-Dockerfile)' '    1. [Building and registering the container](#Building-and-registering-the-container)' '  1. [Testing your algorithm on your local machine](#Testing-your-algorithm-on-your-local-machine)' '1. [Part 2: Training and Hosting your Algorithm in Amazon SageMaker](#Part-2:-Training-and-Hosting-your-Algorithm-in-Amazon-SageMaker)' '  1. [Set up the environment](#Set-up-the-environment)' '  1. [Create the session](#Create-the-session)' '  1. [Upload the data for training](#Upload-the-data-for-training)' '  1. [Training On SageMaker](#Training-on-SageMaker)' '  1. [Optional cleanup](#Optional-cleanup)  ' '1. [Reference](#Reference)' '' \"_or_ I'm impatient just [let me see the code](#The-Dockerfile)!\" '' '## When should I build my own algorithm container?' '' 'You may not need to create a container to bring your own code to Amazon SageMaker. When you are using a framework such as Apache MXNet or TensorFlow that has direct support in SageMaker you can simply supply the Python code that implements your algorithm using the SDK entry points for that framework. This set of supported frameworks is regularly added to so you should check the current list to determine whether your algorithm is written in one of these common machine learning environments.' '' 'Even if there is direct SDK support for your environment or framework you may find it more effective to build your own container. If the code that implements your algorithm is quite complex or you need special additions to the framework building your own container may be the right choice.' '' 'Some of the reasons to build an already supported framework container are:' \"1. A specific version isn't supported.\" '2. Configure and install your dependencies and environment.' '3. Use a different training/hosting solution than provided.' '' \"This walkthrough shows that it is quite straightforward to build your own container. So you can still use SageMaker even if your use case is not covered by the deep learning containers that we've built for you.\" '' '## Permissions' '' \"Running this notebook requires permissions in addition to the normal `SageMakerFullAccess` permissions. This is because it creates new repositories in Amazon ECR. The easiest way to add these permissions is simply to add the managed policy `AmazonEC2ContainerRegistryFullAccess` to the role that you used to start your notebook instance. There's no need to restart your notebook instance when you do this the new permissions will be available immediately.\" '' '## The example' '' 'In this example we show how to package a custom TensorFlow container with a Python example which works with the CIFAR-10 dataset and uses TensorFlow Serving for inference. However different inference solutions other than TensorFlow Serving can be used by modifying the docker container.' '' 'In this example we use a single image to support training and hosting. This simplifies the procedure because we only need to manage one image for both tasks. Sometimes you may want separate images for training and hosting because they have different requirements. In this case separate the parts discussed below into separate Dockerfiles and build two images. Choosing whether to use a single image or two images is a matter of what is most convenient for you to develop and manage.' '' \"If you're only using Amazon SageMaker for training or hosting but not both only the functionality used needs to be built into your container.\" '' '[CIFAR-10]: http://www.cs.toronto.edu/~kriz/cifar.html' '' '## The presentation' '' 'This presentation is divided into two parts: _building_ the container and _using_ the container.']\n",
      "['# TensorFlow BYOM: Train locally and deploy on SageMaker.' '' '' '1. [Introduction](#Introduction)' '2. [Prerequisites and Preprocessing](#Prequisites-and-Preprocessing)' '    1. [Permissions and environment variables](#Permissions-and-environment-variables)' '    2. [Model definitions](#Model-definitions)' '    3. [Data Setup](#Data-setup)' '3. [Training the network locally](#Training)' '4. [Set up hosting for the model](#Set-up-hosting-for-the-model)' '    1. [Export from TensorFlow](#Export-the-model-from-tensorflow)' '    2. [Import model into SageMaker](#Import-model-into-SageMaker)' '    3. [Create endpoint](#Create-endpoint) ' '5. [Validate the endpoint for use](#Validate-the-endpoint-for-use)' '' '__Note__: Compare this with the [tensorflow bring your own model example](../tensorflow_iris_byom/tensorflow_BYOM_iris.ipynb)']\n",
      "['# Copying data from Redshift to S3 and back' '' '---' '' '---' '## Contents' '' '1. [Introduction](#Introduction)' '1. [Reading from Redshift](#Reading-from-Redshift)' '1. [Upload to S3](#Upload-to-S3)' '1. [Writing back to Redshift](#Writing-back-to-Redshift)' '' '' '' '## Introduction' 'In this notebook we illustrate how to copy data from Redshift to S3 and vice-versa.' '' '### Prerequisites' \"In order to successfully run this notebook you'll first need to:\" '1. Have a Redshift cluster within the same VPC.' '1. Preload that cluster with data from the [iris data set](https://archive.ics.uci.edu/ml/datasets/iris) in a table named public.irisdata.' '1. Update the credential file (`redshift_creds_template.json.nogit`) file with the appropriate information.' '' 'Also note that this Notebook instance needs to resolve to a private IP when connecting to the Redshift instance. There are two ways to resolve the Redshift DNS name to a private IP:' '1. The Redshift cluster is not publicly accessible so by default it will resolve to private IP.' '1. The Redshift cluster is publicly accessible and has an EIP associated with it but when accessed from within a VPC it should resolve to private IP of the Redshift cluster. This is possible by setting following two VPC attributes to yes: DNS resolution and DNS hostnames. For instructions on setting that up see Redshift public docs on [Managing Clusters in an Amazon Virtual Private Cloud (VPC)](https://docs.aws.amazon.com/redshift/latest/mgmt/managing-clusters-vpc.html).' '' '### Notebook Setup' \"Let's start by installing `psycopg2` a PostgreSQL database adapter for the Python adding a few imports and specifying a few configs. \"]\n",
      "['# Amazon SageMaker XGBoost Bring Your Own Model' '_**Hosting a Pre-Trained scikit-learn Model in Amazon SageMaker XGBoost Algorithm Container**_' '' '---' '' '---' '' '## Contents' '' '1. [Background](#Background)' '1. [Setup](#Setup)' '1. [Optionally train a scikit learn XGBoost model](#Optionally-train-a-scikit-learn-XGBoost-model)' '1. [Upload the pre-trained model to S3](#Upload-the-pre-trained-model-to-S3)' '1. [Set up hosting for the model](#Set-up-hosting-for-the-model)' '1. [Validate the model for use](#Validate-the-model-for-use)' '' '' '' '' '---' '## Background' '' 'Amazon SageMaker includes functionality to support a hosted notebook environment distributed serverless training and real-time hosting. We think it works best when all three of these services are used together but they can also be used independently.  Some use cases may only require hosting.  Maybe the model was trained prior to Amazon SageMaker existing in a different service.' '' 'This notebook shows how to use a pre-existing scikit-learn trained XGBoost model with the Amazon SageMaker XGBoost Algorithm container to quickly create a hosted endpoint for that model. Please note that scikit-learn XGBoost model is compatible with SageMaker XGBoost container whereas other gradient boosted tree models (such as one trained in SparkML) are not.' '' '---' '## Setup' '' \"Let's start by specifying:\" '' '* AWS region.' '* The IAM role arn used to give learning and hosting access to your data. See the documentation for how to specify these.' '* The S3 bucket that you want to use for training and model data.']\n",
      "['# Customer Churn Prediction with Amazon SageMaker Autopilot' '_**Using AutoPilot to Predict Mobile Customer Departure**_' '' '---' '' '---' '' '## Contents' '' '1. [Introduction](#Introduction)' '1. [Setup](#Setup)' '1. [Data](#Data)' '1. [Train](#Settingup)' '1. [Autopilot Results](#Results)' '1. [Host](#Host)' '1. [Cleanup](#Cleanup)' '' '' '---' '' '## Introduction' '' 'Amazon SageMaker Autopilot is an automated machine learning (commonly referred to as AutoML) solution for tabular datasets. You can use SageMaker Autopilot in different ways: on autopilot (hence the name) or with human guidance without code through SageMaker Studio or using the AWS SDKs. This notebook as a first glimpse will use the AWS SDKs to simply create and deploy a machine learning model.' '' 'Losing customers is costly for any business.  Identifying unhappy customers early on gives you a chance to offer them incentives to stay.  This notebook describes using machine learning (ML) for the automated identification of unhappy customers also known as customer churn prediction. ML models rarely give perfect predictions though so this notebook is also about how to incorporate the relative costs of prediction mistakes when determining the financial outcome of using ML.' '' 'We use an example of churn that is familiar to all of us–leaving a mobile phone operator.  Seems like I can always find fault with my provider du jour! And if my provider knows that I’m thinking of leaving it can offer timely incentives–I can always use a phone upgrade or perhaps have a new feature activated–and I might just stick around. Incentives are often much more cost effective than losing and reacquiring a customer.' '' '---' '## Setup' '' '_This notebook was created and tested on an ml.m4.xlarge notebook instance._' '' \"Let's start by specifying:\" '' '- The S3 bucket and prefix that you want to use for training and model data.  This should be within the same region as the Notebook Instance training and hosting.' '- The IAM role arn used to give training and hosting access to your data. See the documentation for how to create these.  Note if more than one role is required for notebook instances training and/or hosting please replace the boto regexp with a the appropriate full IAM role arn string(s).']\n",
      "['# Direct Marketing with Amazon SageMaker Autopilot' '---' '' '---']\n",
      "['# Building your own container as Algorithm / Model Package' '' 'With Amazon SageMaker you can package your own algorithms that can than be trained and deployed in the SageMaker environment. This notebook will guide you through an example that shows you how to build a Docker container for SageMaker and use it for training and inference.' '' 'This is an extension of the [scikit-bring-your-own notebook](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/advanced_functionality/scikit_bring_your_own/scikit_bring_your_own.ipynb). We append specific steps that help you create a new Algorithm / Model Package SageMaker entities which can be sold on AWS Marketplace' '' 'By packaging an algorithm in a container you can bring almost any code to the Amazon SageMaker environment regardless of programming language environment framework or dependencies. ' '' '1. [Building your own algorithm container](#Building-your-own-algorithm-container)' '  1. [When should I build my own algorithm container?](#When-should-I-build-my-own-algorithm-container?)' '  1. [Permissions](#Permissions)' '  1. [The example](#The-example)' '  1. [The presentation](#The-presentation)' '1. [Part 1: Packaging and Uploading your Algorithm for use with Amazon SageMaker](#Part-1:-Packaging-and-Uploading-your-Algorithm-for-use-with-Amazon-SageMaker)' '    1. [An overview of Docker](#An-overview-of-Docker)' '    1. [How Amazon SageMaker runs your Docker container](#How-Amazon-SageMaker-runs-your-Docker-container)' '      1. [Running your container during training](#Running-your-container-during-training)' '        1. [The input](#The-input)' '        1. [The output](#The-output)' '      1. [Running your container during hosting](#Running-your-container-during-hosting)' '    1. [The parts of the sample container](#The-parts-of-the-sample-container)' '    1. [The Dockerfile](#The-Dockerfile)' '    1. [Building and registering the container](#Building-and-registering-the-container)' '  1. [Testing your algorithm on your local machine or on an Amazon SageMaker notebook instance](#Testing-your-algorithm-on-your-local-machine-or-on-an-Amazon-SageMaker-notebook-instance)' '1. [Part 2: Training and Hosting your Algorithm in Amazon SageMaker](#Part-2:-Training-and-Hosting-your-Algorithm-in-Amazon-SageMaker)' '  1. [Set up the environment](#Set-up-the-environment)' '  1. [Create the session](#Create-the-session)' '  1. [Upload the data for training](#Upload-the-data-for-training)' '  1. [Create an estimator and fit the model](#Create-an-estimator-and-fit-the-model)' '  1. [Run a Batch Transform Job](#Batch-Transform-Job)' '  1. [Deploy the model](#Deploy-the-model)' '  1. [Optional cleanup](#Cleanup-Endpoint)' '1. [Part 3: Package your resources as an Amazon SageMaker Algorithm](#Part-3---Package-your-resources-as-an-Amazon-SageMaker-Algorithm)' '  1. [Algorithm Definition](#Algorithm-Definition)' '1. [Part 4: Package your resources as an Amazon SageMaker ModelPackage](#Part-4---Package-your-resources-as-an-Amazon-SageMaker-ModelPackage)' '  1. [Model Package Definition](#Model-Package-Definition)' '1. [Debugging Creation Issues](#Debugging-Creation-Issues)' '1. [List on AWS Marketplace](#List-on-AWS-Marketplace)' '' '## When should I build my own algorithm container?' '' 'You may not need to create a container to bring your own code to Amazon SageMaker. When you are using a framework (such as Apache MXNet or TensorFlow) that has direct support in SageMaker you can simply supply the Python code that implements your algorithm using the SDK entry points for that framework. This set of frameworks is continually expanding so we recommend that you check the current list if your algorithm is written in a common machine learning environment.' '' 'Even if there is direct SDK support for your environment or framework you may find it more effective to build your own container. If the code that implements your algorithm is quite complex on its own or you need special additions to the framework building your own container may be the right choice.' '' \"If there isn't direct SDK support for your environment don't worry. You'll see in this walk-through that building your own container is quite straightforward.\" '' '## Permissions' '' \"Running this notebook requires permissions in addition to the normal `SageMakerFullAccess` permissions. This is because we'll creating new repositories in Amazon ECR. The easiest way to add these permissions is simply to add the managed policy `AmazonEC2ContainerRegistryFullAccess` to the role that you used to start your notebook instance. There's no need to restart your notebook instance when you do this the new permissions will be available immediately.\" '' '## The example' '' \"Here we'll show how to package a simple Python example which showcases the [decision tree][] algorithm from the widely used [scikit-learn][] machine learning package. The example is purposefully fairly trivial since the point is to show the surrounding structure that you'll want to add to your own code so you can train and host it in Amazon SageMaker.\" '' \"The ideas shown here will work in any language or environment. You'll need to choose the right tools for your environment to serve HTTP requests for inference but good HTTP environments are available in every language these days.\" '' \"In this example we use a single image to support training and hosting. This is easy because it means that we only need to manage one image and we can set it up to do everything. Sometimes you'll want separate images for training and hosting because they have different requirements. Just separate the parts discussed below into separate Dockerfiles and build two images. Choosing whether to have a single image or two images is really a matter of which is more convenient for you to develop and manage.\" '' \"If you're only using Amazon SageMaker for training or hosting but not both there is no need to build the unused functionality into your container.\" '' '[scikit-learn]: http://scikit-learn.org/stable/' '[decision tree]: http://scikit-learn.org/stable/modules/tree.html' '' '## The presentation' '' 'This presentation is divided into two parts: _building_ the container and _using_ the container.']\n",
      "['# AWS Marketplace Product Usage Demonstration - Algorithms' '' '## Using Algorithm ARN with Amazon SageMaker APIs' '' 'This sample notebook demonstrates two new functionalities added to Amazon SageMaker:' '1. Using an Algorithm ARN to run training jobs and use that result for inference' '2. Using an AWS Marketplace product ARN - we will use [Scikit Decision Trees](https://aws.amazon.com/marketplace/pp/prodview-ha4f3kqugba3u?qid=1543169069960&sr=0-1&ref_=srh_res_product_title)' '' '## Overall flow diagram' '<img src=\"images/AlgorithmE2EFlow.jpg\">' '' '## Compatibility' 'This notebook is compatible only with [Scikit Decision Trees](https://aws.amazon.com/marketplace/pp/prodview-ha4f3kqugba3u?qid=1543169069960&sr=0-1&ref_=srh_res_product_title) sample algorithm published to AWS Marketplace. ' '' '***Pre-Requisite:*** Please subscribe to this free product before proceeding with this notebook']\n",
      "['# Goal: Train a model using AutoML functionality! ' '' 'A popular approach to solve a machine learning problem is to try multiple approaches for training a model by running multiple algorithms on a dataset. Based on initial analysis you can decide which algorithm to use for training and tuning the actual model. However each algorithm can have specific feature requirements such as data must be numeric missing values must be addressed before the training etc. Performing algorithm specific feature engineering tasks can take time. Such a project can be shortened by running an AutoML algorithm that performs feature engineering tasks such as one-hot encoding generalization addressing missing values automatically and then trains models using multiple algorithms in parallel.  ' '' 'This notebook demonstrates how to use such an AutoML algorithm offerd by [H2O.ai](https://aws.amazon.com/marketplace/seller-profile?id=55552124-d41b-4bad-90db-72d427682225) in AWS Marketplace for machine learning.  AutoML from H2O.ai trains one or more of following types of models in parallel:' '1. XGBoost GBM (Gradient Boosting Machine)' '2. GLM ' '3. default Random Forest (DRF)' '4. Extremely Randomized Forest (XRT)' '5. Deep Neural Nets' '' 'Once these models have been trained it also creates two stacked ensemble models:' '1. An ensemble model created using all the models.' '2. Best of family ensemble model created using models that performed best in each class/family.' '' \"For more information on how H2O.ai's AutoML works see [FAQ section of H2O.ai's documentation.](http://docs.h2o.ai/h2o/latest-stable/h2o-docs/automl.html#faq)\" '' '' '' '### Contents:' '* [Step 1: Subscribe to AutoML algorithm from AWS Marketplace](#Step-1:-Subscribe-to-AutoML-algorithm-from-AWS-Marketplace)' '* [Step 2: Step 2 : Set up environment](#Step-2-:-Set-up-environment)' '* [Step 3: Prepare and upload data](#Step-3:-Prepare-and-upload-data)' '* [Step 4: Train a model](#Step-4:-Train-a-model)' '* [Step 5: Deploy the model and perform a real-time inference](#Step-5:-Deploy-the-model-and-perform-a-real-time-inference)' '* [ Step 6: Clean-up](#Step-6:-Clean-up)' '' '#### Compatibility' 'This notebook is compatible only with [H2O-3 Automl Algorithm](https://aws.amazon.com/marketplace/pp/prodview-vbm2cls5zcnky) from AWS Marketplace and an AWS Marketplace subscription is required to successfully run this notebook. ' '' '' '#### Usage instructions' 'You can run this notebook one cell at a time (By using Shift+Enter for running a cell).']\n",
      "['# AWS Marketplace Product Usage Demonstration - Model Packages' '' '## Using Model Package ARN with Amazon SageMaker APIs' '' 'This sample notebook demonstrates two new functionalities added to Amazon SageMaker:' '1. Using a Model Package ARN for inference via Batch Transform jobs / Live Endpoints' '2. Using a Marketplace Model Package ARN - we will use [Scikit Decision Trees - Pretrained Model](https://aws.amazon.com/marketplace/pp/prodview-7qop4x5ahrdhe?qid=1543169069960&sr=0-2&ref_=srh_res_product_title)' '' '' '## Overall flow diagram' '<img src=\"images/ModelPackageE2EFlow.jpg\">' '' '## Compatibility' 'This notebook is compatible only with [Scikit Decision Trees - Pretrained Model](https://aws.amazon.com/marketplace/pp/prodview-7qop4x5ahrdhe?qid=1543169069960&sr=0-2&ref_=srh_res_product_title) sample model that is published to AWS Marketplace']\n",
      "['## Goal: Automate Auto Insurance Claim Processing Using Pre-trained Models ' 'Auto insurance claim process requires extracting metadata from images and performing validations to ensure that the claim is not fraudulent. This sample notebook shows how third party pre-trained machine learning models can be used to extract such metadata from images.' '' 'This notebook uses [Vehicle Damage Inspection](https://aws.amazon.com/marketplace/pp/Persistent-Systems-Vehicle-Damage-Inspection/prodview-xhj66rbazm6oe) model to identify the type of damage and [Deep Vision vehicle recognition](https://aws.amazon.com/marketplace/pp/prodview-a7wgrolhu54ts?qid=1558356141251&sr=0-4&ref_=srh_res_product_title) to identify the make model year and bounding box of the car. This notebook also shows how to use the bounding box to extract license information from the using [Amazon Rekognition](https://aws.amazon.com/rekognition/).' '' '### Pre-requisites:' 'This sample notebook requires subscription to following pre-trained machine learning model packages from AWS Marketplace:' '' '1. [Vehicle Damage Inspection](https://aws.amazon.com/marketplace/pp/Persistent-Systems-Vehicle-Damage-Inspection/prodview-xhj66rbazm6oe)' '2. [Deep Vision vehicle recognition](https://aws.amazon.com/marketplace/pp/prodview-a7wgrolhu54ts?qid=1558356141251&sr=0-4&ref_=srh_res_product_title)' '' 'If your AWS account has not been subscribed to these listings here is the process you can follow for each of the above mentioned listings:' '1. Open the listing from AWS Marketplace' '2. Read the **Highlights** section and then **product overview** section of the listing.' '3. View **usage information** and then **additional resources**.' '4. Note the supported instance types.' '5. Next click on **Continue to subscribe**.' '6. Review **End user license agreement** **support terms** as well as **pricing information**.' '7. **\"Accept Offer\"** button needs to be clicked if your organization agrees with EULA pricing information as well as support terms.' '' '**Notes**: ' '1. If **Continue to configuration** button is active it means your account already has a subscription to this listing.' '2. Once you click on **Continue to configuration** button and then choose region you will see that a **Product Arn** will appear. This is the model package ARN that you need to specify while creating a deployable model. However for this notebook the algorithm ARN has been specified in **src/model_package_arns.py** file and you do not need to specify the same explicitly.']\n",
      "['# Extracting insights from your credit card statements']\n",
      "['## Deploy and perform inference on ML Model packages from AWS Marketplace.' '' 'There are two simple ways to try/deploy [ML model packages from AWS Marketplace](https://aws.amazon.com/marketplace/search/results?page=1&filters=FulfillmentOptionType%2CSageMaker::ResourceType&FulfillmentOptionType=SageMaker&SageMaker::ResourceType=ModelPackage) either using AWS console to deploy an ML model package (see [this blog](https://aws.amazon.com/blogs/machine-learning/adding-ai-to-your-applications-with-ready-to-use-models-from-aws-marketplace/)) or via code written typically in a Jupyter notebook. Many listings have a high-quality sample Jupyter notebooks provided by the seller itself usually these sample notebooks are linked to the AWS Marketplace listing (E.g. [Source Separation](https://aws.amazon.com/marketplace/pp/prodview-23n4vi2zw67we?qid=1579739476471&sr=0-1&ref_=srh_res_product_title)) If a sample notebook exists try it out. ' '' 'If such a sample notebook does not exist and you want to deploy and try an ML model package via code written in python language this generic notebook can guide you on how to deploy and perform inference on an ML model package from AWS Marketplace.' '' '' '> **Note**:If  you are facing technical issues while trying an ML model package from AWS Marketplace and need help please open a support ticket or write to the team on aws-mp-bd-ml@amazon.com for additional assistance.' '' '#### Pre-requisites:' '1. Open this notebook from an Amazon SageMaker Notebook instance.' '1. Ensure that Amazon SageMaker notebook instance used  has  IAMExecutionRole with **AmazonSageMakerFullAccess**' '1. Your IAM role has these three permisions - **aws-marketplace:ViewSubscriptions** **aws-marketplace:Unsubscribe** **aws-marketplace:Subscribe** and you have authority to make AWS Marketplace subscriptions in the AWS account used.' '' '> **Note**: If you are viewing this notebook from a GitHub repository then to try this notebook successfully [create an Amazon SageMaker Notebook Instance](https://docs.aws.amazon.com/sagemaker/latest/dg/howitworks-create-ws.html) and then [access Notebook Instance](https://docs.aws.amazon.com/sagemaker/latest/dg/howitworks-access-ws.html) you just created. Next upload this Jupyter notebook to your notebook instance. ' '' '' '' '#### Additional Resources:' '**Background on Model Packages**:' '1. An ML model can be created from a Model Package to know how see [Use a Model Package to Create a Model](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-mkt-model-pkg-model.html). ' '2. An ML Model accepts data and generates predictions.' '3. To perform inference you first need to deploy the ML Model. An ML model typically supports two types of predictions:' '    1. [Use Batch Transform](https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform.html) to asynchronously generate predictions for multiple input data observations. ' '    2. Send input data to Amazon SageMaker endpoint to synchronously generate predictions for individual data observations. For information see [Deploy a Model on Amazon SageMaker Hosting Services](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-hosting.html)' '' '**Background on AWS Marketplace Model packages**:' 'If you are new to Model packages from AWS Marketplace here are some additional resources.' '* For a high level overview of how AWS Marketplace for Machine Learning see the [Using AWS Marketplace for machine learning workloads](https://aws.amazon.com/blogs/awsmarketplace/using-aws-marketplace-for-machine-learning-workloads/) blog post.' '* For a high level overview on Model packages from AWS Marketplace see [this blog post](https://aws.amazon.com/blogs/aws/new-machine-learning-algorithms-and-model-packages-now-available-in-aws-marketplace/).' '* For an overview on how to deploy a Model package using AWS Console and using AWS CLI for performing inference see the [Adding AI to your applications with ready-to-use models from AWS Marketplace](https://aws.amazon.com/blogs/machine-learning/adding-ai-to-your-applications-with-ready-to-use-models-from-aws-marketplace/) blog post. ' '* For a Jupyter notebook of the sample solution for **Automating auto insurance claim processing workflow** outlined in [this re:Mars session](https://www.youtube.com/watch?v=GkKZt0s_ku0) see [amazon-sagemaker-examples/aws-marketplace](https://github.com/awslabs/amazon-sagemaker-examples/tree/master/aws_marketplace/using_model_packages/auto_insurance) GitHub repository.' '* For a Jupyter notebook of the sample solution for **Improving workplace safety solution** outlined in [this re:Invent session](https://www.youtube.com/watch?v=iLOXaWpK6ag) see [amazon-sagemaker-examples/aws-marketplace](https://github.com/awslabs/amazon-sagemaker-examples/tree/master/aws_marketplace/using_model_packages/improving_industrial_workplace_safety) GitHub repository.' '' '#### Contents:' '1. [Subscribe to the model package](#Subscribe-to-the-model-package)' '   1. [Identify compatible instance-type](#A.-Identify-compatible-instance-type)' '   2. [Identify content-type](#B.-Identify-content_type)' '   3. [Specify model-package-arn](#C.-Specify-model-package-arn)' '2. [Create an Endpoint and perform real-time inference](#2.-Create-an-Endpoint-and-perform-real-time-inference)' '   1. [Create an Endpoint](#A.-Create-an-Endpoint)' '   2. [Create input payload](#B.-Create-input-payload)' '   3. [Perform Real-time inference](#C.-Perform-Real-time-inference)' '   4. [Visualize output](#D.-Visualize-output)' '   5. [Delete the endpoint](#E.-Delete-the-endpoint)' '3. [Perform Batch inference](#3.-Perform-Batch-inference) ' '   1. [Prepare input payload](#A.-Prepare-input-payload) ' '   2. [Run a batch-transform job](#B.-Run-a-batch-transform-job)' '   3. [Visualize output](#C.-Visualize-output)' '4. [Delete the model](#4.-Delete-the-model)' '5. [Unsubscribe to the model package](#Unsubscribe-to-the-model-package)' '' '#### Usage instructions' 'You can run this notebook one cell at a time (By using Shift+Enter for running a cell).']\n",
      "['## Demonstrating Industrial Workplace Safety using Pre-trained Machine Learning Models' '' '### Introduction' '' 'This sample notebook shows how to use pre-trained model packages from [AWS Marketplace](https://aws.amazon.com/marketplace/search/results?page=1&filters=FulfillmentOptionType&FulfillmentOptionType=SageMaker&ref_=mlmp_gitdemo_indust) to detect industrial workspace safety related object labels such as hard-hat personal protective equipment construction machinery and construction worker in an image. The notebook also shows an approach to perform inference on a video by taking snapshots from the video file to generate an activity/status log. At the end of this you will become familiar on steps to integrate inferences from pre-trained models into your application. This notebook is intended for demonstration we highly recommend you to evaluate the accuracy of machine learning models to see if they meet your expectations.' '' '' '### Pre-requisites:' 'This sample notebook requires you to subscribe to pre-trained machine learning model packages. Follow the following steps to subscribe to the listings:' '' '1. Open the following model package product detail pages in separate tabs in your web browser. ' '' '  1.  [Construction Worker Detection](https://aws.amazon.com/marketplace/pp/prodview-6utmzaproaqhs?qid=1563547984309&sr=0-5&ref_=mlmp_gitdemo_indust) to identify construction workers in an image. ' '' '  1. [Hard Hat Detector for Worker Safety](https://aws.amazon.com/marketplace/pp/prodview-jd5tj2egpxxum?qid=1563547984309&sr=0-2&ref_=mlmp_gitdemo_indust) model to infer if construction workers are wearing hard hats.' '' '  1. [Personal Protective Equipments](https://aws.amazon.com/marketplace/pp/prodview-2inbkii6o24k4?qid=1563547984309&sr=0-6&ref_=mlmp_gitdemo_indust) to infer if a person is wearing a high visibility safety vest. ' '' '  1. [Construction Machines Detector](https://aws.amazon.com/marketplace/pp/prodview-fuukizaiq5o7c?qid=1563549078039&sr=0-1&ref_=mlmp_gitdemo_indust) to identify construction machines in an image. ' '' '2. For each of the model packages follow these steps: ' '  1. Review the information available on the product details page including **Support Terms** .' '  1. Click on **\"Continue to Subscribe\"**. You will now see the **\"Subscribe to this software\"** page. ' '  1. Review **End User License Agreement** and **Pricing Terms**.' '  1. **\"Accept Offer\"** button needs to be clicked if your organization agrees with EULA pricing information and support terms.' ' ' '' 'Notes: ' '  1. Once you click on **Continue to configuration** button and then choose a region you will see a **Product Arn** displayed. This is the model package ARN that you need to specify while creating a deployable model using Boto3.  However for this notebook the model ARNs have been specified in **src/model_package_arns.py** file and you need not specify them explicitly. The configuration page also provides a **\"View in SageMaker\"** button to navigate to Amazon SageMaker to deploy via Amazon SageMaker Console. ' '  1. Products with **Free Trials** do not incur hourly software charges during free trial period but AWS infrastructure charges still apply. Free Trials will automatically convert to a paid hourly subscription upon expiration. We have included steps below to cancel subscription at the end of this exercise. ']\n",
      "['# Amazon SageMaker Studio Walkthrough' '_**Using Gradient Boosted Trees to Predict Mobile Customer Departure**_' '' '---' '' 'This notebook walks you through some of the main features of Amazon SageMaker Studio. ' '' '* [Amazon SageMaker Experiments](https://docs.aws.amazon.com/sagemaker/latest/dg/experiments.html)' '  * Manage multiple trials' '  * Experiment with hyperparameters and charting' '* [Amazon SageMaker Debugger](https://docs.aws.amazon.com/sagemaker/latest/dg/train-debugger.html)' '  * Debug your model ' '* [Model hosting](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-hosting.html)' '  * Set up a persistent endpoint to get predictions from your model' '* [SageMaker Model Monitor](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor.html)' '  * Monitor the quality of your model' '  * Set alerts for when model quality deviates' '  ' 'You must run this walkthrough in Amazon SageMaker Studio. For Studio onboarding and setup instructions see the [README](README.md).' '' '---' '' '## Contents' '' '1. [Background](#Background) - Predict customer churn with XGBoost' '1. [Data](#Data) - Prep the dataset and upload it to Amazon S3' '1. [Train](#Train) - Train with the Amazon SageMaker XGBoost algorithm' '  - [Amazon SageMaker Experiments](#Amazon-SageMaker-Experiments)' '  - [Amazon SageMaker Debugger](#Amazon-SageMaker-Debugger)' '1. [Host](#Host)' '1. [SageMaker Model Monitor](#SageMaker-Model-Monitor)' '' '---' '' '## Background' '' '_This notebook has been adapted from an [AWS blog post](https://aws.amazon.com/blogs/ai/predicting-customer-churn-with-amazon-machine-learning/). ' '' 'Losing customers is costly for any business.  Identifying unhappy customers early on gives you a chance to offer them incentives to stay.  This notebook describes using machine learning (ML) for automated identification of unhappy customers also known as customer churn prediction. It uses Amazon SageMaker features for managing experiments training and debugging the model and monitoring it after it has been deployed. ' '' \"Import the Python libraries we'll need for this walkthrough.\"]\n",
      "['## MNIST Handwritten Digits Classification Experiment' '' 'This demo shows how you can use SageMaker Experiment Management Python SDK to organize track compare and evaluate your machine learning (ML) model training experiments.' '' 'You can track artifacts for experiments including data sets algorithms hyper-parameters and metrics. Experiments executed on SageMaker such as SageMaker Autopilot jobs and training jobs will be automatically tracked. You can also track artifacts for additional steps within an ML workflow that come before/after model training e.g. data pre-processing or post-training model evaluation.' '' 'The APIs also let you search and browse your current and past experiments compare experiments and identify best performing models.' '' 'Now we will demonstrate these capabilities through an MNIST handwritten digits classification example. The experiment will be organized as follow:' '' '1. Download and prepare the MNIST dataset.' '2. Train a Convolutional Neural Network (CNN) Model. Tune the hyper parameter that configures the number of hidden channels in the model. Track the parameter configurations and resulting model accuracy using SageMaker Experiments Python SDK.' '3. Finally use the search and analytics capabilities of Python SDK to search compare and evaluate the performance of all model versions generated from model tuning in Step 2.' '4. We will also see an example of tracing the complete linage of a model version i.e. the collection of all the data pre-processing and training configurations and inputs that went into creating that model version.' '' 'Make sure you selected `Python 3 (Data Science)` kernel.']\n",
      "['# Understanding Annotation Consolidation: A SageMaker Ground Truth Demonstration for Image Classification']\n",
      "['## Part 1: Create Resources Needed for an Active Learning Workflow' '' 'Use this part of the notebook to create the resources required to create an automated labeling workflow for a text-classification labeling job. Specifically we will create:' '' '* An input manifest file using the UCI News Dataset with 20% of the data labeled' '* A CreateLabelingJob request' '' '**This notebook is intended to be used along side the blog post [Bring your own model for SageMaker labeling workflows with Active Learning](https://aws.amazon.com/blogs/machine-learning/bring-your-own-model-for-amazon-sagemaker-labeling-workflows-with-active-learning/)  Part 1: Create an Active Learning Workflow with BlazingText**.' '' 'While following along with this blog post we recommend that you leave most of the cells unmodified. However the notebook will indicate where you can modify variables to create the resources needed for a custom labeling job.' '' 'If you plan to customize the Ground Truth labeling job request configuration below you will also need the resources required to create a labeling job. For more information see [Use Amazon SageMaker Ground Truth for Data Labeling](https://docs.aws.amazon.com/sagemaker/latest/dg/sms.html). ' '' '### Using this Notebook' '' 'Please set the kernel to *conda_tensorflow_p36* when running this notebook.' '' 'Run the code cells in this notebook to configure a Labeling Job request in JSON format. This request JSON can be used in an active learning workflow and will determine how your labeling job task appears to human workers. ' '' 'To customize this notebook you will need to modify the the cells below and configure the Ground Truth labeling job request (`human_task_config`) to meet your requirements. To learn how to create a Ground Truth labeling job using the Amazon SageMaker API see [CreateLabelingJob](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_CreateLabelingJob.html).']\n",
      "['# Data Analysis Using a Ground Truth Image Classification Output Manifest' '' '1. [Introduction](#Introduction)' '2. [Postprocess the Output Manifest](#Postprocess-the-output-manifest)' '3. [Plot class histograms](#Plott-class-histograms)' '4. [Plot annotated images](#Plot-annotated-images)' '  1. [Plot a small output sample](#Plot-a-small-output-sample)' '  2. [Plot the full results](#Plot-the-full-results)']\n",
      "['# From Unlabeled Data to a Deployed Machine Learning Model: A SageMaker Ground Truth Demonstration for Image Classification' '' '1. [Introduction](#Introduction)' '2. [Run a Ground Truth labeling job (time: about 3h)](#Run-a-Ground-Truth-labeling-job)' '    1. [Prepare the data](#Prepare-the-data)' '    2. [Specify the categories](#Specify-the-categories)' '    3. [Create the instruction template](#Create-the-instruction-template)' '    4. [Create a private team to test your task [OPTIONAL]](#Create-a-private-team-to-test-your-task-[OPTIONAL])' '    5. [Define pre-built lambda functions for use in the labeling job](#Define-pre-built-lambda-functions-for-use-in-the-labeling-job)' '    6. [Submit the Ground Truth job request](#Submit-the-Ground-Truth-job-request)' '        1. [Verify your task using a private team [OPTIONAL]](#Verify-your-task-using-a-private-team-[OPTIONAL])' '    7. [Monitor job progress](#Monitor-job-progress)' '3. [Analyze Ground Truth labeling job results (time: about 20min)](#Analyze-Ground-Truth-labeling-job-results)' '    1. [Postprocess the output manifest](#Postprocess-the-output-manifest)' '    2. [Plot class histograms](#Plot-class-histograms)' '    3. [Plot annotated images](#Plot-annotated-images)' '        1. [Plot a small output sample](#Plot-a-small-output-sample)' '        2. [Plot the full results](#Plot-the-full-results)' '4. [Compare Ground Truth results to standard labels (time: about 5min)](#Compare-Ground-Truth-results-to-standard-labels)' '    1. [Compute accuracy](#Compute-accuracy)' '    2. [Plot correct and incorrect annotations](#Plot-correct-and-incorrect-annotations)' '5. [Train an image classifier using Ground Truth labels (time: about 15min)](#Train-an-image-classifier-using-Ground-Truth-labels)' '6. [Deploy the Model (time: about 20min)](#Deploy-the-Model)' '    1. [Create Model](#Create-Model)' '    2. [Batch Transform](#Batch-Transform)' '    3. [Realtime Inference](#Realtime-Inference)' '        1. [Create Endpoint Configuration](#Create-Endpoint-Configuration)' '        2. [Create Endpoint](#Create-Endpoint)' '        3. [Perform Inference](#Perform-Inference)' '7. [Review](#Review)']\n",
      "['# From Unlabeled Data to a Deployed Machine Learning Model: A SageMaker Ground Truth Demonstration for Object Detection' '' '1. [Introduction](#Introduction)' '2. [Run a Ground Truth labeling job (time: about 4h)](#Run-a-Ground-Truth-labeling-job)' '    1. [Prepare the data](#Prepare-the-data)' '    2. [Specify the category](#Specify-the-categories)' '    3. [Create the instruction template](#Create-the-instruction-template)' '    4. [Create a private team to test your task [OPTIONAL]](#Create-a-private-team-to-test-your-task-[OPTIONAL])' '    5. [Define pre-built lambda functions for use in the labeling job](#Define-pre-built-lambda-functions-for-use-in-the-labeling-job)' '    6. [Submit the Ground Truth job request](#Submit-the-Ground-Truth-job-request)' '        1. [Verify your task using a private team [OPTIONAL]](#Verify-your-task-using-a-private-team-[OPTIONAL])' '    7. [Monitor job progress](#Monitor-job-progress)' '3. [Analyze Ground Truth labeling job results (time: about 20min)](#Analyze-Ground-Truth-labeling-job-results)' '    1. [Postprocess the output manifest](#Postprocess-the-output-manifest)' '    2. [Plot class histograms](#Plot-class-histograms)' '    3. [Plot annotated images](#Plot-annotated-images)' '        1. [Plot a small output sample](#Plot-a-small-output-sample)' '        2. [Plot the full results](#Plot-the-full-results)' '4. [Compare Ground Truth results to standard labels (time: about 5min)](#Compare-Ground-Truth-results-to-standard-labels)' '    1. [Compute accuracy](#Compute-accuracy)' '    2. [Plot correct and incorrect annotations](#Plot-correct-and-incorrect-annotations)' '5. [Train an object detector using Ground Truth labels (time: about 15min)](#Train-an-image-classifier-using-Ground-Truth-labels)' '6. [Deploy the Model (time: about 20min)](#Deploy-the-Model)' '    1. [Create Model](#Create-Model)' '    2. [Batch Transform](#Batch-Transform)' '7. [Review](#Review)']\n",
      "['# Training Object Detection Models in SageMaker with Augmented Manifests' '' 'This notebook demonstrates the use of an \"augmented manifest\" to train an object detection machine learning model with AWS SageMaker.']\n",
      "['# Using a Pre-Trained Model for Cost Effective Data Labeling' '' '1. [Introduction](#Introduction)' '2. [Iteration #1: Create Initial Labeling Job](#Iteration1)' '3. [Iteration #2: Labeling Job with Pre-Trained Model](#Iteration2)' '3. [Iteration #3: Second Data Subset Without Pre-Trained Model](#Iteration3)' '4. [Conclusion](#Conclusion)']\n",
      "['# Identify Worker Labeling Efficiency using SageMaker GroundTruth']\n",
      "['# Analyze Results of a Hyperparameter Tuning job' '' 'Once you have completed a tuning job (or even while the job is still running) you can use this notebook to analyze the results to understand how each hyperparameter effects the quality of the model.' '' '---' '## Set up the environment' 'To start the analysis you must pick the name of the hyperparameter tuning job.']\n",
      "['## Hyperparameter Tuning with Chainer' '' '[VGG](https://arxiv.org/pdf/1409.1556v6.pdf) is an architecture for deep convolution networks. In this example we use convolutional networks to perform image classification using the CIFAR-10 dataset. CIFAR-10 consists of 60000 32x32 colour images in 10 classes with 6000 images per class. There are 50000 training images and 10000 test images.' '' \"We'll use SageMaker's hyperparameter tuning to train multiple convolutional networks experimenting with different hyperparameter combinations. After that we'll find the model with the best performance deploy it to Amazon SageMaker hosting and then classify images using the deployed model.\" '' 'This notebook uses the Chainer script and estimator setup from [the \"Training with Chainer\" notebook](files/chainer_single_machine_cifar10.ipynb).']\n",
      "['# Automatic Model Tuning : Automatic training job early stopping' '_**Using automatic training job early stopping to speed up the tuning of an end-to-end multiclass image classification task**_' '' '---' '## Important notes:' '' '* Two hyperparameter tuning jobs will be created in this sample notebook. With current setting each tuning job takes around 2 hours to complete and may cost you up to 16 USD depending on which region you are in. ' '* Due to cost consideration the goal of this example is to show you how to use the new feature not necessarily to achieve the best result.' '* The built-in image classification algorithm on GPU instance will be used in this example.' '* Different runs of this notebook may lead to different results due to the non-deterministic nature of Automatic Model Tuning. But it is fair to assume some training jobs will be stopped by automatic early stopping.' '' '---' '## Contents' '1. [Background](#Background)' '1. [Set_up](#Set-up)' '1. [Data_preparation](#Data-preparation)' '1. [Set_up_hyperparameter_tuning_job](#Set-up-hyperparameter-tuning-job)' '1. [Launch_hyperparameter_tuning_job](#Launch-hyperparameter-tuning-job)' '1. [Launch_hyperparameter_tuning_job_with_automatic_early_stopping](#Launch-hyperparameter-tuning-job-with-automatic-early-stopping)' '1. [Wrap_up](#Wrap-up)' '' '' '---' '' '## Background' '' 'Selecting the right hyperparameter values for machine learning model can be difficult. The right answer dependes on the algorithm and the data; Some algorithms have many tuneable hyperparameters; Some are very sensitive to the hyperparameter values selected; and yet most have a non-linear relationship between model fit and hyperparameter values. Amazon SageMaker Automatic Model Tuning helps by automating the hyperparameter tuning process.' '' 'Experienced data scientist often stop a training when it is not promising based on the first few validation metrics emitted during the training. This notebook will demonstrate how to use the automatic training job early stopping of Amazon SageMaker Automatic Model Tuning to speed up the tuning process with a simple switch.' '' '---' '' '## Set up' '' 'Let us start by specifying:' '' '- The role that is used to give learning and hosting the access to the data. This will automatically be obtained from the role used to start the notebook.' '- The S3 bucket that will be used for loading training data and saving model data.' '- The Amazon SageMaker image classification docker image which need not to be changed.']\n",
      "['# Automatic Model Tuning : Warm Starting Tuning Jobs' '_** Using Warm Start to tune End-to-End Multiclass Image Classification **_' '' '---' '## Important notes:' '* 3 Hyperparameter tuning jobs will be created in this sample notebook. With current setting each tuning job takes 30-40 minutes to complete and may cost you up to $3 depending on which region you are in. ' '* Due to cost consideration the goal of this exmaple is to show you how to use some of the features not necessarily to achieve the best result.' '* We use the built-in image classification algorithm in this example and GPU instance is required. ' \"* Please do not use Cell -> Run All since you'll need to wait for the parent tuning job to finish before the new tuning job can be created with warm start.\" '' '---' '## Contents' '' '1. [Background](#Background)' '1. [Set_up](#Set-up)' '1. [Data_preparation](#Data-preparation)' '1. [Set_up_hyperparameter_tuning_job](#Set-up-hyperparameter-tuning-job)' '1. [Launch_hyperparameter_tuning_job](#Launch-hyperparameter-tuning-job)' '1. [Set_up_hyperparameter_tuning_using_warm_start_configuration](#Set-up-hyperparameter-tuning-job-using-warm-start-configuration)' '1. [Launch_hyperparameter_tuning_job_using_warm_start_configuration](#Launch-hyperparameter-tuning-job-using-warm-start-configuration)' '1. [Get_the_best_model](#Get-the-best-model)' '1. [Launch_hyperparameter_tuning_job_using_warm_start_configuration_with_transfer_learning](#Launch-hyperparameter-tuning-job-using-warm-start-configuration-with-transfer-learning)' '2. [Wrap_up](#Wrap-up)' '' '' '---' '' '## Background' '' 'Selecting the right hyperparameter values for your machine learning model can be difficult. The right answer is dependent on your data; some algorithms have many different hyperparameters that can be tweaked; some are very sensitive to the hyperparameter values selected; and most have a non-linear relationship between model fit and hyperparameter values. ' '' 'Amazon SageMaker Automatic Model Tuning helps with automating the hyperparameter tuning process. In many occasions the tuning process is iterative and requires to run multiple tuning jobs after analyzing the results to get the best objective metric.' '' 'This notebook will demonstrate how to iteratively tune an image classifer leveraging the warm start feature of Amazon SageMaker Automatic Model Tuning. The [caltech-256 dataset](http://www.vision.caltech.edu/Image_Datasets/Caltech256/) will be used to train the image classifier. ' '' 'Warm start configuration allows you to create a new tuning job with the learning gathered in a parent tuning job by specifying up to 5 parent tuning jobs. If a warm start configuration is specified Automatic Model Tuning will load the previous [hyperparameter set objective metrics values] to warm start the new tuning job. This means you can continue optimizing your model from the point you finished your previous tuning job experiment. ' '' '---' '' '## Set up' '' \"Let's start by specifying:\" '' '- The S3 bucket and prefix that you want to use for your training and model data. This should be within the same region as SageMaker training.' '- The IAM role used to give training access to your data.']\n",
      "['# Hyperparameter Tuning using Your Own Keras/Tensorflow Container' '' 'This notebook shows how to build your own Keras(Tensorflow) container test it locally using SageMaker Python SDK local mode and bring it to SageMaker for training leveraging hyperparameter tuning. ' '' 'The model used for this notebook is a ResNet model trainer with the CIFAR-10 dataset. The example is based on https://github.com/keras-team/keras/blob/master/examples/cifar10_cnn.py']\n",
      "['# Gluon CIFAR-10 Hyperparameter Tuning' '_**ResNet model in Gluon trained with SageMaker Automatic Model Tuning and Random Search Tuning**_' '' '---' '' '---' '' '_This notebook was created and tested on an ml.m4.xlarge notebook instance.  However the tuning jobs use multiple ml.p3.8xlarge instances meaning re-running this test could cost approximately \\\\$400.  Please do not use Cell -> Run All.  Certain cell outputs have not been cleared so that you can see results without having to run the notebook yourself._' '' '## Outline' '' '1. [Background](#Background)' '1. [Setup](#Setup)' '1. [Data](#Data)' '1. [Script](#Script)' '1. [Train: Initial](#Train:-Initial)' '1. [Tune: Random](#Tune:-Random)' '1. [Tune: Automatic Model Tuning](#Tune:-Automatic-Model-Tuning)' '1. [Wrap-up](#Wrap-up)' '' '## Background' '' 'Selecting the right hyperparameter values for your machine learning model can be difficult.  The right answer is dependent on your data; some algorithms have many different hyperparameters that can be tweaked; some are very sensitive to the hyperparameter values selected; and most have a non-linear relationship between model fit and hyperparameter values.' '' 'There are a variety of strategies to select hyperparameter values.  Some scientists use domain knowledge heuristics intuition or manual experimentation; others use brute force searches; and some build meta models to predict what performant hyperparameter values may be.  But regardless of the method it usually requires a specialized skill set.  Meanwhile most scientists themselves would prefer to be creating new models rather than endlessly refining an old one.' '' 'Amazon SageMaker can ease this process with Automatic Model Tuning.  This technique uses Gaussian Process regression to predict which hyperparameter values may be most effective at improving fit and Bayesian optimization to balance exploring the hyperparameter space (so that a better predictive model for hyperparameters can be built) and exploiting specific hyperparameter values when needed.' '' \"Other popular methods of hyperparameter optimization include brute force methods like random search.  Despite sounding naive this is often very competitive.  However we've found SageMaker's Automatic Model Tuning to provide better fits in fewer job runs resulting in a better model with less time spent and at a lower cost.  This notebook will compare the two methods in more detail.\" '' \"SageMaker's Automatic Model Tuning works with SageMaker's built-in algorithms pre-built deep learning frameworks and the bring your own algorithm container options.  But for this example let's stick with the MXNet framework a ResNet-34 convolutional neural network and the [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) image dataset.  For more background please see the [MXNet CIFAR-10 example notebook](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/sagemaker-python-sdk/mxnet_gluon_cifar10/mxnet_cifar10_with_gluon.ipynb).\" '' '## Setup' '' 'Specify the IAM role for permission to access the dataset in S3 and SageMaker functionality.']\n",
      "['# Hyperparameter Tuning with Amazon SageMaker and MXNet' '_**Creating a Hyperparameter Tuning Job for an MXNet Network**_' '' '---' '' '---' '' '' '## Contents' '' '1. [Background](#Background)' '1. [Setup](#Setup)' '1. [Data](#Data)' '1. [Code](#Code)' '1. [Tune](#Train)' '1. [Wrap-up](#Wrap-up)' '' '---' '' '## Background' '' \"This example notebook focuses on how to create a convolutional neural network model to train the [MNIST dataset](http://yann.lecun.com/exdb/mnist/) using MXNet distributed training. It leverages SageMaker's hyperparameter tuning to kick off multiple training jobs with different hyperparameter combinations to find the set with best model performance.  This is an important step in the machine learning process as hyperparameter settings can have a large impact on model accuracy.  In this example we'll use the [SageMaker Python SDK](https://github.com/aws/sagemaker-python-sdk) to create a hyperparameter tuning job for an MXNet estimator.\" '' '---' '' '## Setup' '' '_This notebook was created and tested on an ml.m4.xlarge notebook instance._' '' \"Let's start by specifying:\" '' '- The S3 bucket and prefix that you want to use for training and model data.  This should be within the same region as the notebook instance training and hosting.' '- The IAM role arn used to give training and hosting access to your data. See the [documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/using-identity-based-policies.html) for more details on creating these.  Note if a role not associated with the current notebook instance or more than one role is required for training and/or hosting please replace `sagemaker.get_execution_role()` with a the appropriate full IAM role arn string(s).']\n",
      "['# Hyperparameter Tuning using SageMaker PyTorch Container']\n",
      "['# Hyperparameter Tuning with Your Own Container in Amazon SageMaker' \"_**Using Amazon SageMaker's Hyperparameter Tuning with a customer Docker container and R algorithm**_\" '' '---' '' '---' '' '## Contents' '' '1. [Background](#Background)' '1. [Setup](#Setup)' '  1. [Permissions](#Permissions)' '1. [Code](#Code)' '  1. [Publish](#Publish)' '1. [Data](#Data)' '1. [Tune](#Tune)' '1. [Wrap-up](#Wrap-up)' '' '---' '## Background' '' \"R is a popular open source statistical programming language with a lengthy history in Data Science and Machine Learning.  The breadth of algorithms available as R packages is impressive and fuels a diverse community of users.  In this example we'll combine one of those algorithms ([Multivariate Adaptive Regression Splines](https://en.wikipedia.org/wiki/Multivariate_adaptive_regression_splines)) with SageMaker's hyperparameter tuning capabilities to build a simple model on the well-known [Iris dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set).  This notebook will focus mainly on the integration of hyperparameter tuning and a custom algorithm container rather than the process of building your own container.  For more details on that process please see this [notebook](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/advanced_functionality/r_bring_your_own/r_bring_your_own.ipynb).\" '' '---' '## Setup' '' '_This notebook was created and tested on an ml.m4.xlarge notebook instance._' '' \"Let's start by specifying:\" '' '- The S3 bucket and prefix that you want to use for training and model data.  This should be within the same region as the notebook instance training and hosting.' '- The IAM role arn used to give training and hosting access to your data. See the [documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/using-identity-based-policies.html) for more details on creating these.  Note if a role not associated with the current notebook instance or more than one role is required for training and/or hosting please replace `sagemaker.get_execution_role()` with a the appropriate full IAM role arn string(s).']\n",
      "['# Hyperparameter Tuning using SageMaker Tensorflow Container' '' 'This tutorial focuses on how to create a convolutional neural network model to train the [MNIST dataset](http://yann.lecun.com/exdb/mnist/) using **SageMaker TensorFlow container**. It leverages hyperparameter tuning to kick off multiple training jobs with different hyperparameter combinations to find the one with best model training result.']\n",
      "['# Direct Marketing with Amazon SageMaker XGBoost and Hyperparameter Tuning' '_**Supervised Learning with Gradient Boosted Trees: A Binary Prediction Problem With Unbalanced Classes**_' '' '---' '' '---' '' '## Contents' '' '1. [Background](#Background)' '1. [Prepration](#Preparation)' '1. [Data Downloading](#Data_Downloading)' '1. [Data Transformation](#Data_Transformation)' '1. [Setup Hyperparameter Tuning](#Setup_Hyperparameter_Tuning)' '1. [Launch Hyperparameter Tuning](#Launch_Hyperparameter_Tuning)' '1. [Analyze Hyperparameter Tuning Results](#Analyze_Hyperparameter_Tuning_Results)' '1. [Deploy The Best Model](#Deploy_The_Best_Model)' '' '' '---' '' '## Background' \"Direct marketing either through mail email phone etc. is a common tactic to acquire customers.  Because resources and a customer's attention is limited the goal is to only target the subset of prospects who are likely to engage with a specific offer.  Predicting those potential customers based on readily available information like demographics past interactions and environmental factors is a common machine learning problem.\" '' 'This notebook will train a model which can be used to predict if a customer will enroll for a term deposit at a bank after one or more phone calls. Hyperparameter tuning will be used in order to try multiple hyperparameter settings and produce the best model.' '' '---' '' '## Preparation' '' \"Let's start by specifying:\" '' '- The S3 bucket and prefix that you want to use for training and model data.  This should be within the same region as SageMaker training.' '- The IAM role used to give training access to your data. See SageMaker documentation for how to create these.']\n",
      "['# Direct Marketing with Amazon SageMaker XGBoost and Hyperparameter Tuning' '_**Supervised Learning with Gradient Boosted Trees: A Binary Prediction Problem With Unbalanced Classes**_' '' '---' '' '---' '' '## Contents' '' '1. [Background](#Background)' '1. [Prepration](#Preparation)' '1. [Data Downloading](#Data_Downloading)' '1. [Data Transformation](#Data_Transformation)' '1. [Setup Hyperparameter Tuning](#Setup_Hyperparameter_Tuning)' '1. [Launch Hyperparameter Tuning](#Launch_Hyperparameter_Tuning)' '1. [Analyze Hyperparameter Tuning Results](#Analyze_Hyperparameter_Tuning_Results)' '1. [Deploy The Best Model](#Deploy_The_Best_Model)' '1. [Evaluation](#Evaluation)' '' '' '---' '' '## Background' \"Direct marketing either through mail email phone etc. is a common tactic to acquire customers.  Because resources and a customer's attention is limited the goal is to only target the subset of prospects who are likely to engage with a specific offer.  Predicting those potential customers based on readily available information like demographics past interactions and environmental factors is a common machine learning problem.\" '' 'This notebook will train a model which can be used to predict if a customer will enroll for a term deposit at a bank after one or more phone calls. Hyperparameter tuning will be used in order to try multiple hyperparameter settings and produce the best model.' '' 'We will use SageMaker Python SDK a high level SDK to simplify the way we interact with SageMaker Hyperparameter Tuning.' '' '---' '' '## Preparation' '' \"Let's start by specifying:\" '' '- The S3 bucket and prefix that you want to use for training and model data.  This should be within the same region as SageMaker training.' '- The IAM role used to give training access to your data. See SageMaker documentation for how to create these.']\n",
      "['# Random search and hyperparameter scaling with SageMaker XGBoost and Automatic Model Tuning' '' '---' '' '## Contents' '' '1. [Introduction](#Introduction)' '1. [Preparation](#Preparation)' '1. [Download and prepare the data](#Download-and-prepare-the-data)' '1. [Setup hyperparameter tuning](#Setup-hyperparameter-tuning)' '1. [Logarithmic scaling](#Logarithmic-scaling)' '1. [Random search](#Random-search)' '1. [Linear scaling](#Linear-scaling)' '' '' '---' '' '## Introduction' '' 'This notebook showcases the use of two hyperparameter tuning features: **random search** and **hyperparameter scaling**.' '' '' 'We will use SageMaker Python SDK a high level SDK to simplify the way we interact with SageMaker Hyperparameter Tuning.' '' '---' '' '## Preparation' '' \"Let's start by specifying:\" '' '- The S3 bucket and prefix that you want to use for training and model data.  This should be within the same region as SageMaker training.' '- The IAM role used to give training access to your data. See SageMaker documentation for how to create these.']\n",
      "['## Introduction' '' 'In this notebook we demonstrate how BlazingText supports hosting of pre-trained Text Classification and Word2Vec models [FastText models](https://fasttext.cc/docs/en/english-vectors.html). BlazingText is a GPU accelerated version of FastText. FastText is a shallow Neural Network model used to perform both word embedding generation (unsupervised) and text classification (supervised). BlazingText uses custom CUDA kernels to accelerate the training process of FastText but the underlying algorithm is same for both the algorithms. Therefore if you have a model trained with FastText or if one of the pre-trained models made available by FastText team is sufficient for your use case then you can take advantage of Hosting support for BlazingText to setup SageMaker endpoints for realtime predictions using FastText models. It can help you avoid to train with BlazingText algorithm if your use-case is covered by the pre-trained models available from FastText.']\n",
      "['## Introduction' '' 'Text Classification can be used to solve various use-cases like sentiment analysis spam detection hashtag prediction etc. This notebook demonstrates the use of SageMaker BlazingText to perform supervised binary/multi class with single or multi label text classification. BlazingText can train the model on more than a billion words in a couple of minutes using a multi-core CPU or a GPU while achieving performance on par with the state-of-the-art deep learning text classification algorithms. BlazingText extends the fastText text classifier to leverage GPU acceleration using custom CUDA kernels.']\n",
      "['## Introduction' '' 'Word2Vec is a popular algorithm used for generating dense vector representations of words in large corpora using unsupervised learning. These representations are useful for many natural language processing (NLP) tasks like sentiment analysis named entity recognition and machine translation.  ' '' 'Popular models that learn such representations ignore the morphology of words by assigning a distinct vector to each word. This is a limitation especially for languages with large vocabularies and many rare words. *SageMaker BlazingText* can learn vector representations associated with character n-grams; representing words as the sum of these character n-grams representations [1]. This method enables *BlazingText* to generate vectors for out-of-vocabulary (OOV) words as demonstrated in this notebook.']\n",
      "['## Introduction' '' 'Word2Vec is a popular algorithm used for generating dense vector representations of words in large corpora using unsupervised learning. The resulting vectors have been shown to capture semantic relationships between the corresponding words and are used extensively for many downstream natural language processing (NLP) tasks like sentiment analysis named entity recognition and machine translation.  ']\n",
      "['# SageMaker/DeepAR demo on electricity dataset' '' 'This notebook complements the [DeepAR introduction notebook](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/introduction_to_amazon_algorithms/deepar_synthetic/deepar_synthetic.ipynb). ' '' 'Here we will consider a real use case and show how to use DeepAR on SageMaker for predicting energy consumption of 370 customers over time based on a [dataset](https://archive.ics.uci.edu/ml/datasets/ElectricityLoadDiagrams20112014) that was used in the academic papers [[1](https://media.nips.cc/nipsbooks/nipspapers/paper_files/nips29/reviews/526.html)] and [[2](https://arxiv.org/abs/1704.04110)].  ' '' 'In particular we will see how to:' '* Prepare the dataset' '* Use the SageMaker Python SDK to train a DeepAR model and deploy it' '* Make requests to the deployed model to obtain forecasts interactively' '* Illustrate advanced features of DeepAR: missing values additional time features non-regular frequencies and category information' '' 'Running this notebook takes around 40 min on a ml.c4.2xlarge for the training and inference is done on a ml.m4.xlarge (the usage time will depend on how long you leave your served model running).' '' 'For more information see the DeepAR [documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/deepar.html) or [paper](https://arxiv.org/abs/1704.04110) ']\n",
      "['# Time series forecasting with DeepAR - Synthetic data']\n",
      "['# An Introduction to Factorization Machines with MNIST' '_**Making a Binary Prediction of Whether a Handwritten Digit is a 0**_' '' '1. [Introduction](#Introduction)' '2. [Prerequisites and Preprocessing](#Prequisites-and-Preprocessing)' '  1. [Permissions and environment variables](#Permissions-and-environment-variables)' '  2. [Data ingestion](#Data-ingestion)' '  3. [Data inspection](#Data-inspection)' '  4. [Data conversion](#Data-conversion)' '3. [Training the FM model](#Training-the-FM-model)' '4. [Set up hosting for the model](#Set-up-hosting-for-the-model)' '  1. [Import model into hosting](#Import-model-into-hosting)' '  2. [Create endpoint configuration](#Create-endpoint-configuration)' '  3. [Create endpoint](#Create-endpoint)' '5. [Validate the model for use](#Validate-the-model-for-use)']\n",
      "['#  Using SageMaker Image Classification with Amazon Elastic Inference' '' '1. [Introduction](#Introduction)' '2. [Prerequisites and Preprocessing](#Prequisites-and-Preprocessing)' '  1. [Permissions and environment variables](#Permissions-and-environment-variables)' '3. [Training the ResNet model](#Training-the-ResNet-model)' '4. [Deploy The Model](#Deploy-the-model)' '  1. [Create model](#Create-model)' '  3. [Real-time inference](#Real-time-inference)' '    1. [Create endpoint configuration](#Create-endpoint-configuration) ' '    2. [Create endpoint](#Create-endpoint) ' '    3. [Perform inference](#Perform-inference) ' '    4. [Clean up](#Clean-up)']\n",
      "['# End-to-End Multiclass Image Classification Example' '1. [Introduction](#Introduction)' '2. [Prerequisites and Preprocessing](#Prequisites-and-Preprocessing)' '  1. [Permissions and environment variables](#Permissions-and-environment-variables)' '  2. [Prepare the data](#Prepare-the-data)' '3. [Training the model](#Training-the-model)' '  1. [Training parameters](#Training-parameters)' '  2. [Start the training](#Start-the-training)' '4. [Compile](#Compile)' '5. [Inference](#Inference)']\n",
      "['# End-to-End Multiclass Image Classification Example' '' '1. [Introduction](#Introduction)' '2. [Prerequisites and Preprocessing](#Prequisites-and-Preprocessing)' '  1. [Permissions and environment variables](#Permissions-and-environment-variables)' '3. [Training the ResNet model](#Training-the-ResNet-model)' '4. [Deploy The Model](#Deploy-the-model)' '  1. [Create model](#Create-model)' '  2. [Batch transform](#Batch-transform)' '  3. [Realtime inference](#Realtime-inference)' '    1. [Create endpoint configuration](#Create-endpoint-configuration) ' '    2. [Create endpoint](#Create-endpoint) ' '    3. [Perform inference](#Perform-inference) ' '    4. [Clean up](#Clean-up)']\n",
      "['# End-to-End Incremental Training Image Classification Example' '1. [Introduction](#Introduction)' '2. [Prerequisites and Preprocessing](#Prequisites-and-Preprocessing)' '  1. [Permissions and environment variables](#Permissions-and-environment-variables)' '  2. [Prepare the data](#Prepare-the-data)' '3. [Training the model](#Training-the-model)' '  1. [Training parameters](#Training-parameters)' '  2. [Start the training](#Start-the-training)' '4. [Inference](#Inference)']\n",
      "['# Image classification training with image format demo' '' '1. [Introduction](#Introduction)' '2. [Prerequisites and Preprocessing](#Prequisites-and-Preprocessing)' '  1. [Permissions and environment variables](#Permissions-and-environment-variables)' '  2. [Prepare the data](#Prepare-the-data)' '3. [Fine-tuning The Image Classification Model](#Fine-tuning-the-Image-classification-model)' '  1. [Training parameters](#Training-parameters)' '  2. [Start the training](#Start-the-training)' '4. [Inference](#Inference)']\n",
      "['# Image classification training with image format' '' '1. [Introduction](#Introduction)' '2. [Prerequisites and Preprocessing](#Prequisites-and-Preprocessing)' '  1. [Permissions and environment variables](#Permissions-and-environment-variables)' '  2. [Prepare the data](#Prepare-the-data)' '3. [Fine-tuning The Image Classification Model](#Fine-tuning-the-Image-classification-model)' '  1. [Training parameters](#Training-parameters)' '  2. [Training](#Training)' '4. [Deploy The Model](#Deploy-the-model)' '  1. [Create model](#Create-model)' '  2. [Batch transform](#Batch-transform)' '  3. [Realtime inference](#Realtime-inference)' '    1. [Create endpoint configuration](#Create-endpoint-configuration) ' '    2. [Create endpoint](#Create-endpoint) ' '    3. [Perform inference](#Perform-inference) ' '    4. [Clean up](#Clean-up)']\n",
      "['# Image classification transfer learning demo' '' '1. [Introduction](#Introduction)' '2. [Prerequisites and Preprocessing](#Prequisites-and-Preprocessing)' '3. [Fine-tuning the Image classification model](#Fine-tuning-the-Image-classification-model)' '4. [Training parameters](#Training-parameters)' '5. [Start the training](#Start-the-training)' '6. [Inference](#Inference)']\n",
      "['# Image classification transfer learning demo' '' '1. [Introduction](#Introduction)' '2. [Prerequisites and Preprocessing](#Prequisites-and-Preprocessing)' '3. [Fine-tuning the Image classification model](#Fine-tuning-the-Image-classification-model)' '4. [Deploy The Model](#Deploy-the-model)' '  1. [Create model](#Create-model)' '  2. [Batch transform](#Batch-transform)' '  3. [Realtime inference](#Realtime-inference)' '    1. [Create endpoint configuration](#Create-endpoint-configuration) ' '    2. [Create endpoint](#Create-endpoint) ' '    3. [Perform inference](#Perform-inference) ' '    4. [Clean up](#Clean-up)']\n",
      "['# Image classification multi-label classification' '' '1. [Introduction](#Introduction)' '2. [Prerequisites](#Prequisites)' '3. [Data Preparation](#Data-Preparation)' '3. [Multi-label Training](#Multi-label-Training)' '4. [Inference](#Inference)' '5. [Clean-up](#Clean-up)']\n",
      "['# An Introduction to the Amazon SageMaker IP Insights Algorithm' '#### Unsupervised anomaly detection for susicipous IP addresses' '-------' '1. [Introduction](#Introduction)' '2. [Setup](#Setup)' '3. [Training](#Training)' '4. [Inference](#Inference)' '5. [Epilogue](#Epilogue)' '' '## Introduction' '-------' '' 'The Amazon SageMaker IP Insights algorithm uses statistical modeling and neural networks to capture associations between online resources (such as account IDs or hostnames) and IPv4 addresses. Under the hood it learns vector representations for online resources and IP addresses. This essentially means that if the vector representing an IP address and an online resource are close together then it is likey for that IP address to access that online resource even if it has never accessed it before.' '' 'In this notebook we use the Amazon SageMaker IP Insights algorithm to train a model on synthetic data. We then use this model to perform inference on the data and show how to discover anomalies. After running this notebook you should be able to:' '' '- obtain transform and store data for use in Amazon SageMaker' '- create an AWS SageMaker training job to produce an IP Insights model' '- use the model to perform inference with an Amazon SageMaker endpoint.' '' 'If you would like to know more please check out the [SageMaker IP Inisghts Documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/ip-insights.html). ' '' '## Setup' '------' '*This notebook was created and tested on a ml.m4.xlarge notebook instance.*' '' 'Our first step is to setup our AWS credentials so that AWS SageMaker can store and access training data and model artifacts.' '' '### Select Amazon S3 Bucket' 'We first need to specify the locations where we will store our training data and trained model artifacts. ***This is the only cell of this notebook that you will need to edit.*** In particular we need the following data:' '' '- `bucket` - An S3 bucket accessible by this account.' \"- `prefix` - The location in the bucket where this notebook's input and output data will be stored. (The default value is sufficient.)\"]\n",
      "['# Introduction' '' 'k-Nearest-Neighbors (kNN) is a simple technique for classification. The idea behind' 'it is that similar data points should have the same class at least most of the time.' 'This method is very intuitive and has proven itself in many domains including' 'recommendation systems anomaly detection image/text classification and more.' '' 'In what follows we present a detailed example of a multi-class classification objective. The dataset we use contains information collected by the US Geological Survey and the US Forest Service about wilderness areas in northern Colorado. The features are measurements like soil type elevation and distance to water and the labels encode the type of trees - the forest cover type - for each location. The machine learning task is to predict the cover type in a given location using the features. Overall there are seven cover types.' '' \"The notebook has two sections. In the first we use Amazon SageMaker's python SDK in order to train a kNN classifier in its simplest setting. We explain the components common to all Amazon SageMaker's algorithms including uploading data to Amazon S3 training a model and setting up an endpoint for online inference. In the second section we dive deeper into the details of Amazon SageMaker kNN. We explain the different knobs (hyper-parameters) associated with it and demonstrate how each setting can lead to a somewhat different accuracy and latency at inference time.\"]\n",
      "['# An Introduction to SageMaker LDA' '' '***Finding topics in synthetic document data using Spectral LDA algorithms.***' '' '---' '' '1. [Introduction](#Introduction)' '1. [Setup](#Setup)' '1. [Training](#Training)' '1. [Inference](#Inference)' '1. [Epilogue](#Epilogue)']\n",
      "['# An Introduction to Linear Learner with MNIST' '_**Making a Binary Prediction of Whether a Handwritten Digit is a 0**_' '' '1. [Introduction](#Introduction)' '2. [Prerequisites and Preprocessing](#Prequisites-and-Preprocessing)' '  1. [Permissions and environment variables](#Permissions-and-environment-variables)' '  2. [Data ingestion](#Data-ingestion)' '  3. [Data inspection](#Data-inspection)' '  4. [Data conversion](#Data-conversion)' '3. [Training the linear model](#Training-the-linear-model)' '4. [Set up hosting for the model](#Set-up-hosting-for-the-model)' '5. [Validate the model for use](#Validate-the-model-for-use)']\n",
      "['# Train Linear Learner model using File System Data Source ']\n",
      "['# Object Detection using Managed Spot Training' '' 'The example here is almost the same as [Amazon SageMaker Object Detection using the RecordIO format](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/introduction_to_amazon_algorithms/object_detection_pascalvoc_coco/object_detection_recordio_format.ipynb).' '' 'This notebook tackles the exact same problem with the same solution but it has been modified to be able to run using SageMaker Managed Spot infrastructure. SageMaker Managed Spot uses [EC2 Spot Instances](https://aws.amazon.com/ec2/spot/) to run Training at a lower cost.' '' 'Please read the original notebook and try it out to gain an understanding of the ML use-case and how it is being solved. We will not delve into that here in this notebook.' '' '## Setup' \"Again we won't go into detail explaining the code below it has been lifted verbatim from [Amazon SageMaker Object Detection using the RecordIO format](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/introduction_to_amazon_algorithms/object_detection_pascalvoc_coco/object_detection_recordio_format.ipynb).\"]\n",
      "['# Introduction to Basic Functionality of NTM' '_**Finding Topics in Synthetic Document Data with the Neural Topic Model**_' '' '---' '' '---' '' '# Contents' '***' '' '1. [Introduction](#Introduction)' '1. [Setup](#Setup)' '1. [Data](#Data)' '1. [Train](#Train)' '1. [Host](#Host)' '1. [Extensions](#Extensions)']\n",
      "['# An Introduction to SageMaker ObjectToVec model for MovieLens recommendation' '' '' '1. [Background](#Background)' '1. [Data exploration and preparation](#Data-exploration-and-preparation)' '1. [Rating prediction task](#Rating-prediction-task)' '1. [Recommendation task](#Recommendation-task)' '1. [Movie retrieval in the embedding space](#Movie-retrieval-in-the-embedding-space)']\n",
      "['# Movie genre prediction with Object2Vec Algorithm' '' '1. [Introduction](#Introduction)' '2. [Install and import dependencies](#Install-and-import-dependencies)' '3. [Preprocessing](#Preprocessing)' '  1. [Build the vocabulary](#Build-the-vocabulary)' '  2. [Split data into train validation and test](#Split-data-into-train-validation-and-test)' '  3. [Negative sampling](#Negative-sampling)' '  4. [Tokenization](#Tokenization)' '  5. [Download pretrained word embeddings](#Download-pretrained-word-embeddings)' '4. [Sagemaker Training](#Sagemaker-Training)' '  1. [Upload data to S3](#Upload-data-to-S3)' '  1. [Training hyperparameters](#Training-hyperparameters)' '5. [Evaluation with Batch inference](#Evaluation-with-Batch-inference)' '6. [Online inference demo](#Online-inference-demo)']\n",
      "['# An Introduction to SageMaker ObjectToVec model for sequence-sequence embedding' '' '## Table of contents' '' '1. [Background](#Background)' '1. [Download datasets](#Download-datasets)' '1. [Preprocessing](#Preprocessing)' '1. [Model training and inference](#Model-training-and-inference)' '1. [Transfer learning with object2vec](#Transfer-learning)' '1. [How to enable the optimal training result](#How-to-enable-the-optimal-training-result)' '1. [Hyperparameter Tuning (Advanced)](#Hyperparameter-Tuning-(Advanced))']\n",
      "['# Amazon SageMaker Object Detection for Bird Species' '' '1. [Introduction](#Introduction)' '2. [Setup](#Setup)' '3. [Data Preparation](#Data-Preparation)' '  1. [Download and unpack the dataset](#Download-and-unpack-the-dataset)' '  2. [Understand the dataset](#Understand-the-dataset)' '  3. [Generate RecordIO files](#Generate-RecordIO-files)' '4. [Train the model](#Train-the-model)' '5. [Host the model](#Host-the-model)' '6. [Test the model](#Test-the-model)' '7. [Clean up](#Clean-up)' '8. [Improve the model](#Improve-the-model)' '9. [Final cleanup](#Final-cleanup)']\n",
      "['# Amazon SageMaker Object Detection using the Image and JSON format' '' '1. [Introduction](#Introduction)' '2. [Setup](#Setup)' '3. [Data Preparation](#Data-Preparation)' '  1. [Download data](#Download-Data)' '  2. [Prepare Dataset](#Prepare-dataset)' '  3. [Upload to S3](#Upload-to-S3)' '4. [Training](#Training)' '5. [Hosting](#Hosting)' '6. [Inference](#Inference)']\n",
      "['# Amazon SageMaker Object Detection Incremental Training' '' '1. [Introduction](#Introduction)' '2. [Setup](#Setup)' '3. [Data Preparation](#Data-Preparation)' '  1. [Download data](#Download-data)' '  2. [Convert data into RecordIO](#Convert-data-into-RecordIO)' '  3. [Upload data to S3](#Upload-data-to-S3)' '4. [Intial Training](#Initial-Training)' '5. [Incremental Training](#Incremental-Training)' '6. [Hosting](#Hosting)' '7. [Inference](#Inference)']\n",
      "['# Amazon SageMaker Object Detection using the RecordIO format' '' '1. [Introduction](#Introduction)' '2. [Setup](#Setup)' '3. [Data Preparation](#Data-Preparation)' '  1. [Download data](#Download-Data)' '  2. [Convert data into RecordIO](#Convert-data-into-RecordIO)' '  3. [Upload to S3](#Upload-to-S3)' '4. [Training](#Training)' '5. [Hosting](#Hosting)' '6. [Inference](#Inference)']\n",
      "['# An Introduction to PCA with MNIST' '_**Investigating Eigendigits from Principal Components Analysis on Handwritten Digits**_' '' '1. [Introduction](#Introduction)' '2. [Prerequisites and Preprocessing](#Prequisites-and-Preprocessing)' '  1. [Permissions and environment variables](#Permissions-and-environment-variables)' '  2. [Data ingestion](#Data-ingestion)' '  3. [Data inspection](#Data-inspection)' '  4. [Data conversion](#Data-conversion)' '3. [Training the PCA model](#Training-the-PCA-model)' '4. [Set up hosting for the model](#Set-up-hosting-for-the-model)' '  1. [Import model into hosting](#Import-model-into-hosting)' '  2. [Create endpoint configuration](#Create-endpoint-configuration)' '  3. [Create endpoint](#Create-endpoint)' '5. [Validate the model for use](#Validate-the-model-for-use)']\n",
      "['# An Introduction to SageMaker Random Cut Forests' '' '***Unsupervised anomaly detection on timeseries data a Random Cut Forest algorithm.***' '' '---' '' '1. [Introduction](#Introduction)' '1. [Setup](#Setup)' '1. [Training](#Training)' '1. [Inference](#Inference)' '1. [Epilogue](#Epilogue)']\n",
      "['# Amazon SageMaker Semantic Segmentation Algorithm' '' '1. [Introduction](#Introduction)' '2. [Setup](#Setup)' '3. [Data Preparation](#Data-Preparation)' '  1. [Download data](#Download-data)' '  2. [Setup Data](#Setup-data)' '  3. [Upload to S3](#Upload-to-S3)' '4. [Training](#Training)' '5. [Hosting](#Hosting)' '6. [Inference](#Inference)' '' '## Introduction' '' 'Semantic Segmentation (SS) is the task of classifying every pixel in an image with a class from a known set of labels. In contrast [image classification](https://github.com/awslabs/amazon-sagemaker-examples/tree/master/introduction_to_amazon_algorithms/imageclassification_caltech) generates only one label per image and [object detection](https://github.com/awslabs/amazon-sagemaker-examples/tree/master/introduction_to_amazon_algorithms/object_detection_pascalvoc_coco) generates a bounding box along with the label for each object in the image. The semantic segmentation output is usually represented as different pixel values in the image. Therefore the output is an integer matrix (or a grayscale image) with the same shape as the input image. This output image is also called a segmentation mask. With the Amazon SageMaker Semantic Segmentation algorithm not only can you train your models with your own dataset but also use our pre-trained models for lazy initialization.' '' 'This notebook is an end-to-end example introducing the Amazon SageMaker Semantic Segmentation algorithm. In this demo we will demonstrate how to train and host a semantic segmentation model using the fully-convolutional network ([FCN](https://arxiv.org/abs/1605.06211)) algorithm using the [Pascal VOC dataset](http://host.robots.ox.ac.uk/pascal/VOC/) for training. Amazon SageMaker Semantic Segmentation also provides the option of using Pyramid Scene Parsing Network([PSP](https://arxiv.org/abs/1612.01105)) and [Deeplab-v3](https://arxiv.org/abs/1706.05587) in addition to the FCN Network. Along the way we will also demonstrate how to construct a training dataset in the format that the training job will consume. Finally we will demonstrate how to host and validate the trained model.' '' '## Setup' '' 'To train the Semantic Segmentation algorithm on Amazon SageMaker we need to setup and authenticate the use of AWS services. To begin with we need an AWS account role with SageMaker access. This role that is used to give SageMaker access to your data in S3 can automatically be obtained from the role used to start the notebook.']\n",
      "['# Machine Translation English-German Example Using SageMaker Seq2Seq' '' '1. [Introduction](#Introduction)' '2. [Setup](#Setup)' '3. [Download dataset and preprocess](#Download-dataset-and-preprocess)' '3. [Training the Machine Translation model](#Training-the-Machine-Translation-model)' '4. [Inference](#Inference)']\n",
      "['# Regression with Amazon SageMaker XGBoost algorithm' '_**Single machine training for regression with Amazon SageMaker XGBoost algorithm**_' '' '---' '' '---' '## Contents' '1. [Introduction](#Introduction)' '2. [Setup](#Setup)' '  1. [Fetching the dataset](#Fetching-the-dataset)' '  2. [Data Ingestion](#Data-ingestion)' '3. [Training the XGBoost model](#Training-the-XGBoost-model)' '  1. [Plotting evaluation metrics](#Plotting-evaluation-metrics)' '4. [Set up hosting for the model](#Set-up-hosting-for-the-model)' '  1. [Import model into hosting](#Import-model-into-hosting)' '  2. [Create endpoint configuration](#Create-endpoint-configuration)' '  3. [Create endpoint](#Create-endpoint)' '5. [Validate the model for use](#Validate-the-model-for-use)' '' '---' '## Introduction' '' 'This notebook demonstrates the use of Amazon SageMaker’s implementation of the XGBoost algorithm to train and host a regression model. We use the [Abalone data](https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/regression.html) originally from the [UCI data repository](https://archive.ics.uci.edu/ml/datasets/abalone). More details about the original dataset can be found [here](https://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.names).  In the libsvm converted [version](https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/regression.html) the nominal feature (Male/Female/Infant) has been converted into a real valued feature. Age of abalone is to be predicted from eight physical measurements.  ' '' '---' '## Setup' '' '' 'This notebook was created and tested on an ml.m4.4xlarge notebook instance.' '' \"Let's start by specifying:\" '1. The S3 bucket and prefix that you want to use for training and model data. This should be within the same region as the Notebook Instance training and hosting.' '1. The IAM role arn used to give training and hosting access to your data. See the documentation for how to create these. Note if more than one role is required for notebook instances training and/or hosting please replace the boto regexp with a the appropriate full IAM role arn string(s).']\n",
      "['# Regression with Amazon SageMaker XGBoost algorithm' '_**Distributed training for regression with Amazon SageMaker XGBoost script mode**_' '' '---' '' '## Contents' '1. [Introduction](#Introduction)' '2. [Setup](#Setup)' '  1. [Fetching the dataset](#Fetching-the-dataset)' '  2. [Data Ingestion](#Data-ingestion)' '3. [Training the XGBoost model](#Training-the-XGBoost-model)' '3. [Deploying the XGBoost model](#Deploying-the-XGBoost-model)' '' '---']\n",
      "['# Managed Spot Training for XGBoost' '' \"This notebook shows usage of SageMaker Managed Spot infrastructure for XGBoost training. Below we show how Spot instances can be used for the 'algorithm mode' and 'script mode' training methods with the XGBoost container. \" '' '[Managed Spot Training](https://docs.aws.amazon.com/sagemaker/latest/dg/model-managed-spot-training.html) uses Amazon EC2 Spot instance to run training jobs instead of on-demand instances. You can specify which training jobs use spot instances and a stopping condition that specifies how long Amazon SageMaker waits for a job to run using Amazon EC2 Spot instances.']\n",
      "['# Regression with Amazon SageMaker XGBoost (Parquet input)' '' 'This notebook exhibits the use of a Parquet dataset for use with the SageMaker XGBoost algorithm. The example here is almost the same as [Regression with Amazon SageMaker XGBoost algorithm](xgboost_abalone.ipynb).' '' 'This notebook tackles the exact same problem with the same solution but has been modified for a Parquet input. ' 'The original notebook provides details of dataset and the machine learning use-case.']\n",
      "['# Multiclass classification with Amazon SageMaker XGBoost algorithm' '_**Single machine and distributed training for multiclass classification with Amazon SageMaker XGBoost algorithm**_' '' '---' '' '---' '## Contents' '' '1. [Introduction](#Introduction)' '2. [Prerequisites and Preprocessing](#Prequisites-and-Preprocessing)' '  1. [Permissions and environment variables](#Permissions-and-environment-variables)' '  2. [Data ingestion](#Data-ingestion)' '  3. [Data conversion](#Data-conversion)' '3. [Training the XGBoost model](#Training-the-XGBoost-model)' '  1. [Training on a single instance](#Training-on-a-single-instance)' '  2. [Training on multiple instances](#Training-on-multiple-instances)' '4. [Set up hosting for the model](#Set-up-hosting-for-the-model)' '  1. [Import model into hosting](#Import-model-into-hosting)' '  2. [Create endpoint configuration](#Create-endpoint-configuration)' '  3. [Create endpoint](#Create-endpoint)' '5. [Validate the model for use](#Validate-the-model-for-use)' '' '---' '## Introduction' '' '' 'This notebook demonstrates the use of Amazon SageMaker’s implementation of the XGBoost algorithm to train and host a multiclass classification model. The MNIST dataset is used for training. It has a training set of 60000 examples and a test set of 10000 examples. To illustrate the use of libsvm training data format we download the dataset and convert it to the libsvm format before training.' '' 'To get started we need to set up the environment with a few prerequisites for permissions and configurations.' '' '---' '## Prequisites and Preprocessing' '' '### Permissions and environment variables' '' 'Here we set up the linkage and authentication to AWS services.' '' '1. The roles used to give learning and hosting access to your data. See the documentation for how to specify these.' '2. The S3 bucket that you want to use for training and model data.']\n",
      "['# Breast Cancer Prediction ' \"_**Predict Breast Cancer using SageMaker's Linear-Learner with features derived from images of Breast Mass**_\" '' '---' '' '---' '' '## Contents' '' '1. [Background](#Background)' '1. [Setup](#Setup)' '1. [Data](#Data)' '1. [Train](#Train)' '1. [Host](#Host)' '1. [Predict](#Predict)' '1. [Extensions](#Extensions)' '' '---' '' '## Background' \"This notebook illustrates how one can use SageMaker's algorithms for solving applications which require `linear models` for prediction. For this illustration we have taken an example for breast cancer prediction using UCI'S breast cancer diagnostic data set available at https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29. The data set is also available on Kaggle at https://www.kaggle.com/uciml/breast-cancer-wisconsin-data. The purpose here is to use this data set to build a predictve model of whether a breast mass image indicates benign or malignant tumor. The data set will be used to illustrate\" '' '* Basic setup for using SageMaker.' '* converting datasets to protobuf format used by the Amazon SageMaker algorithms and uploading to S3. ' \"* Training SageMaker's linear learner on the data set.\" '* Hosting the trained model.' '* Scoring using the trained model.' '' '' '' '---' '' '## Setup' '' \"Let's start by specifying:\" '' \"* The SageMaker role arn used to give learning and hosting access to your data. The snippet below will use the same role used by your SageMaker notebook instance if you're using other.  Otherwise specify the full ARN of a role with the SageMakerFullAccess policy attached.\" '* The S3 bucket that you want to use for training and storing model objects.']\n",
      "['# Ensemble Predictions From Multiple Models' '_**Combining a Linear-Learner with XGBoost for  superior predictive peformance**_' '' '---' '' '---' '' '## Contents' '' '1. [Background](#Background)' '1. [Prepration](#Preparation)' '1. [Data](#Data)' '    1. [Exploration and Transformation](#Exploration) ' '1. [Training Xgboost model using SageMaker](#Training)' '1. [Hosting the model](#Hosting)' '1. [Evaluating the model on test samples](#Evaluation)' '1. [Training a second Logistic Regression model using SageMaker](#Linear-Model)' '1. [Hosting the Second model](#Hosting:Linear-Learner)' '1. [Evaluating the model on test samples](#Prediction:Linear-Learner)' '1. [Combining the model results](#Ensemble)' '1. [Evaluating the combined model on test samples](#Evaluate-Ensemble)' '1. [Exentsions](#Extensions)' '' '---' '' '## Background' \"Quite often in pratical applications of Machine-Learning on predictive tasks one model doesn't suffice. Most of the prediction competitions typically require combining forecasts from multiple sources to get an improved forecast. By combining or averaging predictions from multiple sources/models we typically get an improved forecast. This happens as there is considerable uncertainty in the choice of the model and there is no one true model in many practical applications. It is therefore beneficial to combine predictions from different models. In the Bayesian literature this idea is referred as Bayesian Model Averaging http://www.stat.colostate.edu/~jah/papers/statsci.pdf and has been shown to work much better than just picking one model.\" '' '' 'This notebook presents an illustrative example to predict if a person makes over 50K a year based on information about their education work-experience geneder etc.' '' '* Preparing your _SageMaker_ notebook' '* Loading a dataset from S3 using SageMaker' '* Investigating and transforming the data so that it can be fed to _SageMaker_ algorithms' \"* Estimating a model using SageMaker's XGBoost (eXtreme Gradient Boosting) algorithm\" '* Hosting the model on SageMaker to make on-going predictions' \"* Estimating a second model using SageMaker's Linear Learner method\" '* Combining the predictions from both the models and evluating the combined prediction' '* Generating final predictions on the test data set' '' '' '---' '' '## Setup' '' \"Let's start by specifying:\" '' '* The SageMaker role arn used to give learning and hosting access to your data. See the documentation for how to create these.  Note if more than one role is required for notebook instances training and/or hosting please replace the boto call with a the appropriate full SageMaker role arn string.' '* The S3 bucket that you want to use for training and storing model objects.' '']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['# Fairness Linear Learner  in SageMaker' '' '1. [Introduction](#Introduction)' '    1. [Fairness definition](#fairness)' '2. [Prerequisites and Data](#pre_and_data)' '    1. [Initialize SageMaker](#initsagemaker)' '    2. [Download data](#download_data)' '    3. [Loading the data: Adult Dataset](#load_data) ' '    4. [Data inspection](#inspect_data) ' '    5. [Data encoding](#encode_data) ' '    6. [Data conversion and upload of the training data](#upload_data) ' '3. [Training the standard linear model](#train_linear_model)' '    1. [Accuracy and Fairness of the model](#performance_linear_model)' '4. [Changing the data to impose fairness](#impose_fairness)' '    1. [Train the model with the fair data](#train_fair_model)' '    2. [Accuracy and Fairness of the fair model](#performance_fair_model)' '    3. [Sanity check: performance on the training set](#performance_fair_model_train)' '5. [Distribution of the outputs](#distrib)' '    ' '' '' '## Introduction <a class=\"anchor\" id=\"Introduction\">' 'There have recently been concerns about bias in machine learning algorithms as a result of mimicking existing human prejudices. Nowadays several Machine Learning methods have strong social implications for example they are used to predict bank loans insurance rates or advertising. Unfortunately an algorithm that learns from historical data will naturally inherit the past biases. In this notebook we present how to overcome this problem by using SageMaker and Fair Algorithms in the context of Linear Learners.' '    ' 'We will start by introducing some of the concepts and math behind fairness then we will get ourselves setup to use these concepts in SageMaker download data train a model and finally apply our fairness concepts to adjust our model predictions appropriately.']\n",
      "['# Implementing a Recommender System with SageMaker MXNet and Gluon' '_**Making Video Recommendations Using Neural Networks and Embeddings**_' '' '--- ' '' '---' '' \"*This work is based on content from the [Cyrus Vahid's 2017 re:Invent Talk](https://github.com/cyrusmvahid/gluontutorials/blob/master/recommendations/MLPMF.ipynb)*\" '' '' '## Contents' '' '1. [Background](#Background)' '1. [Setup](#Setup)' '1. [Data](#Data)' '  1. [Explore](#Explore)' '  1. [Clean](#Clean)' '  1. [Prepare](#Prepare)' '1. [Train Locally](#Train-Locally)' '  1. [Define Network](#Define-Network)' '  1. [Set Parameters](#Set-Parameters)' '  1. [Execute](#Execute)' '1. [Train with SageMaker](#Train-with-SageMaker)' '  1. [Wrap Code](#Wrap-Code)' '  1. [Move Data](#Move-Data)' '  1. [Submit](#Submit)' '1. [Host](#Host)' '  1. [Evaluate](#Evaluate)' '1. [Wrap-up](#Wrap-up)' '' '---' '' '## Background' '' 'In many ways recommender systems were a catalyst for the current popularity of machine learning.  One of Amazon\\'s earliest successes was the \"Customers who bought this also bought...\" feature while the million dollar Netflix Prize spurred research raised public awareness and inspired numerous other data science competitions.' '' \"Recommender systems can utilize a multitude of data sources and ML algorithms and most combine various unsupervised supervised and reinforcement learning techniques into a holistic framework.  However the core component is almost always a model which which predicts a user's rating (or purchase) for a certain item based on that user's historical ratings of similar items as well as the behavior of other similar users.  The minimal required dataset for this is a history of user item ratings.  In our case we'll use 1 to 5 star ratings from over 2M Amazon customers on over 160K digital videos.  More details on this dataset can be found at its [AWS Public Datasets page](https://s3.amazonaws.com/amazon-reviews-pds/readme.html).\" '' 'Matrix factorization has been the cornerstone of most user-item prediction models.  This method starts with the large sparse user-item ratings in a single matrix where users index the rows and items index the columns.  It then seeks to find two lower-dimensional dense matrices which when multiplied together preserve the information and relationships in the larger matrix.' '' '![image](https://data-artisans.com/img/blog/factorization.svg)' '' \"Matrix factorization has been extended and genarlized with deep learning and embeddings.  These techniques allows us to introduce non-linearities for enhanced performance and flexibility.  This notebook will fit a neural network-based model to generate recommendations for the Amazon video dataset.  It will start by exploring our data in the notebook and even training a model on a sample of the data.  Later we'll expand to the full dataset and fit our model using a SageMaker managed training cluster.  We'll then deploy to an endpoint and check our method.\" '' '---' '' '## Setup' '' '_This notebook was created and tested on an ml.p2.xlarge notebook instance._' '' \"Let's start by specifying:\" '' '- The S3 bucket and prefix that you want to use for training and model data.  This should be within the same region as the Notebook Instance training and hosting.' '- The IAM role arn used to give training and hosting access to your data. See the documentation for how to create these.  Note if more than one role is required for notebook instances training and/or hosting please replace the `get_execution_role()` call with the appropriate full IAM role arn string(s).']\n",
      "['# Time Series Forecasting with Linear Learner' '_**Using Linear Regression to Forecast Monthly Demand**_' '' '---' '' '---' '' '## Contents' '' '1. [Background](#Background)' '1. [Setup](#Setup)' '1. [Data](#Data)' '1. [Train](#Train)' '1. [Host](#Host)' '  1. [Forecast](#Forecast)' '1. [Extensions](#Extensions)' '' '---' '' '## Background' '' 'Forecasting is potentially the most broadly relevant machine learning topic there is.  Whether predicting future sales in retail housing prices in real estate traffic in cities or patient visits in healthcare almost every industry could benefit from improvements in their forecasts.  There are numerous statistical methodologies that have been developed to forecast time-series data but still the process for developing forecasts tends to be a mix of objective statistics and subjective interpretations.' '' \"Properly modeling time-series data takes a great deal of care.  What's the right level of aggregation to model at?  Too granular and the signal gets lost in the noise too aggregate and important variation is missed.  Also what is the right cyclicality?  Daily weekly monthly?  Are there holiday peaks?  How should we weight recent versus overall trends?\" '' \"Linear regression with appropriate controls for trend seasonality and recent behavior remains a common method for forecasting stable time-series with reasonable volatility.  This notebook will build a linear model to forecast weekly output for US gasoline products starting in 1991 to 2005.  It will focus almost exclusively on the application.  For a more in-depth treatment on forecasting in general see [Forecasting: Principles & Practice](https://robjhyndman.com/uwafiles/fpp-notes.pdf).  In addition because our dataset is a single time-series we'll stick with SageMaker's Linear Learner algorithm.  If we had multiple related time-series we would use SageMaker's DeepAR algorithm which is specifically designed for forecasting.  See the [DeepAR Notebook](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/introduction_to_amazon_algorithms/deepar_synthetic/deepar_synthetic.ipynb) for more detail.\" '' '---' '' '## Setup' '' '_This notebook was created and tested on an ml.m4.xlarge notebook instance._' '' \"Let's start by specifying:\" '' '- The S3 bucket and prefix that you want to use for training and model data.  This should be within the same region as the Notebook Instance training and hosting.' '- The IAM role arn used to give training and hosting access to your data. See the documentation for how to create these.  Note if more than one role is required for notebook instances training and/or hosting please replace the boto regexp with a the appropriate full IAM role arn string(s).']\n",
      "['# An Introduction to SageMaker Neural Topic Model' '' '***Unsupervised representation learning and topic extraction using Neural Topic Model***' '' '1. [Introduction](#Introduction)' '1. [Data Preparation](#Data-Preparation)' '1. [Model Training](#Model-Training)' '1. [Model Hosting and Inference](#Model-Hosting-and-Inference)' '1. [Model Exploration](#Model-Exploration)']\n",
      "['# Document Embedding with Amazon SageMaker Object2Vec']\n",
      "['# Analyze US census data for population segmentation using Amazon SageMaker' '' '### https://aws.amazon.com/blogs/machine-learning/analyze-us-census-data-for-population-segmentation-using-amazon-sagemaker/ ###' '' '' '## Introduction' '' 'In the United States with the 2018 midterm elections approaching people are looking for more information about the voting process. This example notebook explores how we can apply machine learning (ML) to better integrate science into the task of understanding the electorate.' '' 'Typically for machine learning applications clear use cases are derived from labelled data. For example based on the attributes of a device such as its age or model number we can predict its likelihood of failure. We call this *supervised learning* because there is supervision or guidance towards predicting specific outcomes.' '' 'However in the real world there are often large data sets where there is no particular outcome to predict where clean labels are hard to define. It can be difficult to pinpoint exactly what the right outcome is to predict. This type of use case is often exploratory. It seeks to understand the makeup of a dataset and what natural patterns exist. This type of use case is known as *unsupervised learning*. One example of this is trying to group similar individuals together based on a set of attributes.' '' 'The use case this blog post explores is population segmentation. We have taken publicly available anonymized data from the US census on demographics by different US counties: https://factfinder.census.gov/faces/nav/jsf/pages/index.xhtml. (Note that this product uses the Census Bureau Data API but is not endorsed or certified by the Census Bureau.) The outcome of this analysis are natural groupings of similar counties in a transformed feature space. The cluster that a county belongs to can be leveraged to plan an election campaign for example to understand how to reach a group of similar counties by highlighting messages that resonate with that group. More generally this technique can be applied by businesses in customer or user segmentation to create targeted marketing campaigns. This type of analysis has the ability to uncover similarities that may not be obvious at face value- such as counties CA-Fresno and AZ- Yuma County being grouped together. While intuitively they differ in commonly-examined attributes such as population size and racial makeup they are more similar than different when viewed along axes such as the mix of employment type.' '' 'You can follow along in this sample notebook where you can run the code and interact with the data while reading through the blog post (link is shown above).' '' 'There are two goals for this exercise:' '' '1) Walk through a data science workflow using Amazon SageMaker for unsupervised learning using PCA and Kmeans modelling techniques.' '' '2) Demonstrate how users can access the underlying models that are built within Amazon SageMaker to extract useful model attributes. Often it can be difficult to draw conclusions from unsupervised learning so being able to access the models for PCA and Kmeans becomes even more important beyond simply generating predictions using the model.' '' 'The data science workflow has 4 main steps:' '' '1. [Loading the data from Amazon S3](#Step-1:-Loading-the-data-from-Amazon-S3)' '2. [Exploratory data analysis (EDA) - Data cleaning and exploration](#Step-2:-Exploratory-data-analysis-EDA---Data-cleaning-and-exploration)' '   1. [Cleaning the data](#a.-Cleaning-the-data)' '   2. [Visualizing the data](#b.-Visualizing-the-data)' '   3. [Feature engineering](#c.-Feature-engineering)' '3. [Data modelling](#Step-3:-Data-modelling)' '   1. [Dimensionality reduction](#a.-Dimensionality-reduction)' '   2. [Accessing the PCA model attributes](#b.-Accessing-the-PCA-model-attributes)' '   3. [Deploying the PCA model](#c.-Deploying-the-PCA-model)' '   4. [Population segmentation using unsupervised clustering](#d.-Population-segmentation-using-unsupervised-clustering)' '4. [Drawing conclusions from our modelling](#Step-4:-Drawing-conclusions-from-our-modelling)' '    1. [Accessing the KMeans model attributes](#a.-Accessing-the-KMeans-model-attributes)']\n",
      "['# Predicting Product Success When Review Data Is Available' '_**Using XGBoost to Predict Whether Sales will Exceed the \"Hit\" Threshold**_' '' '---' '' '---' '' '## Contents' '' '1. [Background](#Background)' '1. [Setup](#Setup)' '1. [Data](#Data)' '1. [Train](#Train)' '1. [Host](#Host)' '1. [Evaluation](#Evaluation)' '1. [Extensions](#Extensions)' '' '' '## Background' '' \"Word of mouth in the form of user reviews critic reviews social media comments etc. often can provide insights about whether a product ultimately will be a success. In the video game industry in particular reviews and ratings can have a large impact on a game's success. However not all games with bad reviews fail and not all games with good reviews turn out to be hits. To predict hit games machine learning algorithms potentially can take advantage of various relevant data attributes in addition to reviews.  \" '' 'For this notebook we will work with the dataset [Video Game Sales with Ratings](https://www.kaggle.com/rush4ratio/video-game-sales-with-ratings) from Kaggle. This dataset includes data from [Metacritic](http://www.metacritic.com/browse/games/release-date/available) and other sources with attributes for user reviews as well as critic reviews sales ESRB ratings among others. Both user reviews and critic reviews are in the form of ratings scores on a scale of 0 to 10 or 0 to 100. Although this is convenient a significant issue with the dataset is that it is relatively small.  ' '' 'Dealing with a small dataset such as this one is a common problem in machine learning. This problem often is compounded by imbalances between the classes in the small dataset. In such situations using an ensemble learner can be a good choice.  This notebook will focus on using XGBoost a popular ensemble learner to build a classifier to determine whether a game will be a hit. ' '' '## Setup' '' '' \"Let's start by:\" '' \"- Importing various Python libraries we'll need.\" '- Instantiate a SageMaker session for various tasks within this notebook and get the AWS Region.' '- Specifying a S3 bucket and bucket prefix to use for training and model data.' '- Defining an IAM role for S3 data access which is pulled in from the SageMaker notebook instance.']\n",
      "['# Customer Churn Prediction with XGBoost' '_**Using Gradient Boosted Trees to Predict Mobile Customer Departure**_' '' '---' '' '---' '' '## Contents' '' '1. [Background](#Background)' '1. [Setup](#Setup)' '1. [Data](#Data)' '1. [Train](#Train)' '1. [Compile](#Compile)' '1. [Host](#Host)' '  1. [Evaluate](#Evaluate)' '  1. [Relative cost of errors](#Relative-cost-of-errors)' '1. [Extensions](#Extensions)' '' '---' '' '## Background' '' '_This notebook has been adapted from an [AWS blog post](https://aws.amazon.com/blogs/ai/predicting-customer-churn-with-amazon-machine-learning/)_' '' 'Losing customers is costly for any business.  Identifying unhappy customers early on gives you a chance to offer them incentives to stay.  This notebook describes using machine learning (ML) for the automated identification of unhappy customers also known as customer churn prediction. ML models rarely give perfect predictions though so this notebook is also about how to incorporate the relative costs of prediction mistakes when determining the financial outcome of using ML.' '' 'We use an example of churn that is familiar to all of us–leaving a mobile phone operator.  Seems like I can always find fault with my provider du jour! And if my provider knows that I’m thinking of leaving it can offer timely incentives–I can always use a phone upgrade or perhaps have a new feature activated–and I might just stick around. Incentives are often much more cost effective than losing and reacquiring a customer.' '' '---' '' '## Setup' '' '_This notebook was created and tested on an ml.m4.xlarge notebook instance._' '' \"Let's start by specifying:\" '' '- The S3 bucket and prefix that you want to use for training and model data.  This should be within the same region as the Notebook Instance training and hosting.' '- The IAM role arn used to give training and hosting access to your data. See the documentation for how to create these.  Note if more than one role is required for notebook instances training and/or hosting please replace the boto regexp with a the appropriate full IAM role arn string(s).']\n",
      "['# Targeting Direct Marketing with Amazon SageMaker XGBoost' '_**Supervised Learning with Gradient Boosted Trees: A Binary Prediction Problem With Unbalanced Classes**_' '' '---' '' '---' '' '## Contents' '' '1. [Background](#Background)' '1. [Prepration](#Preparation)' '1. [Data](#Data)' '    1. [Exploration](#Exploration)' '    1. [Transformation](#Transformation)' '1. [Training](#Training)' '1. [Hosting](#Hosting)' '1. [Evaluation](#Evaluation)' '1. [Exentsions](#Extensions)' '' '---' '' '## Background' \"Direct marketing either through mail email phone etc. is a common tactic to acquire customers.  Because resources and a customer's attention is limited the goal is to only target the subset of prospects who are likely to engage with a specific offer.  Predicting those potential customers based on readily available information like demographics past interactions and environmental factors is a common machine learning problem.\" '' 'This notebook presents an example problem to predict if a customer will enroll for a term deposit at a bank after one or more phone calls.  The steps include:' '' '* Preparing your Amazon SageMaker notebook' '* Downloading data from the internet into Amazon SageMaker' '* Investigating and transforming the data so that it can be fed to Amazon SageMaker algorithms' '* Estimating a model using the Gradient Boosting algorithm' '* Evaluating the effectiveness of the model' '* Setting the model up to make on-going predictions' '' '---' '' '## Preparation' '' '_This notebook was created and tested on an ml.m4.xlarge notebook instance._' '' \"Let's start by specifying:\" '' '- The S3 bucket and prefix that you want to use for training and model data.  This should be within the same region as the Notebook Instance training and hosting.' '- The IAM role arn used to give training and hosting access to your data. See the documentation for how to create these.  Note if more than one role is required for notebook instances training and/or hosting please replace the boto regexp with a the appropriate full IAM role arn string(s).']\n",
      "['# Contextual Bandits with Parametric Actions -- Experimentation Mode']\n",
      "['# Contextual Bandits with Amazon SageMaker RL' '' 'We demonstrate how you can manage your own contextual multi-armed bandit workflow on SageMaker using the built-in [Vowpal Wabbit (VW)](https://github.com/VowpalWabbit/vowpal_wabbit) container to train and deploy contextual bandit models. We show how to train these models that interact with a live environment (using a simulated client application) and continuously update the model with efficient exploration.' '' '### Why Contextual Bandits?' '' 'Wherever we look to personalize content for a user (content layout ads search product recommendations etc.) contextual bandits come in handy. Traditional personalization methods collect a training dataset build a model and deploy it for generating recommendations. However the training algorithm does not inform us on how to collect this dataset especially in a production system where generating poor recommendations lead to loss of revenue. Contextual bandit algorithms help us collect this data in a strategic manner by trading off between exploiting known information and exploring recommendations which may yield higher benefits. The collected data is used to update the personalization model in an online manner. Therefore contextual bandits help us train a personalization model while minimizing the impact of poor recommendations.' '' '### What does this notebook contain?' '' 'To implement the exploration-exploitation strategy we need an iterative training and deployment system that: (1) recommends an action using the contextual bandit model based on user context (2) captures the implicit feedback over time and (3) continuously trains the model with incremental interaction data. In this notebook we show how to setup the infrastructure needed for such an iterative learning system. While the example demonstrates a bandits application these continual learning systems are useful more generally in dynamic scenarios where models need to be continually updated to capture the recent trends in the data (e.g. tracking fraud behaviors based on detection mechanisms or tracking user interests over time). ' '' 'In a typical supervised learning setup the model is trained with a SageMaker training job and it is hosted behind a SageMaker hosting endpoint. The client application calls the endpoint for inference and receives a response. In bandits the client application also sends the reward (a score assigned to each recommendation generated by the model) back for subsequent model training. These rewards will be part of the dataset for the subsequent model training. ']\n",
      "['# Training Batch Reinforcement Learning Policies with Amazon SageMaker RL' '' 'For many real-world problems the reinforcement learning (RL) agent needs to learn from historical data that was generated by some deployed policy. For example we may have historical data of experts playing games users interacting with a website or sensor data from a control system. This notebook shows an example of how to use batch RL to train a new policy from offline dataset[1]. We use gym `CartPole-v0` as a fake simulated system to generate offline dataset and the RL agents are trained using Amazon SageMaker RL.' '' 'We may want to evaluate the policy learned from historical data before deployment. Since simulators may not be available in all use cases we need to evaluate how good the learned policy by using held out historical data. This is called as off-policy evaluation or counterfactual evaluation. In this notebook we evaluate the policy during the training using several off-policy evaluation metrics. ' '' 'We can deploy the policy using SageMaker Hosting endpoint. However some use cases may not require a persistent serving endpoint with sub-second latency. Here we demonstrate how to deploy the policy with [SageMaker Batch Transform](https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform.html) where large volumes of input state features can be inferenced with high throughput.' '' 'Figure below shows an overview of the entire notebook.' '' '![Batch RL in Notebook](./batch_rl.png)']\n",
      "['# Cart-pole Balancing Model with Amazon SageMaker' '' '---' '## Introduction' '' \"In this notebook we'll start from the cart-pole balancing problem where a pole is attached by an un-actuated joint to a cart moving along a frictionless track. Instead of applying control theory to solve the problem this example shows how to solve the problem with reinforcement learning on Amazon SageMaker.\" '' '1. *Objective*: Prevent the pole from falling over' '2. *Environment*: The environment used in this exmaple is part of OpenAI Gym corresponding to the version of the cart-pole problem described by Barto Sutton and Anderson [1]' '3. *State*: Cart position cart velocity pole angle pole velocity at tip\\t' '4. *Action*: Push cart to the left push cart to the right' '5. *Reward*: Reward is 1 for every step taken including the termination step' '' 'References' '' '1. AG Barto RS Sutton and CW Anderson \"Neuronlike Adaptive Elements That Can Solve Difficult Learning Control Problem\" IEEE Transactions on Systems Man and Cybernetics 1983.']\n",
      "['# Distributed DeepRacer RL training with SageMaker and RoboMaker' '' '---' '## Introduction' '' '' \"In this notebook we will train a fully autonomous 1/18th scale race car using reinforcement learning using Amazon SageMaker RL and AWS RoboMaker's 3D driving simulator. [AWS RoboMaker](https://console.aws.amazon.com/robomaker/home#welcome) is a service that makes it easy for developers to develop test and deploy robotics applications.  \" '' 'This notebook provides a jailbreak experience of [AWS DeepRacer](https://console.aws.amazon.com/deepracer/home#welcome) giving us more control over the training/simulation process and RL algorithm tuning.' '' '![Training in Action](./deepracer-reinvent-track.jpg)' '' '' '---' '## How it works?  ' '' '![How training works](./training.png)' '' 'The reinforcement learning agent (i.e. our autonomous car) learns to drive by interacting with its environment e.g. the track by taking an action in a given state to maximize the expected reward. The agent learns the optimal plan of actions in training by trial-and-error through repeated episodes.  ' '  ' 'The figure above shows an example of distributed RL training across SageMaker and two RoboMaker simulation envrionments that perform the **rollouts** - execute a fixed number of episodes using the current model or policy. The rollouts collect agent experiences (state-transition tuples) and share this data with SageMaker for training. SageMaker updates the model policy which is then used to execute the next sequence of rollouts. This training loop continues until the model converges i.e. the car learns to drive and stops going off-track. More formally we can define the problem in terms of the following:  ' '' '1. **Objective**: Learn to drive autonomously by staying close to the center of the track.' '2. **Environment**: A 3D driving simulator hosted on AWS RoboMaker.' \"3. **State**: The driving POV image captured by the car's head camera as shown in the illustration above.\" '4. **Action**: Six discrete steering wheel positions at different angles (configurable)' '5. **Reward**: Positive reward for staying close to the center line; High penalty for going off-track. This is configurable and can be made more complex (for e.g. steering penalty can be added).']\n",
      "['# Game servers autopilot' 'Multiplayer game publishers often need to either over-provision resources or manually manage compute resource allocation when launching a large-scale worldwide game to avoid the long player-wait in the game lobby. Game publishers need to develop config and deploy tools that helped them to monitor and control the compute allocation.' '' 'This notebook demonstrates Game server autopilot a new machine learning-based example tool that makes it easy for game publishers to reduce the time players wait for compute to spawn while still avoiding compute over-provisioning. It also eliminates manual configuration decisions and changes publishers need to make and reduces the opportunity for human errors.' '' 'We heard from customers that optimizing compute resource allocation is not trivial. This is because it often takes substantial time to allocate and prepare EC2 instances. The time needed to spin up an EC2 instance and install game binaries and other assets must be learned and accounted for in the allocation algorithm. Ever-changing usage patterns require a model that is adaptive to emerging player habits. Finally the system also performs scale down in concert with new server allocation as needed.' '' 'We describe a reinforcement learning-based system that learns to allocate resources in response to player usage patterns. The hosted model directly predicts the required number of game-servers so as to allow EKS the time to allocate instances to reduce player wait time. The training process integrates with the game eco-system and requires minimal manual configuration.']\n",
      "['# HVAC with Amazon SageMaker RL' '' '---' '## Introduction' '' '' 'HVAC stands for Heating Ventilation and Air Conditioning and is responsible for keeping us warm and comfortable indoors.  HVAC takes up a whopping 50% of the energy in a building and accounts for 40% of energy use in the US [1 2]. Several control system optimizations have been proposed to reduce energy usage while ensuring thermal comfort.' '' 'Modern buildings collect data about the weather occupancy and equipment use. All of this can be used to optimize HVAC energy usage. Reinforcement Learning (RL) is a good fit because it can learn how to interact with the environment and identify strategies to limit wasted energy. Several recent research efforts have shown that RL can reduce HVAC energy consumption by 15-20% [3 4].' '' 'As training an RL algorithm in a real HVAC system can take time to converge as well as potentially lead to hazardous settings as the agent explores its state space we turn to a simulator to train the agent. [EnergyPlus](https://energyplus.net/) is an open source state of the art HVAC simulator from the US Department of Energy. We use a simple example with this simulator to showcase how we can train an RL model easily with Amazon SageMaker RL.' '' '<br>' '' '<img width=\"85%\" src=\"images/datacenter_env.png\" />' '' '<br>' '' '1. Objective: Control the data center HVAC system to reduce energy consumption while ensuring the room temperature stays within specified limits.' '2. Environment: We have a small single room datacenter that the HVAC system is cooling to ensure the compute equipment works properly. We will train our RL agent to control this HVAC system for one day subject to weather conditions in San Francisco.  The agent takes actions every 5 minutes for a 24 hour period. Hence the episode is a fixed 120 steps. ' '3. State: The outdoor temperature outdoor humidity and indoor room temperature.' '4. Action: The agent can set the heating and cooling setpoints. The cooling setpoint tells the HVAC system that it should start cooling the room if the room temperature goes above this setpoint. Likewise the HVAC systems starts heating if the room temperature goes below the heating setpoint.' '5. Reward: The rewards has two components which are added together with coefficients: ' '    1. It is proportional to the energy consumed by the HVAC system.' '    2. It gets a large penalty when the room temperature exceeds pre-specified lower or upper limits (as defined in `data_center_env.py`).' '' 'References' '' '1. [sciencedirect.com](https://www.sciencedirect.com/science/article/pii/S0378778807001016)' '2. [environment.gov.au](https://www.environment.gov.au/system/files/energy/files/hvac-factsheet-energy-breakdown.pdf)' '3. Wei Tianshu Yanzhi Wang and Qi Zhu. \"Deep reinforcement learning for building hvac control.\" In Proceedings of the 54th Annual Design Automation Conference 2017 p. 22. ACM 2017.' '4. Zhang Zhiang and Khee Poh Lam. \"Practical implementation and evaluation of deep reinforcement learning control for a radiant heating system.\" In Proceedings of the 5th Conference on Systems for Built Environments pp. 148-157. ACM 2018.']\n",
      "['# Solving Knapsack Problem with Amazon SageMaker RL']\n",
      "['# Cart-pole Balancing Model with Amazon SageMaker on SageMaker Managed Spot Training' '' 'The example here is almost the same as [Cart-pole Balancing Model with Amazon SageMaker](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/reinforcement_learning/rl_cartpole_coach/rl_cartpole_coach_gymEnv.ipynb).' '' 'This notebook tackles the exact same problem with the same solution but it has been modified to be able to run using SageMaker Managed Spot infrastructure. SageMaker Managed Spot uses [EC2 Spot Instances](https://aws.amazon.com/ec2/spot/) to run Training at a lower cost. In this notebook the RLEstimator function has two additional arguments `train_use_spot_instances` and `train_max_wait` to call the training ' '' 'Please read the original notebook and try it out to gain an understanding of the ML use-case and how it is being solved. We will not delve into that here in this notebook.' '' 'The explanations below has been lifted verbatim from [Cart-pole Balancing Model with Amazon SageMaker](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/reinforcement_learning/rl_cartpole_coach/rl_cartpole_coach_gymEnv.ipynb).' '' '' '---' '## Introduction' '' \"In this notebook we'll start from the cart-pole balancing problem where a pole is attached by an un-actuated joint to a cart moving along a frictionless track. Instead of applying control theory to solve the problem this example shows how to solve the problem with reinforcement learning on Amazon SageMaker.\" '' '1. *Objective*: Prevent the pole from falling over' '2. *Environment*: The environment used in this exmaple is part of OpenAI Gym corresponding to the version of the cart-pole problem described by Barto Sutton and Anderson [1]' '3. *State*: Cart position cart velocity pole angle pole velocity at tip\\t' '4. *Action*: Push cart to the left push cart to the right' '5. *Reward*: Reward is 1 for every step taken including the termination step' '' 'References' '' '1. AG Barto RS Sutton and CW Anderson \"Neuronlike Adaptive Elements That Can Solve Difficult Learning Control Problem\" IEEE Transactions on Systems Man and Cybernetics 1983.']\n",
      "['# Mountain Car with Amazon SageMaker RL' '' '---' '' \"Mountain Car is a classic control Reinforcement Learning problem that was first introduced by A. Moore in 1991 [1]. An under-powered car is tasked with climbing a steep mountain and is only successful when it reaches the top. Luckily there's another mountain on the opposite side which can be used to gain momentum and launch the car to the peak. It can be tricky to find this optimal solution due to the sparsity of the reward. Complex exploration strategies can be used to incentivise exploration of the mountain but to keep things simple in this example we extend the amount of time in each episode from Open AI Gym's default of 200 environment steps to 10000 steps showing how to customise environments. We consider two variants in this example: `PatientMountainCar` for discrete actions and `PatientContinuousMountainCar` for continuous actions.\" '' '<img src=\"./successful_policy.gif\">' '' '### `PatientMountainCar`' '' ' > 1. Objective: Get the car to the top of the right hand side mountain.' \" > 2. Environment(s): Open AI Gym's `MountainCar-v0` that is extended to 10000 steps per episode.\" \" > 3. State: Car's horizontal position and velocity (can be negative).\" ' > 4. Action: Direction of push (left nothing or right).' ' > 5. Reward: -1 for every environment step until success which incentivises quick solutions.' ' ' ' ' '### `PatientContinuousMountainCar`' '' ' > 1. Objective: Get the car to the top of the right hand side mountain.' \" > 2. Environment(s): Open AI Gym's `MountainCarContinuous-v0` that is extended to 10000 steps per episode.\" \" > 3. State: Car's horizontal position and velocity (can be negative).\" ' > 4. Action: Mmagnitude of push (if negative push to left if positive push to right).' ' > 5. Reward: +100 for reaching top of the right hand side mountain minus the squared sum of actions from start to end.' '' '' '[1] A. Moore Efficient Memory-Based Learning for Robot Control PhD thesis University of Cambridge November 1990.']\n",
      "['# Distributed Neural Network Compression using Reinforcement Learning' '------------------------------------------------' '## Introduction' 'In this notebook we demonstrate how to compress a neural network (Resnet-18) using reinforcement learning. The work in this notebook is based on [1] even though heavily adapted to work with Amazon SageMaker RL. The following are the key highlights of AWS SageMaker RL demonstrated in this notebook.' '1. A custom environment for neural network compression.' '2. Usage of the Ray container in SageMaker with distributed training.' '3. Using tensorflow within the environment in the container.' '4. Network compression through RL.' '' '[1] [Ashok Anubhav Nicholas Rhinehart Fares Beainy and Kris M. Kitani. \"N2N learning: network to network compression via policy gradient reinforcement learning.\" arXiv preprint arXiv:1709.06030 (2017)](https://arxiv.org/abs/1709.06030).' '' 'The RL problem here can be defined as follows: ' '' '**Objective:** Search and find the smallest possible network architecture from a pre-trained network architecture while producing the best accuracy possible. ' '' \"**Environment:** A custom developed environment that accepts a Boolean array of layers to remove from the RL agent and produces an observation that is some description of every layer in the network. This environment is sub-classed from OpenAI Gym's environment. It can be found in the [environment file](./src/environment.py).\" '' '**State:** For every layer in the network there is a $1 \\\\times 8$ array of floats. In Resnet-18 there are 40 removable layers.' '' \"**Action:** A boolean array one for each layer. ```False``` implies don't remove the layer and ```True``` implies remove the layer.\" '' \"**Reward:** Consider $C = 1 - \\\\frac{M_s}{M}$ where $C$ is the compression ratio $M_s$ is the number of parameters in a network that the RL agent explores $M$ is the number of parameters in the master network to be compressed. The reward is $r = \\\\frac{CA_s}{(2-C)A}$ where $A_s$ is the accuracy of the network that the RL agent explores and $A$ is the accuracy of the master network. If the explored network can't even train or is out-of-memory the reward is $r = -1$.\" '' '## Attribution' '' '1. Cifar10 Dataset: We use the cifar10 dataset in this notebook [2] to conduct our experiments.' '2. We rely on the open-source codebase from [tensorflow/models repository](https://github.com/tensorflow/models) released under Apache 2.0 to build the backend resnet models. Please refer to the [license](https://github.com/tensorflow/models/blob/master/LICENSE) of that repository.' '' '[2] [Learning Multiple Layers of Features from Tiny Images Alex Krizhevsky 2009.](https://www.cs.toronto.edu/~kriz/cifar.html)' '' '## Pre-requisites ' '' '### Roles and permissions' \"To get started we'll import the sagemaker python library and setup the permissions and IAM role.\"]\n",
      "['# Distributed Object Tracker RL training with Amazon SageMaker RL and RoboMaker' '' '---' '## Introduction' '' '' 'In this notebook we show you how you can apply reinforcement learning to train a Robot (named Waffle) track and follow another Robot (named Burger) by using the [Clipped PPO](https://coach.nervanasys.com/algorithms/policy_optimization/cppo/index.html)  algorithm implementation in [coach](https://ai.intel.com/r-l-coach/) toolkit [Tensorflow](https://www.tensorflow.org/) as the deep learning framework and [AWS RoboMaker](https://console.aws.amazon.com/robomaker/home#welcome) as the simulation environment.' '' '![Training in Action](./object-tracker-world.jpg)' '' '---' '## How it works?  ' '' '' 'The reinforcement learning agent (i.e. Waffle) learns to track and follow Burger by interacting with its environment e.g. visual world around it by taking an action in a given state to maximize the expected reward. The agent learns the optimal plan of actions in training by trial-and-error through multiple episodes.  ' '  ' 'This notebook shows an example of distributed RL training across SageMaker and two RoboMaker simulation envrionments that perform the **rollouts** - execute a fixed number of episodes using the current model or policy. The rollouts collect agent experiences (state-transition tuples) and share this data with SageMaker for training. SageMaker updates the model policy which is then used to execute the next sequence of rollouts. This training loop continues until the model converges i.e. the car learns to drive and stops going off-track. More formally we can define the problem in terms of the following:  ' '' '1. **Objective**: Learn to drive toward and reach the Burger.' '2. **Environment**: A simulator with Burger hosted on AWS RoboMaker.' \"3. **State**: The driving POV image captured by the Waffle's head camera.\" '4. **Action**: Six discrete steering wheel positions at different angles (configurable)' '5. **Reward**: Reward is inversely proportional to distance from Burger. Waffle gets more reward as it get closer to the Burger. It gets a reward of 0 if the action takes it away from Burger. ' '' '---' '## Prequisites' '### Imports' \"To get started we'll import the Python libraries we need set up the environment with a few prerequisites for permissions and configurations.\" '' 'You can run this notebook from your local host or from a SageMaker notebook instance. In both of these scenarios you can run the following to launch a training job on `SageMaker` and a simulation job on `RoboMaker`.']\n",
      "['# Portfolio Management with Amazon SageMaker RL']\n",
      "['# Autoscaling a service with Amazon SageMaker' '' 'This notebook shows an example of how to use reinforcement learning technique to address a very common problem in production operation of software systems: scaling a production service by adding and removing resources (e.g. servers or EC2 instances) in reaction to dynamically changing load. This example is a simple toy demonstrating how one might begin to address this real and challenging problem. We build up a fake simulated system with daily and weekly variations and occassional spikes. It also has a delay between when new resources are requested and when they become available for serving requests. The customized environment is constructed using Open AI gym and the RL agents are trained using Amazon SageMaker.']\n",
      "['# Solving Bin Packing Problem with Amazon SageMaker RL' '' 'This notebook shows an example of how to use reinforcement learning to solve the online stochastic bin packing problem. In the classic version of bin packing we are given items of different sizes and need to pack them into as few bins as possible. In the online stochastic version items arrive one at a time and item sizes are drawn from an unknown distribution. The task is to find a feasible packing that minimizes the number of bins used to pack all of the items that arrive within the time horizon.']\n",
      "['# Solving Multi-Period Newsvendor Problem with Amazon SageMaker RL' '' 'This notebook shows an example of how to use reinforcement learning to solve a version of online stochastic Newsvendor problem. This problem is well-studied in inventory management wherein one must decide on an ordering decision (how much of an item to purchase from a supplier) to cover a single period of uncertain demand. The objective is to trade-off the various costs incurred and revenues achieved during the period usually consisting of sales revenue purchasing and holding costs loss' 'of goodwill in the case of missed sales and the terminal salvage value of unsold items.']\n",
      "['# Solving Vehicle Routing Problem with Amazon SageMaker RL']\n",
      "['# Roboschool simulations of physical robotics with Amazon SageMaker' '' '---' '## Introduction' '' 'Roboschool is an [open source](https://github.com/openai/roboschool/tree/master/roboschool) physics simulator that is commonly used to train RL policies for simulated robotic systems.  Roboschool provides 3D visualization of physical systems with multiple joints in contact with each other and their environment.' '' 'This notebook will show how to install Roboschool into the SageMaker RL container and train pre-built robotics applications that are included with Roboschool.']\n",
      "['## Tune hyperparameters for your RL training job' \"This notebook shows how to use SageMaker's Automatic Model Tuning functionality to optimize the training of an RL model using the Roboschool environment.  Note that the bayesian hyperparameter optimization algorithm used in SageMaker Automatic Model Tuning expects a stable objective function which means that running the same training job multiple times with the same configuration should give about the same result.  Some RL training processes are highly non-deterministic such that the same configuration sometimes performs well and sometimes fails to train.  These environments will not work well with the automatic model tuner.  However the Roboschool environments are fairly stable and tend to perform similarly given the same hyperparameters.  So the hyperparameter tuner should work well here. \"]\n",
      "['# Training Roboschool agents using distributed RL training across multiple nodes with Amazon SageMaker']\n",
      "['# Roboschool simulations training with stable baselines on Amazon SageMaker RL']\n",
      "['# Learning Tic-Tac-Toe with Reinforcement Learning' '**_Train with SageMaker RL and evaluate interactively within the notebook_**' '' '---' '' '---' '' '' '## Outline' '' '1. [Overview](#Overview)' '1. [Setup](#Setup)' '1. [Code](#Code)' '  1. [Environment](#Environment)' '  1. [Preset](#Preset)' '  1. [Launcher](#Launcher)' '1. [Train](#Train)' '1. [Deploy](#Deploy)' '  1. [Inference](#Inference)' '1. [Play](#Play)' '1. [Wrap Up](#Wrap-Up)' '' '---' '' '## Overview' '' 'Tic-tac-toe is one of the first games children learn to play and was one of the [first computer games ever](https://en.wikipedia.org/wiki/OXO).  Optimal play through exhaustive search is relatively straightforward however approaching with a reinforcement learning agent can be educational.' '' 'This notebook shows how to train a reinforcement learning agent with SageMaker RL and then play locally and interactively within the notebook.  Unlike SageMaker local mode this method does not require a docker container to run locally instead using an endpoint and integration with a small Jupyter app (*Note this app does not work in JupyterLab*).' '' '---' '' '## Setup' '' \"Let's start by defining our S3 bucket and and IAM role.\"]\n",
      "['# Traveling Salesman Problem with Reinforcement Learning']\n",
      "['# Tensor analysis using Amazon SageMaker Debugger' '' 'Looking at the distributions of activation inputs/outputs gradients and weights per layer can give useful insights. For instance it helps to understand whether the model runs into problems like neuron saturation whether there are layers in your model that are not learning at all or whether the network consists of too many layers etc. ' '' 'The following animation shows the distribution of gradients of a convolutional layer from an example application  as the training progresses. We can see that it starts as Gaussian distribution but then becomes more and more narrow. We can also see that the range of gradients starts very small (order of $1e-5$) and becomes even tinier as training progresses. If tiny gradients are observed from the start of training it is an indication that we should check the hyperparameters of our model. ' '' '![](images/example.gif)' '' 'In this notebook we will train a poorly configured neural network and use Amazon SageMaker Debugger with custom rules to aggregate and analyse specific tensors. Before we proceed let us install the smdebug binary which allows us to perform interactive analysis in this notebook. After installing it please restart the kernel and when you come back skip this cell.' '' '### Installing smdebug']\n",
      "['# Visualizing Debugging Tensors of MXNet training']\n",
      "['## Using SageMaker debugger to monitor autoencoder model training' '' 'This notebook will train a convolutional autoencoder model on MNIST dataset and use SageMaker debugger to monitor key metrics in realtime. An autoencoder consists of an encoder that downsamples input data and a decoder that tries to reconstruct the original input. In this notebook we will use an autoencoder with the following architecture:' '```' '--------------------------------------------------------------------------------' '        Layer (type)                                Output Shape         Param #' '================================================================================' '               Input                              (1 1 28 28)               0' '        Activation-1  <Symbol hybridsequential0_conv0_relu_fwd>                0' '        Activation-2                             (1 32 24 24)               0' '            Conv2D-3                             (1 32 24 24)             832' '         MaxPool2D-4                             (1 32 12 12)               0' '        Activation-5  <Symbol hybridsequential0_conv1_relu_fwd>                0' '        Activation-6                               (1 32 8 8)               0' '            Conv2D-7                               (1 32 8 8)           25632' '         MaxPool2D-8                               (1 32 4 4)               0' '             Dense-9                                     (1 20)           10260' '       Activation-10  <Symbol hybridsequential1_dense0_relu_fwd>               0' '       Activation-11                                    (1 512)               0' '            Dense-12                                    (1 512)           10752' '     HybridLambda-13                               (1 32 8 8)               0' '       Activation-14  <Symbol hybridsequential1_conv0_relu_fwd>                0' '       Activation-15                             (1 32 12 12)               0' '  Conv2DTranspose-16                             (1 32 12 12)           25632' '     HybridLambda-17                             (1 32 24 24)               0' '       Activation-18  <Symbol hybridsequential1_conv1_sigmoid_fwd>             0' '       Activation-19                              (1 1 28 28)               0' '  Conv2DTranspose-20                              (1 1 28 28)             801' 'ConvolutionalAutoencoder-21                       (1 1 28 28)               0' '================================================================================' 'Parameters in forward computation graph duplicate included' '   Total params: 73909' '   Trainable params: 73909' '   Non-trainable params: 0' 'Shared params in forward computation graph: 0' 'Unique parameters in model: 73909' '--------------------------------------------------------------------------------' '```' '' 'The bottleneck layer forces the autoencoder to learn a compressed representation (latent variables) of the dataset. Visualizing the latent space helps to understand what the autoencoder is learning. We can check if the model is training well by checking ' '- reconstructed images (autoencoder output)' '- t-Distributed Stochastic Neighbor Embedding (t-SNE) of the latent variables ' '' 't-SNE maps high dimensional data into a 2- or 3-dimensional space. Following animation shows those emebeddings of latent variables while the training progresses. Each cluster represents a class (0-9) of the MNIST training dataset. Over time the autoencoder becomes better in separating those classes.  ' '<img src=\"images/tsne.gif\" alt=\"drawing\" width=\"600\"/> ']\n",
      "['## Using SageMaker debugger to monitor attentions in BERT model training' '' '[BERT](https://arxiv.org/abs/1810.04805) is a deep bidirectional transformer model that achieves state-of the art results in NLP tasks like question answering text classification and others.' 'In this notebook we will use [GluonNLP](https://gluon-nlp.mxnet.io/) to finetune a pretrained BERT model on the [Stanford Question and Answering dataset](https://web.stanford.edu/class/cs224n/reports/default/15848195.pdf) and we will use [SageMaker Debugger](https://docs.aws.amazon.com/sagemaker/latest/dg/train-debugger.html) to monitor model training in real-time. ' '' 'The paper [Visualizing Attention in Transformer-Based Language Representation Models [1]](https://arxiv.org/pdf/1904.02679.pdf) shows that plotting attentions and individual neurons in the query and key vectors can help to identify causes of incorrect model predictions.' 'With SageMaker Debugger we can easily retrieve those tensors and plot them in real-time as training progresses which may help to understand what the model is learning. ' '' 'The animation below shows the attention scores of the first 20 input tokens for the first 10 iterations in the training.' '' \"<img src='images/attention_scores.gif' width='350' /> \" 'Fig. 1: Attention scores of the first head in the 7th layer ' '' '[1] *Visualizing Attention in Transformer-Based Language Representation Models*:  Jesse Vig 2019 1904.02679 arXiv']\n",
      "['## Using SageMaker debugger to visualize class activation maps in CNNs' '' 'This notebook will demonstrate how to use SageMaker debugger to plot class activations maps for image classification models. A class activation map (saliency map) is a heatmap that highlights the regions in the image that lead the model to make a certain prediction. This is especially useful:  ' '' '1. if the model makes a misclassification and it is not clear why; ' '' '2. or to determine if the model takes all important features of an object into account ' '' 'In this notebook we will train a [ResNet](https://arxiv.org/abs/1512.03385) model on the [German Traffic Sign Dataset](http://benchmark.ini.rub.de/?section=gtsrb&subsection=news) and we will use SageMaker debugger to plot class activation maps in real-time.' '' 'The following animation shows the saliency map for a particular traffic sign as training progresses. Red highlights the regions with high activation leading to the prediction blue indicates low activation that are less relevant for the prediction. ' '' 'In the beginning the model will do a lot of mis-classifications as it focuses on the wrong image regions e.g. the obstacle in the lower left corner. As training progresses the focus shifts to the center of the image and the model becomes more and more confident in predicting the class 3 (which is the correct class).' '' '![](images/example.gif)' '' 'There exist several methods to generate saliency maps e.g. [CAM](http://cnnlocalization.csail.mit.edu/) [GradCAM](https://arxiv.org/abs/1610.02391). The paper [Full-Gradient Representation for Neural Network Visualization [1]](https://arxiv.org/abs/1905.00780) proposes a new method which produces state of the art results. It requires intermediate features and their biases. With SageMaker debugger we can easily retrieve these tensors.' '' '[1] *Full-Gradient Representation for Neural Network Visualization*: Suraj Srinivas and Francois Fleuret 2019 1905.00780 arXiv']\n",
      "['# Debugging Amazon SageMaker training jobs in real time with Debugger']\n",
      "['# Enable Spot Training with Amazon SageMaker Debugger' '' 'Amazon SageMaker Debugger is a new capability of Amazon SageMaker that allows debugging machine learning training. ' \"It lets you go beyond just looking at scalars like losses and accuracies during training and gives you full visibility into all tensors 'flowing through the graph' during training. Amazon SageMaker Debugger helps you to monitor your training in near real time using rules and would provide you alerts once it has detected inconsistency in training flow.\" '' 'Using Amazon SageMaker Debugger is a two step process: Saving tensors and Analysis.' '' '### Saving tensors' 'Tensors define the state of the training job at any particular instant in its lifecycle. Debugger exposes a library which allows you to capture these tensors and save them for analysis.' '' '### Analysis' 'There are two ways to get to tensors and run analysis on them. One way is to use concept called ***Rules***. For more information about a rules-based approach to analysis see [Rules](https://github.com/awslabs/sagemaker-debugger/blob/master/docs/analysis.md#Rules). You can also perform interactive analysis in a notebook. Please refer to our other notebooks on how to do that.' '' '## Spot Training' 'This notebook talks about how Amazon SageMaker Debugger feature can also be used with Spot Training. For more information related to spot training in Amazon SageMaker please see [Spot Training](https://docs.aws.amazon.com/sagemaker/latest/dg/model-managed-spot-training.html).' '' 'The examples uses a small gluon CNN model and trains it on the FashionMNIST dataset. If during the training spot instance terminates the training and analysis of tensors will continue from the last saved checkpoint.']\n",
      "['# Using Amazon SageMaker Debugger with your own PyTorch container']\n",
      "['## Using SageMaker Debugger and SageMaker Experiments for iterative model pruning' '' \"This notebook demonstrates how we can use [SageMaker Debugger](https://docs.aws.amazon.com/sagemaker/latest/dg/train-debugger.html) and [SageMaker Experiments](https://docs.aws.amazon.com/sagemaker/latest/dg/experiments.html) to perform iterative model pruning. Let's start first with a quick introduction into model pruning.\" '' 'State of the art deep learning models consist of millions of parameters and are trained on very large datasets. For transfer learning we take a pre-trained model and fine-tune it on a new and typically much smaller dataset. The new dataset may even consist of different classes so the model is basically learning a new task. This process allows us to quickly achieve state of the art results without having to design and train our own model from scratch. However it may happen that a much smaller and simpler model would also perform well on our dataset. With model pruning we identify the importance of weights during training and remove the weights that are contributing very little to the learning process. We can do this in an iterative way where we remove a small percentage of weights in each iteration. Removing means to eliminate the entries in the tensor so its size shrinks.' '' 'We use SageMaker Debugger to get weights activation outputs and gradients during training. These tensors are used to compute the importance of weights. We will use SageMaker Experiments to keep track of each pruning iteration: if we prune too much we may degrade model accuracy so we will monitor number of parameters versus validation accuracy. ']\n",
      "['## Using SageMaker Debugger and SageMaker Experiments for iterative model pruning' '' \"This notebook demonstrates how we can use [SageMaker Debugger](https://docs.aws.amazon.com/sagemaker/latest/dg/train-debugger.html) and [SageMaker Experiments](https://docs.aws.amazon.com/sagemaker/latest/dg/experiments.html) to perform iterative model pruning. Let's start first with a quick introduction into model pruning.\" '' 'State of the art deep learning models consist of millions of parameters and are trained on very large datasets. For transfer learning we take a pre-trained model and fine-tune it on a new and typically much smaller dataset. The new dataset may even consist of different classes so the model is basically learning a new task. This process allows us to quickly achieve state of the art results without having to design and train our own model from scratch. However it may happen that a much smaller and simpler model would also perform well on our dataset. With model pruning we identify the importance of weights during training and remove the weights that are contributing very little to the learning process. We can do this in an iterative way where we remove a small percentage of weights in each iteration. Removing means to eliminate the entries in the tensor so its size shrinks.' '' 'We use SageMaker Debugger to get weights activation outputs and gradients during training. These tensors are used to compute the importance of weights. We will use SageMaker Experiments to keep track of each pruning iteration: if we prune too much we may degrade model accuracy so we will monitor number of parameters versus validation accuracy. ']\n",
      "['# Amazon SageMaker Debugger - Reacting to Cloudwatch Events from Rules' '[Amazon SageMaker](https://aws.amazon.com/sagemaker/) is managed platform to build train and host maching learning models. Amazon SageMaker Debugger is a new feature which offers the capability to debug machine learning models during training by identifying and detecting problems with the models in near real time. ' '' \"In this notebook we'll show you how you can react off rule triggers and take some action e.g. stop the training job through CloudWatch Events.\" '' '## How does Amazon SageMaker Debugger work?' '' \"Amazon SageMaker Debugger lets you go beyond just looking at scalars like losses and accuracies during training and gives you full visibility into all tensors 'flowing through the graph' during training. Furthermore it helps you monitor your training in near real time using rules and provides you alerts once it has detected inconsistency in training flow.\" '' '### Concepts' '* **Tensors**: These represent the state of the training network at intermediate points during its execution' '* **Debug Hook**: Hook is the construct with which Amazon SageMaker Debugger looks into the training process and captures the tensors requested at the desired step intervals' '* **Rule**: A logical construct implemented as Python code which helps analyze the tensors captured by the hook and report anomalies if at all' '' \"With these concepts in mind let's understand the overall flow of things that Amazon SageMaker Debugger uses to orchestrate debugging.\" '' '### Saving tensors during training' '' 'The tensors captured by the debug hook are stored in the S3 location specified by you. There are two ways you can configure Amazon SageMaker Debugger to save tensors:' '' '#### With no changes to your training script' \"If you use one of the SageMaker provided [Deep Learning Containers](https://docs.aws.amazon.com/sagemaker/latest/dg/pre-built-containers-frameworks-deep-learning.html) for 1.15 then you don't need to make any changes to your training script for the tensors to be stored. SageMaker Debugger will use the configuration you provide through the SageMaker SDK's Tensorflow `Estimator` when creating your job to save the tensors in the fashion you specify. You can review the script we are going to use at [src/mnist_zerocodechange.py](src/mnist_zerocodechange.py). You will note that this is an untouched TensorFlow script which uses the Estimator interface. Please note that SageMaker Debugger only supports `tf.keras` `tf.Estimator` and `tf.MonitoredSession` interfaces. Full description of support is available at [SageMaker Debugger with TensorFlow ](https://github.com/awslabs/sagemaker-debugger/tree/master/docs/tensorflow.md)\" '' '#### Orchestrating your script to store tensors' \"For other containers you need to make couple of lines of changes to your training script. SageMaker Debugger exposes a library `smdebug` which allows you to capture these tensors and save them for analysis. It's highly customizable and allows to save the specific tensors you want at different frequencies and possibly with other configurations. Refer [DeveloperGuide](https://github.com/awslabs/sagemaker-debugger/tree/master/docs) for details on how to use SageMaker Debugger library with your choice of framework in your training script. Here we have an example script orchestrated at [src/mnist_byoc](src/mnist_byoc.py). You also need to ensure that your container has the `smdebug` library installed.\" '' '### Analysis of tensors' '' \"Once the tensors are saved Amazon SageMaker Debugger can be configured to run debugging ***Rules*** on them. At a very broad level a rule is Python code used to detect certain conditions during training. Some of the conditions that a data scientist training an algorithm may care about are monitoring for gradients getting too large or too small detecting overfitting and so on. Sagemaker Debugger comes pre-packaged with certain built-in rules. Users can write their own rules using the Sagemaker Debugger APIs. You can also analyze raw tensor data outside of the Rules construct in say a Sagemaker notebook using Amazon Sagemaker Debugger's full set of APIs. Please refer [Analysis Developer Guide](https://github.com/awslabs/sagemaker-debugger/blob/master/docs/api.md) for more on these APIs.\"]\n",
      "['# Amazon SageMaker Debugger - Using built-in rule' '[Amazon SageMaker](https://aws.amazon.com/sagemaker/) is managed platform to build train and host maching learning models. Amazon SageMaker Debugger is a new feature which offers the capability to debug machine learning models during training by identifying and detecting problems with the models in near real-time. ' '' \"In this notebook you'll be looking at how to use a SageMaker provided built in rule during a TensorFlow training job.\" '' '## How does Amazon SageMaker Debugger work?' '' \"Amazon SageMaker Debugger lets you go beyond just looking at scalars like losses and accuracies during training and gives you full visibility into all tensors 'flowing through the graph' during training. Furthermore it helps you monitor your training in near real-time using rules and provides you alerts once it has detected inconsistency in training flow.\" '' '### Concepts' '* **Tensors**: These represent the state of the training network at intermediate points during its execution' '* **Debug Hook**: Hook is the construct with which Amazon SageMaker Debugger looks into the training process and captures the tensors requested at the desired step intervals' '* **Rule**: A logical construct implemented as Python code which helps analyze the tensors captured by the hook and report anomalies if at all' '' \"With these concepts in mind let's understand the overall flow of things that Amazon SageMaker Debugger uses to orchestrate debugging\" '' '### Saving tensors during training' '' 'The tensors captured by the debug hook are stored in the S3 location specified by you. There are two ways you can configure Amazon SageMaker Debugger to save tensors:' '' '#### With no changes to your training script' \"If you use one of Amazon SageMaker provided [Deep Learning Containers](https://docs.aws.amazon.com/sagemaker/latest/dg/pre-built-containers-frameworks-deep-learning.html) for 1.15 then you don't need to make any changes to your training script for the tensors to be stored. Amazon SageMaker Debugger will use the configuration you provide through Amazon SageMaker SDK's Tensorflow `Estimator` when creating your job to save the tensors in the fashion you specify. You can review the script we are going to use at [src/mnist_zerocodechange.py](src/mnist_zerocodechange.py). You will note that this is an untouched TensorFlow script which uses the `tf.estimator` interface. Please note that Amazon SageMaker Debugger only supports `tf.keras` `tf.Estimator` and `tf.MonitoredSession` interfaces. Full description of support is available at [Amazon SageMaker Debugger with TensorFlow ](https://github.com/awslabs/sagemaker-debugger/tree/master/docs/tensorflow.md)\" '' '#### Orchestrating your script to store tensors' \"For other containers you need to make couple of lines of changes to your training script. The Amazon SageMaker Debugger exposes a library `smdebug` which allows you to capture these tensors and save them for analysis. It's highly customizable and allows to save the specific tensors you want at different frequencies and possibly with other configurations. Refer [DeveloperGuide](https://github.com/awslabs/sagemaker-debugger/tree/master/docs) for details on how to use the Debugger library with your choice of framework in your training script. Here we have an example script orchestrated at [src/mnist_byoc](src/mnist_byoc.py). You also need to ensure that your container has the `smdebug` library installed.\" '' '### Analysis of tensors' '' \"Once the tensors are saved Amazon SageMaker Debugger can be configured to run debugging ***Rules*** on them. At a very broad level a rule is python code used to detect certain conditions during training. Some of the conditions that a data scientist training an algorithm may care about are monitoring for gradients getting too large or too small detecting overfitting and so on. Amazon Sagemaker Debugger will come pre-packaged with certain first-party (1P) rules. Users can write their own rules using Amazon Sagemaker Debugger APIs. You can also analyze raw tensor data outside of the Rules construct in say a Sagemaker notebook using Amazon Sagemaker Debugger's full set of APIs. This notebook will show you how to use a built in SageMaker Rule with your training job as well as provide a sneak peak into these APIs for interactive exploration. Please refer [Analysis Developer Guide](https://github.com/awslabs/sagemaker-debugger/blob/master/docs/api.md) for more on these APIs.\" '' '## Setup' '' 'Follow this one time setup to get your notebook up and running to use Amazon SageMaker Debugger. This is only needed because we plan to perform interactive analysis using this library in the notebook. ']\n",
      "['# Amazon SageMaker - Debugging with custom rules' '[Amazon SageMaker](https://aws.amazon.com/sagemaker/) is managed platform to build train and host maching learning models. Amazon SageMaker Debugger is a new feature which offers the capability to debug machine learning models during training by identifying and detecting problems with the models in near real-time. ' '' \"In this notebook we'll show you how to use a custom rule to monitor your training job. All through a tf.keras ResNet example.\" '' '## How does Amazon SageMaker Debugger work?' '' \"Amazon SageMaker Debugger lets you go beyond just looking at scalars like losses and accuracies during training and gives you full visibility into all tensors 'flowing through the graph' during training. Furthermore it helps you monitor your training in near real-time using rules and provides you alerts once it has detected inconsistency in training flow.\" '' '### Concepts' '* **Tensors**: These represent the state of the training network at intermediate points during its execution' '* **Debug Hook**: Hook is the construct with which Amazon SageMaker Debugger looks into the training process and captures the tensors requested at the desired step intervals' '* **Rule**: A logical construct implemented as Python code which helps analyze the tensors captured by the hook and report anomalies if at all' '' \"With these concepts in mind let's understand the overall flow of things that Amazon SageMaker Debugger uses to orchestrate debugging.\" '' '### Saving tensors during training' '' 'The tensors captured by the debug hook are stored in the S3 location specified by you. There are two ways you can configure Amazon SageMaker Debugger to save tensors:' '' '#### With no changes to your training script' \"If you use one of the Amazon SageMaker provided [Deep Learning Containers](https://docs.aws.amazon.com/sagemaker/latest/dg/pre-built-containers-frameworks-deep-learning.html) for 1.15 then you don't need to make any changes to your training script for the tensors to be stored. Amazon SageMaker Debugger will use the configuration you provide through the Amazon SageMaker SDK's Tensorflow `Estimator` when creating your job to save the tensors in the fashion you specify. You can review the script we are going to use at [src/tf_keras_resnet_zerocodechange.py](src/tf_keras_resnet_zerocodechange.py). You will note that this is an untouched TensorFlow Keras script which uses the `tf.keras` interface. Please note that Amazon SageMaker Debugger only supports `tf.keras` `tf.estimator` and `tf.MonitoredSession` interfaces for the zero script change experience. Full description of support is available at [Amazon SageMaker Debugger with TensorFlow](https://github.com/awslabs/sagemaker-debugger/tree/master/docs/tensorflow.md)\" '' '#### Orchestrating your script to store tensors' \" For other containers you need to make couple of lines of changes to your training script. Amazon SageMaker Debugger exposes a library `smdebug` which allows you to capture these tensors and save them for analysis. It's highly customizable and allows to save the specific tensors you want at different frequencies and possibly with other configurations. Refer [DeveloperGuide](https://github.com/awslabs/sagemaker-debugger/tree/master/docs) for details on how to use Amazon SageMaker Debugger library with your choice of framework in your training script. Here we have an example script orchestrated at [src/tf_keras_resnet_byoc.py](src/tf_keras_resnet_byoc.py). In addition to this you will need to ensure that your container has the `smdebug` library installed in this case and specify your container image URI when creating the SageMaker Estimator below. Please refer [SageMaker Documentation](https://sagemaker.readthedocs.io/en/stable/sagemaker.tensorflow.html) on how to do that.\" '' '### Analysis of tensors' '' 'Amazon SageMaker Debugger can be configured to run debugging ***Rules*** on the tensors saved from the training job. At a very broad level a rule is Python code used to detect certain conditions during training. Some of the conditions that a data scientist training an algorithm may care about are monitoring for gradients getting too large or too small detecting overfitting and so on. Amazon SageMaker Debugger comes pre-packaged with certain built-in rules. Users can write their own rules using the APIs provided by Amazon SageMaker Debugger through the `smdebug` library. You can also analyze raw tensor data outside of the Rules construct in say a SageMaker notebook using these APIs. Please refer [Analysis Developer Guide](https://github.com/awslabs/sagemaker-debugger/blob/master/docs/api.md) for more on these APIs.']\n",
      "['# Debugging XGBoost Training Jobs with Amazon SageMaker Debugger Using Rules' '' 'This notebook was created and tested on an ml.m5.4xlarge notebook instance.' '' '## Overview' '' 'Amazon SageMaker Debugger is a new capability of Amazon SageMaker that allows debugging machine learning training. ' 'Amazon SageMaker Debugger helps you to monitor your training in near real time using rules and would provide you alerts once it has detected inconsistency in training. ' '' 'Using Amazon SageMaker Debugger is a two step process: Saving tensors and Analysis.' \"Let's look at each one of them closely.\" '' '### Saving tensors' '' 'In deep learning algorithms tensors define the state of the training job at any particular instant in its lifecycle.' 'Amazon SageMaker Debugger exposes a library which allows you to capture these tensors and save them for analysis.' 'Although XGBoost is not a deep learning algorithm Amazon SageMaker Debugger is highly customizable and can help provide interpretability by saving insightful metrics such as performance metrics or feature importances at different frequencies.' 'Refer to [documentation](https://github.com/awslabs/sagemaker-debugger/blob/master/docs/xgboost.md) for details on how to save the metrics you want.' '' '' '### Analysis' '' 'After the tensors are saved perform automatic analysis by running debugging ***Rules***.' 'On a very broad level a rule is Python code used to detect certain conditions during training.' 'Some of the conditions that a data scientist training an algorithm may care about are monitoring for gradients getting too large or too small detecting overfitting and so on.' 'Amazon SageMaker Debugger comes pre-packaged with certain rules that can be invoked on Amazon SageMaker. Users can also write their own rules using the Amazon SageMaker Debugger APIs. ' 'For more information about automatic analysis using a rule see the [rules documentation](https://github.com/awslabs/sagemaker-debugger/blob/master/docs/analysis.md).']\n",
      "['# Debugging XGBoost training jobs in real time with Amazon SageMaker Debugger ' '' 'This notebook uses the MNIST dataset to demonstrate real-time analysis of XGBoost training jobs while the training jobs are running. ' '' 'This notebook was created and tested on an ml.m5.4xlarge notebook instance using 100GB instance volume. ' '' '## Overview ' '' 'Amazon SageMaker Debugger is a new capability of Amazon SageMaker that allows debugging machine learning training.  ' 'SageMaker Debugger helps you to monitor your training in near real time using rules and provides alerts if it detects an inconsistency in training.  ' '' 'Using SageMaker Debugger is a two step process: Saving tensors and analysis. ' \"Let's look at each one of them closely. \" '' '### Saving tensors' '' 'In deep learning algorithms tensors define the state of the training job at any particular instant in its lifecycle.' 'Amazon SageMaker Debugger exposes a library which allows you to capture these tensors and save them for analysis.' 'Although XGBoost is not a deep learning algorithm Amazon SageMaker Debugger is highly customizable and can help you interpret results by saving insightful metrics. For example performance metrics or the importance of features at different frequencies. ' 'Refer to [documentation](https://github.com/awslabs/sagemaker-debugger/blob/master/docs/xgboost.md) for details on how to save the metrics you want. ' '' '' '### Analysis' '' 'There are two ways to get to tensors and run analysis on them.' '' 'One way is to use concept called ***Rules***. On a very broad level a rule is Python code used to detect certain conditions during training.' 'Some of the conditions that a data scientist training an algorithm may care about are monitoring for gradients getting too large or too small detecting overfitting and so on.' 'Amazon SageMaker Debugger comes pre-packaged with certain built-in rules that can be invoked on Amazon SageMaker. You can also write your own rules using the Amazon SageMaker Debugger APIs. ' 'For more details about automatic analysis using rules see [rules documentation](https://github.com/awslabs/sagemaker-debugger/tree/master/docs/rules).' '' 'This notebook focuses on another approach: **Manual analysis** which can be performed in realtime while training jobs are running.' '' \"Manual analysis is helpful to detect which type of issue you're running into. You save raw tensors in order to understand your data and model better and figure out the root cause of your training job problem.\" '' 'Manual analysis is powered by the Amazon SageMaker Debugger API. This API framework enables retrieving tensors and scalars (e.g. debugging data) saved during training job via few lines of code. One of the most powerful features provided by it is realtime access to data. You can get tensors and scalars ***while your training job is running***.' '' '![Animated confusion matrix](cm.gif)']\n",
      "['## MNIST Handwritten Digits Classification Experiment' '' 'This demo shows how you can use SageMaker Experiment Management Python SDK to organize track compare and evaluate your machine learning (ML) model training experiments.' '' 'You can track artifacts for experiments including data sets algorithms hyper-parameters and metrics. Experiments executed on SageMaker such as SageMaker Autopilot jobs and training jobs will be automatically tracked. You can also track artifacts for additional steps within an ML workflow that come before/after model training e.g. data pre-processing or post-training model evaluation.' '' 'The APIs also let you search and browse your current and past experiments compare experiments and identify best performing models.' '' 'Now we will demonstrate these capabilities through an MNIST handwritten digits classification example. The experiment will be organized as follow:' '' '1. Download and prepare the MNIST dataset.' '2. Train a Convolutional Neural Network (CNN) Model. Tune the hyper parameter that configures the number of hidden channels in the model. Track the parameter configurations and resulting model accuracy using SageMaker Experiments Python SDK.' '3. Finally use the search and analytics capabilities of Python SDK to search compare and evaluate the performance of all model versions generated from model tuning in Step 2.' '4. We will also see an example of tracing the complete linage of a model version i.e. the collection of all the data pre-processing and training configurations and inputs that went into creating that model version.' '' 'Make sure you selected `Python 3 (Data Science)` kernel.']\n",
      "['# End-to-End Example #1' '' '1. [Introduction](#Introduction)' '2. [Prerequisites and Preprocessing](#Prequisites-and-Preprocessing)' '  1. [Permissions and environment variables](#Permissions-and-environment-variables)' '  2. [Data ingestion](#Data-ingestion)' '  3. [Data inspection](#Data-inspection)' '  4. [Data conversion](#Data-conversion)' '3. [Training the K-Means model](#Training-the-K-Means-model)' '4. [Set up hosting for the model](#Set-up-hosting-for-the-model)' '5. [Validate the model for use](#Validate-the-model-for-use)']\n",
      "['# End-to-End Example #1' '' '1. [Introduction](#Introduction)' '2. [Prerequisites and Preprocessing](#Prequisites-and-Preprocessing)' '  1. [Permissions and environment variables](#Permissions-and-environment-variables)' '  2. [Data ingestion](#Data-ingestion)' '  3. [Data inspection](#Data-inspection)' '  4. [Data conversion](#Data-conversion)' '3. [Training the K-Means model](#Training-the-K-Means-model)' '4. [Set up hosting for the model](#Set-up-hosting-for-the-model)' '  1. [Import model into hosting](#Import-model-into-hosting)' '  2. [Create endpoint configuration](#Create-endpoint-configuration)' '  3. [Create endpoint](#Create-endpoint)' '5. [Validate the model for use](#Validate-the-model-for-use)']\n",
      "['## Distributed Training with Chainer and ChainerMN' '' 'Chainer can train in two modes: single-machine and distributed. Unlike the single-machine notebook example that trains an image classification model on the CIFAR-10 dataset we will write a Chainer script that uses `chainermn` to distribute training to multiple instances.' '' \"[VGG](https://arxiv.org/pdf/1409.1556v6.pdf) is an architecture for deep convolution networks. In this example we train a convolutional network to perform image classification using the CIFAR-10 dataset on multiple instances. CIFAR-10 consists of 60000 32x32 colour images in 10 classes with 6000 images per class. There are 50000 training images and 10000 test images. We'll train a model on SageMaker deploy it to Amazon SageMaker and then classify images using the deployed model.\" '' 'The Chainer script runs inside of a Docker container running on SageMaker. For more information about the Chainer container see the sagemaker-chainer-containers repository and the sagemaker-python-sdk repository:' '' '* https://github.com/aws/sagemaker-chainer-containers' '* https://github.com/aws/sagemaker-python-sdk' '' 'For more on Chainer and ChainerMN please visit the Chainer and ChainerMN repositories:' '' '* https://github.com/chainer/chainer' '* https://github.com/chainer/chainermn' '' 'This notebook is adapted from the [CIFAR-10](https://github.com/chainer/chainer/tree/master/examples/cifar) example in the Chainer repository.']\n",
      "['## Training with Chainer' '' \"[VGG](https://arxiv.org/pdf/1409.1556v6.pdf) is an architecture for deep convolution networks. In this example we train a convolutional network to perform image classification using the CIFAR-10 dataset. CIFAR-10 consists of 60000 32x32 colour images in 10 classes with 6000 images per class. There are 50000 training images and 10000 test images. We'll train a model on SageMaker deploy it to Amazon SageMaker hosting and then classify images using the deployed model.\" '' 'The Chainer script runs inside of a Docker container running on SageMaker. For more information about the Chainer container see the sagemaker-chainer-containers repository and the sagemaker-python-sdk repository:' '' '* https://github.com/aws/sagemaker-chainer-containers' '* https://github.com/aws/sagemaker-python-sdk' '' 'For more on Chainer please visit the Chainer repository:' '' '* https://github.com/chainer/chainer' '' 'This notebook is adapted from the [CIFAR-10](https://github.com/chainer/chainer/tree/master/examples/cifar) example in the Chainer repository.']\n",
      "['## MNIST Training and Prediction with SageMaker Chainer' '' '[MNIST](http://yann.lecun.com/exdb/mnist/) the \"Hello World\" of machine learning is a popular dataset for handwritten digit classification. It consists of 70000 28x28 grayscale images labeled in 10 digit classes (0 to 9). This tutorial will show how to train a model to predict handwritten digits on the MNIST dataset by running a Chainer script on SageMaker using the sagemaker-python-sdk.' '' 'For more information about the Chainer container see the sagemaker-chainer-containers repository and the sagemaker-python-sdk repository:' '' '* https://github.com/aws/sagemaker-chainer-containers' '* https://github.com/aws/sagemaker-python-sdk' '' 'For more on Chainer please visit the Chainer repository:' '' '* https://github.com/chainer/chainer' '' 'This notebook is adapted from the [MNIST](https://github.com/chainer/chainer/tree/master/examples/mnist) example in the Chainer repository.']\n",
      "['## Training a sentiment analysis model with Chainer' '' 'In this notebook we will train a model that will allow us to analyze text for positive or negative sentiment. The model will use a recurrent neural network with long short-term memory blocks to generate word embeddings.' '' 'The Chainer script runs inside of a Docker container running on SageMaker. For more information about the Chainer container see the sagemaker-chainer-containers repository and the sagemaker-python-sdk repository:' '' '* https://github.com/aws/sagemaker-chainer-containers' '* https://github.com/aws/sagemaker-python-sdk' '' 'For more on Chainer please visit the Chainer repository:' '' '* https://github.com/chainer/chainer' '' 'The code in this notebook is adapted from the [text classification](https://github.com/chainer/chainer/tree/master/examples/text_classification) example in the Chainer repository.']\n",
      "['## Training Graph Convolutional Matrix Completion by using the Deep Graph Library with MXNet backend on Amazon SageMaker' 'The **Amazon SageMaker Python SDK** makes it easy to train Deep Graph Library (DGL) models. In this example you train [Graph Convolutional Matrix Completion](https://arxiv.org/abs/1706.02263) network using the [DMLC DGL API](https://github.com/dmlc/dgl.git) and the [MovieLens dataset](https://grouplens.org/datasets/movielens/). Three datasets are supported:' ' * MovieLens 100K Dataset MovieLens 100K movie ratings. Stable benchmark dataset. 100000 ratings from 1000 users on 1700 movies.' ' * MovieLens 1M Dataset MovieLens 1M movie ratings. Stable benchmark dataset. 1 million ratings from 6000 users on 4000 movies.' ' * MovieLens 10M Dataset MovieLens 10M movie ratings. Stable benchmark dataset. 10 million ratings and 100000 tag applications applied to 10000 movies by 72000 users.' '' '### Prerequisites' 'To get started install necessary packages.']\n",
      "['# Graph convolutional matrix completion hyperparameter tuning with Amazon SageMaker and Deep Graph Library with MXNet backend' '_**Creating a hyperparameter tuning job for a DGL network**_' '___' '___' '' '' '## Contents' '1. [Background](#Background)  ' '2. [Setup](#Setup)  ' '3. [Code](#Code)  ' '4. [Tune](#Train)  ' '5. [Wrap-up](#Wrap-up)  ' '' '## Background' \"This example notebook focuses on how to create a graph neural network (GNN) model to train [Graph Convolutional Matrix Completion (GCMC)](https://arxiv.org/abs/1706.02263) network using DGL with mxnet backend with the [MovieLens dataset](https://grouplens.org/datasets/movielens/). It leverages SageMaker's hyperparameter tuning to kick off multiple training jobs with different hyperparameter combinations to find the set with best model performance. This is an important step in the machine learning process as hyperparameter settings can have a large impact on model accuracy. In this example you use the [SageMaker Python SDK](https://github.com/aws/sagemaker-python-sdk) to create a hyperparameter tuning job for an Amazomn SageMaker estimator.\"]\n",
      "['## Training Amazon SageMaker models by using the Deep Graph Library with MXNet backend' 'The **Amazon SageMaker Python SDK** makes it easy to train Deep Graph Library (DGL) models. In this example you train a graph neural network by using the [DMLC DGL API](https://github.com/dmlc/dgl.git) and the [Cora dataset](https://relational.fit.cvut.cz/dataset/CORA). The Cora dataset describes a citation network. The Cora dataset consists of 2708 scientific publications classified into one of seven classes. The citation network consists of 5429 links. The task is to train a node classification model using Cora dataset. ' '' 'For more information about Graph Neural Network and this example see https://docs.dgl.ai/en/latest/tutorials/models/1_gnn/1_gcn.html' '' '### Prepare for training' 'To get started install necessary packages.']\n",
      "['# Hyperparameter tuning with Amazon SageMaker and Deep Graph Library with MXNet backend' '_**Creating a Hyperparameter tuning job for a DGL network**_' '___' '___' '' '' '## Contents' '1. [Background](#Background)  ' '2. [Setup](#Setup)  ' '3. [Code](#Code)  ' '4. [Tune](#Train)  ' '5. [Wrap-up](#Wrap-up)  ' '' '## Background' 'This example notebook shows how to create a graph neural network model to train the [Cora dataset] by using DGL with MXNet backend. It uses the Amazon SageMaker hyperparameter tuning to start multiple training jobs with different hyperparameter combinations. This helps you find the set with best model performance. This is an important step in the machine learning process as hyperparameter settings can have a large effect on model accuracy. In this example you use the [Amazon SageMaker Python SDK](https://github.com/aws/sagemaker-python-sdk) to create a hyperparameter tuning job for an Amazon SageMaker estimator.']\n",
      "['## Training Amazon SageMaker models by using the Deep Graph Library with PyTorch backend' 'The **Amazon SageMaker Python SDK** makes it easy to train Deep Graph Library (DGL) models. In this example you train a simple graph neural network using the [DMLC DGL API](https://github.com/dmlc/dgl.git) and the [Cora dataset](https://relational.fit.cvut.cz/dataset/CORA). The Cora dataset describes a citation network. The Cora dataset consists of 2708 scientific publications classified into one of seven classes. The citation network consists of 5429 links. The task is to train a node classification model using Cora dataset. ']\n",
      "['# Hyperparameter tuning with Amazon SageMaker and Deep Graph Library with PyTorch backend' '_**Creating a Hyperparameter Tuning Job for an Deep Graph Library (DGL) Network**_' '___' '___' '' '' '## Contents' '1. [Background](#Background)  ' '2. [Setup](#Setup)  ' '3. [Code](#Code)  ' '4. [Tune](#Train)  ' '5. [Wrap-up](#Wrap-up)  ' '' '## Background' \"This example notebook focuses on how to create a graph neural network model to train the [Cora dataset] using DGL with PyTorch backend. It leverages SageMaker's hyperparameter tuning to kick off multiple training jobs with different hyperparameter combinations to find the set with best model performance. This is an important step in the machine learning process as hyperparameter settings can have a large impact on model accuracy. In this example you use the [Amazon SageMaker Python SDK](https://github.com/aws/sagemaker-python-sdk) to create a hyperparameter tuning job for an Amazon SageMaker estimator.\"]\n",
      "['# Hyperparameter tuning with Amazon SageMaker for molecular property prediction']\n",
      "['# Training Amazon SageMaker models for molecular property prediction by using DGL with PyTorch backend' '' 'The **Amazon SageMaker Python SDK** makes it easy to train Deep Graph Library (DGL) models. In this example you train a simple graph neural network for molecular toxicity prediction by using [DGL](https://github.com/dmlc/dgl) and the Tox21 dataset.' '' 'The dataset contains qualitative toxicity measurements for 8014 compounds on 12 different targets including nuclear ' 'receptors and stress-response pathways. Each target yields a binary classification problem. You can model the problem as a graph classification problem. ']\n",
      "['## Training knowledge graph embedding by using the Deep Graph Library with MXNet backend' 'The **Amazon SageMaker Python SDK** makes it easy to train Deep Graph Library (DGL) models. In this example you generate knowledge graph embedding using the [DMLC DGL API](https://github.com/dmlc/dgl.git) and FB15k dataset.' '' 'For more information about knowledge graph embedding and this example see https://github.com/dmlc/dgl/tree/master/apps/kg']\n",
      "['# Hyperparameter tuning with Amazon SageMaker and Deep Graph Library with MXNet backend' '_**Creating a Hyperparameter tuning job for a DGL network**_' '___' '___' '' '' '## Contents' '1. [Background](#Background)  ' '2. [Setup](#Setup)' '3. [Tune](#Train)  ' '4. [Wrap-up](#Wrap-up)  ' '' '## Background' 'This example notebook shows how to generate knowledge graph embedding using the DMLC DGL API and FB15k dataset. It uses the Amazon SageMaker hyperparameter tuning to start multiple training jobs with different hyperparameter combinations. This helps you find the set with best model performance. This is an important step in the machine learning process as hyperparameter settings can have a large effect on model accuracy. In this example you use the [Amazon SageMaker Python SDK](https://github.com/aws/sagemaker-python-sdk) to create a hyperparameter tuning job for an Amazon SageMaker estimator.']\n",
      "['## Training knowledge graph embedding by using the Deep Graph Library with PyTorch backend' 'The **Amazon SageMaker Python SDK** makes it easy to train Deep Graph Library (DGL) models. In this example you generate knowledge graph embedding using the [DMLC DGL API](https://github.com/dmlc/dgl.git) and FB15k dataset.' '' 'For more details about Knowledge Graph Embedding and this example see https://github.com/dmlc/dgl/tree/master/apps/kg']\n",
      "['# Hyperparameter tuning with Amazon SageMaker and Deep Graph Library with PyTorch backend' '_**Creating a Hyperparameter tuning job for a DGL network**_' '___' '___' '' '' '## Contents' '1. [Background](#Background)  ' '2. [Setup](#Setup)  ' '3. [Tune](#Train)  ' '4. [Wrap-up](#Wrap-up)  ' '' '## Background' 'This example notebook shows how to generate knowledge graph embedding using the DMLC DGL API and FB15k dataset. It uses the Amazon SageMaker hyperparameter tuning to start multiple training jobs with different hyperparameter combinations. This helps you find the set with best model performance. This is an important step in the machine learning process as hyperparameter settings can have a large effect on model accuracy. In this example you use the [Amazon SageMaker Python SDK](https://github.com/aws/sagemaker-python-sdk) to create a hyperparameter tuning job for an Amazon SageMaker estimator.']\n",
      "['# Train and Host a Keras Sequential Model' '## Using Pipe Mode datasets and distributed training with Horovod' 'This notebook shows how to train and host a Keras Sequential model on SageMaker. The model used for this notebook is a simple deep CNN that was extracted from [the Keras examples](https://github.com/keras-team/keras/blob/master/examples/cifar10_cnn.py).']\n",
      "['# Training SageMaker Models using the Apache MXNet Module API on SageMaker Managed Spot Training' '' 'The example here is almost the same as [Training and hosting SageMaker Models using the Apache MXNet Module API](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/sagemaker-python-sdk/mxnet_mnist/mxnet_mnist.ipynb).' '' 'This notebook tackles the exact same problem with the same solution but it has been modified to be able to run using SageMaker Managed Spot infrastructure. SageMaker Managed Spot uses [EC2 Spot Instances](https://aws.amazon.com/ec2/spot/) to run Training at a lower cost.' '' 'Please read the original notebook and try it out to gain an understanding of the ML use-case and how it is being solved. We will not delve into that here in this notebook.' '' '## First setup variables and define functions' '' \"Again we won't go into detail explaining the code below it has been lifted verbatim from [Training and hosting SageMaker Models using the Apache MXNet Module API](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/sagemaker-python-sdk/mxnet_mnist/mxnet_mnist.ipynb)\"]\n",
      "['# Training using SageMaker Estimators on SageMaker Managed Spot Training' '' 'The example here is almost the same as [Creating training and serving using SageMaker Estimators](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/sagemaker-python-sdk/tensorflow_iris_dnn_classifier_using_estimators/tensorflow_iris_dnn_classifier_using_estimators.ipynb).' '' 'This notebook tackles the exact same problem with the same solution but it has been modified to be able to run using SageMaker Managed Spot infrastructure. SageMaker Managed Spot uses [EC2 Spot Instances](https://aws.amazon.com/ec2/spot/) to run Training at a lower cost.' '' 'Please read the original notebook and try it out to gain an understanding of the ML use-case and how it is being solved. We will not delve into that here in this notebook.' '' '## First setup variables and define functions' '' \"Again we won't go into detail explaining the code below it has been lifted verbatim from [Creating training and serving using SageMaker Estimators](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/sagemaker-python-sdk/tensorflow_iris_dnn_classifier_using_estimators/tensorflow_iris_dnn_classifier_using_estimators.ipynb)\"]\n",
      "['# Building an image embedding server with Gluon' 'In this notebook we use a pre-trained model to extract image embeddings.' '* **Image embeddings** are dense high-semantic low-dimension vector representation of images learnt by neural networks. They can directly by learnt by a model or obtained as a byproduct of a downstream task. In this demo we use a pre-trained classifier from the gluon model zoo to obtain those embeddings:' ' 1. We first import a model from the gluon model zoo locally on the notebook that we then compress and send to S3' ' 1. We then use the SageMaker MXNet Serving feature to deploy the embedding model to a real-time managed endpoint. It uses the model artifact that we previously loaded to S3.' ' 1. We query the endpoint and visualize embeddings in a 2D scatter plot using PCA' '' '' '* **More on gluon:** [gluon](https://mxnet.incubator.apache.org/api/python/docs/api/gluon/index.html) is the imperative python front-end of the Apache MXNet deep learning framework. Gluon notably features specialized toolkits helping reproducing state-of-the-art architectures: [gluon-cv](https://gluon-cv.mxnet.io/) [gluon-nlp](https://gluon-nlp.mxnet.io/) [gluon-ts](https://gluon-ts.mxnet.io/). Gluon also features a number of excellent end-to-end tutorial mixing science with code such as [D2L.ai](https://classic.d2l.ai/) and [The Straight Dope](https://gluon.mxnet.io/)' '* This specific demo has been developed on the `conda_mxnet_p36` kernel of a SageMaker `ml.t2.medium` Notebook instance' '* For a more advanced fully-deployed demo and an embedding server + approximate kNN pipeline see the excellent https://thomasdelteil.github.io/VisualSearch_MXNet/ from Thomas Delteil.' '' '**This sample is provided for demonstration purposes make sure to conduct appropriate testing if derivating this code for your own use-cases!**']\n",
      "['## MNIST Training with MXNet and Gluon' '' 'MNIST is a widely used dataset for handwritten digit classification. It consists of 70000 labeled 28x28 pixel grayscale images of hand-written digits. The dataset is split into 60000 training images and 10000 test images. There are 10 classes (one for each of the 10 digits). This tutorial will show how to train and test an MNIST model on SageMaker using MXNet and the Gluon API.' '']\n",
      "['## Local MNIST Training with MXNet and Gluon' '' '### Pre-requisites' '' \"This notebook shows how to use the SageMaker Python SDK to run your code in a local container before deploying to SageMaker's managed training or hosting environments.  This can speed up iterative testing and debugging while using the same familiar Python SDK interface.  Just change your estimator's `train_instance_type` to `local`.  You could also use `local_gpu` if you're using an ml.p2 or ml.p3 notebook instance but then you'll need to set `train_instance_count=1` since distributed local GPU training is not yet supported.\" '' \"In order to use this feature you'll need to install docker-compose (and nvidia-docker if training with a GPU).  Running the setup.sh script below will handle this for you.\" '' '**Note you can only run a single local notebook at one time.**']\n",
      "['## Sentiment Analysis with MXNet and Gluon' '' 'This tutorial will show how to train and test a Sentiment Analysis (Text Classification) model on SageMaker using MXNet and the Gluon API.' '']\n",
      "['# Training and hosting SageMaker Models using the Apache MXNet Module API' '' 'The **SageMaker Python SDK** makes it easy to train and deploy MXNet models. In this example we train a simple neural network using the Apache MXNet [Module API](https://mxnet.apache.org/api/python/module/module.html) and the MNIST dataset. The MNIST dataset is widely used for handwritten digit classification and consists of 70000 labeled 28x28 pixel grayscale images of hand-written digits. The dataset is split into 60000 training images and 10000 test images. There are 10 classes (one for each of the 10 digits). The task at hand is to train a model using the 60000 training images and subsequently test its classification accuracy on the 10000 test images.' '' '### Setup' '' 'First we need to define a few variables that will be needed later in the example.']\n",
      "['# Using Amazon Elastic Inference with MXNet on Amazon SageMaker' '' 'This notebook demonstrates how to enable and use Amazon Elastic Inference with our predefined SageMaker MXNet containers.' '' 'Amazon Elastic Inference (EI) is a resource you can attach to your Amazon EC2 instances to accelerate your deep learning (DL) inference workloads. EI allows you to add inference acceleration to an Amazon SageMaker hosted endpoint or Jupyter notebook for a fraction of the cost of using a full GPU instance. For more information please visit: https://docs.aws.amazon.com/sagemaker/latest/dg/ei.html' '' 'This notebook is an adaption of the [SageMaker MXNet MNIST notebook](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/sagemaker-python-sdk/mxnet_mnist/mxnet_mnist.ipynb) with modifications showing the changes needed to enable and use EI with MXNet on SageMaker.' '' '1. [Using Amazon Elastic Inference with MXNet on Amazon SageMaker](#Using-Amazon-Elastic-Inference-with-MXNet-on-Amazon-SageMaker)' '1. [MNIST dataset](#MNIST-dataset)' '1. [Setup](#Setup)' '1. [The training script](#The-training-script)' \"1. [SageMaker's MXNet estimator class](#SageMaker's-MXNet-estimator-class)\" '1. [Running the training job](#Running-the-training-Job)' '1. [Creating an inference endpoint and attaching an EI accelerator](#Creating-an-inference-endpoint-and-attaching-an-EI-accelerator)' '1. [How our models are loaded](#How-our-models-are-loaded)' '1. [Using EI with a SageMaker notebook instance](#Using-EI-with-a-SageMaker-notebook-instance)' '1. [Making an inference request](#Making-an-inference-request)' '1. [Delete the Endpoint](#Delete-the-endpoint)' '' 'If you are familiar with SageMaker and already have a trained model skip ahead to the [Creating-an-inference-endpoint section](#Creating-an-inference-endpoint-with-EI)' '' 'For this example we will use the SageMaker Python SDK which makes it easy to train and deploy MXNet models. In this example we train a simple neural network using the Apache MXNet [Module API](https://mxnet.apache.org/api/python/module/module.html) and the MNIST dataset.' '' '### MNIST dataset' '' 'The MNIST dataset is widely used for handwritten digit classification and consists of 70000 labeled 28x28 pixel grayscale images of hand-written digits. The dataset is split into 60000 training images and 10000 test images. There are 10 classes (one for each of the 10 digits). The task at hand is to train a model using the 60000 training images and then test its classification accuracy on the 10000 test images.' '' '### Setup' '' \"Let's start by creating a SageMaker session and specifying the IAM role arn used to give training and hosting access to your data. See the [documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-roles.html) for how to create these. Note if more than one role is required for notebook instances training and/or hosting please replace the `sagemaker.get_execution_role()` with a the appropriate full IAM role arn string(s).\"]\n",
      "['# Using Amazon Elastic Inference with MXNet on an Amazon SageMaker Notebook Instance' '' 'This notebook demonstrates how to enable and utilize Amazon Elastic Inference with our predefined SageMaker MXNet containers.' '' 'Amazon Elastic Inference (EI) is a resource you can attach to your Amazon EC2 instances to accelerate your deep learning (DL) inference workloads. EI allows you to add inference acceleration to an Amazon SageMaker hosted endpoint or Jupyter notebook for a fraction of the cost of using a full GPU instance. For more information please visit: https://docs.aws.amazon.com/sagemaker/latest/dg/ei.html' '' 'This notebook is an adaption of the [SageMaker MXNet MNIST notebook](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/sagemaker-python-sdk/mxnet_mnist/mxnet_mnist.ipynb) with modifications showing the changes needed to enable and use EI with MXNet on SageMaker.' '' '1. [Using Amazon Elastic Inference with MXNet on an Amazon SageMaker Notebook Instance](#Using-Amazon-Elastic-Inference-with-MXNet-on-an-Amazon-SageMaker-Notebook-Instance)' '1. [MNIST dataset](#MNIST-dataset)' '1. [Setup](#Setup)' '1. [The training script](#The-training-script)' \"1. [SageMaker's MXNet estimator class](#SageMaker's-MXNet-estimator-class)\" '1. [Running the Training job](#Running-the-Training-job)' '1. [Creating an inference endpoint and attaching an EI accelerator](#Creating-an-inference-endpoint-and-attaching-an-EI-accelerator)' '1. [How our models are loaded](#How-our-models-are-loaded)' '1. [Using EI with a SageMaker notebook instance](#Using-EI-with-a-SageMaker-notebook-instance)' '1. [Making an inference request locally](#Making-an-inference-request-locally)' '1. [Delete the Endpoint](#Delete-the-endpoint)' '' 'If you are familiar with SageMaker and already have a trained model skip ahead to the [Creating-an-inference-endpoint section](#Creating-an-inference-endpoint-with-EI)' '' 'For this example we will be utilizing the SageMaker Python SDK which makes it easy to train and deploy MXNet models. In this example we train a simple neural network using the Apache MXNet [Module API](https://mxnet.apache.org/api/python/module/module.html) and the MNIST dataset.' '' '### MNIST dataset' '' 'The MNIST dataset is widely used for handwritten digit classification and consists of 70000 labeled 28x28 pixel grayscale images of hand-written digits. The dataset is split into 60000 training images and 10000 test images. There are 10 classes (one for each of the 10 digits). The task at hand is to train a model using the 60000 training images and subsequently test its classification accuracy on the 10000 test images.' '' '### Setup' '' \"Let's start by creating a SageMaker session and specifying the IAM role arn used to give training and hosting access to your data. See the [documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-roles.html) for how to create these. Note if more than one role is required for notebook instances training and/or hosting please replace the `sagemaker.get_execution_role()` with a the appropriate full IAM role arn string(s).\"]\n",
      "['# Using the Apache MXNet Module API with SageMaker Training and Batch Transformation ' '' 'The SageMaker Python SDK makes it easy to train MXNet models and use them for batch transformation. In this example we train a simple neural network using the Apache MXNet [Module API](https://mxnet.incubator.apache.org/api/python/module.html) and the MNIST dataset. The MNIST dataset is widely used for handwritten digit classification and consists of 70000 labeled 28x28 pixel grayscale images of hand-written digits. The dataset is split into 60000 training images and 10000 test images. There are 10 classes (one for each of the 10 digits). The task at hand is to train a model using the 60000 training images and subsequently test its classification accuracy on the 10000 test images.']\n",
      "['# Hosting ONNX models with Amazon Elastic Inference' '' 'Amazon Elastic Inference (EI) is a resource you can attach to your Amazon EC2 instances to accelerate your deep learning (DL) inference workloads. EI allows you to add inference acceleration to an Amazon SageMaker hosted endpoint or Jupyter notebook for a fraction of the cost of using a full GPU instance. It reduces the cost of running deep learning inference by up to 75%. ' '' 'Amazon EI provides support for Apache MXNet TensorFlow and ONNX models. The [Open Neural Network Exchange](https://onnx.ai/) (ONNX) is an open standard format for deep learning models that enables interoperability between deep learning frameworks such as Apache MXNet Caffe2 Microsoft Cognitive Toolkit(CNTK) PyTorch and more. This means that we can use any of these frameworks to train the model export these pretrained models in ONNX format and then import them in MXNet for inference. For more information please visit: https://docs.aws.amazon.com/sagemaker/latest/dg/ei.html' '' 'In this example we will use the ResNet-152v1 model from [Deep residual learning for image recognition](https://arxiv.org/abs/1512.03385). This model alongside many others can be found at the [ONNX Model Zoo](https://github.com/onnx/models).' '' 'We will use the SageMaker Python SDK to host this ONNX model in SageMaker and perform inference requests.']\n",
      "['## Exporting ONNX Models with MXNet' '' 'The [Open Neural Network Exchange](https://onnx.ai/) (ONNX) is an open format for representing deep learning models with an extensible computation graph model definitions of built-in operators and standard data types. Starting with MXNet 1.3 models trained using MXNet can now be saved as ONNX models.' '' 'In this example we show how to train a model on Amazon SageMaker and save it as an ONNX model. This notebook is based on the [MXNet MNIST notebook](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/sagemaker-python-sdk/mxnet_mnist/mxnet_mnist.ipynb) and the [MXNet example for exporting to ONNX](https://mxnet.incubator.apache.org/tutorials/onnx/export_mxnet_to_onnx.html).']\n",
      "['## Exporting ONNX Models with MXNet' '' 'The [Open Neural Network Exchange](https://onnx.ai/) (ONNX) is an open format for representing deep learning models with an extensible computation graph model definitions of built-in operators and standard data types. Starting with MXNet 1.3 models trained using MXNet can now be saved as ONNX models.' '' 'In this example we show how to train a model on Amazon SageMaker and save it as an ONNX model. This notebook is based on the [MXNet MNIST notebook](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/sagemaker-python-sdk/mxnet_mnist/mxnet_mnist.ipynb) and the [MXNet example for exporting to ONNX](https://mxnet.incubator.apache.org/tutorials/onnx/export_mxnet_to_onnx.html).']\n",
      "['# Importing and hosting an ONNX model with MXNet' '' 'The [Open Neural Network Exchange](https://onnx.ai/) (ONNX) is an open format for representing deep learning models with its extensible computation graph model and definitions of built-in operators and standard data types.' '' 'In this example we will use the Super Resolution model from [Image Super-Resolution Using Deep Convolutional Networks](https://ieeexplore.ieee.org/document/7115171) where Dong et al. trained a model for taking a low-resolution image as input and producing a high-resolution one. This model along with many others can be found at the [ONNX Model Zoo](https://github.com/onnx/models).' '' 'We will use the SageMaker Python SDK to host this ONNX model in SageMaker and perform inference requests.']\n",
      "['## Introduction' '' 'Deep Learning frameworks enable Machine Learning (ML) practitioners to build and train ML models. However the process of deploying ML models in production to serve predictions (also known as inferences) in real time is more complex. It requires that ML practitioners build a scalable and performant model server which can host these models and handle inference requests at scale. Model Server for Apache MXNet (MMS) was developed to address this hurdle. MMS is a highly scalable production ready inference server. MMS was designed in a ML/DL framework agnostic way to host models trained in any ML/DL framework.' '' \"In this blog post we will showcase how anyone could use Model Server for Apache MXNet (MMS) to host their model trained using any Machine Learning/Deep Learning (ML/DL) framework or tool kit in production. We chose Amazon Sagemaker service for production hosting - this PaaS solution does a lot of heavy lifting to provide infrastructure and allows users to focus on their use cases. We will be using 'Bring your own Inference code with Amazon Sagemaker hosting'  approach where users could bring their models together with all necessary dependencies libraries frameworks and other components compiled inside of a single custom-built docker container and host it on Sagemaker. \" '' \"To showcase the true 'ML/DL framework agnostic architecture' of MMS we chose to launch a model trained with 'PaddlePaddle' framework into production.\" '' 'The overall picture of steps involved to take a model trained on any ML/DL framework to Amazon Sagemaker using MMS BYO container looks as follows:' '' '![image.png](attachment:image.png)' '' 'As shown in the picture above in order to bring your own ML/DL framework to Amazon Sagemaker using MMS Bring Your Own (BYO) container we need two main components' '' '1. **Model artifacts/Model Archive**: These are all the artifacts required to run your model on a given host. This contains the following:' '  1. **Model files** which are usually symbols and weights. These are the artifacts of training a model.' \"  2. **Custom Service File**: This file contains the entry-point which gets called every time when inference request is received and served by MMS. This file generally contains the logic to initialize the model in a particular ML/DL framework preprocess the incoming request run inference in a particular ML/DL framework and post-process logic which takes the data coming out of framework's inference method and converts it to end-user consumable data.\" \"  3. **MANIFEST File**: This is the interface between custom service file and the MMS. This file is generated by running a tool that comes as part of MMS distribution called 'model-archiver'.\" '2. **Container artifact**: To load and run a model written in a custom DL framework on Sagemaker you need to bring a container that will be run on Sagemaker service. In this document we will show how to use MMS base container and extend it to support custom DL frameworks and other model dependencies. The MMS base container is a docker container that comes with a highly scalable and performant model-server which is readily launchable onto Sagemaker service.' 'In the following sections we will see each of the above components in detail.' '' '## Preparing a Model' 'MMS container is completely ML/DL framework agnostic. Users can write models in a ML/DL framework of their choice and bring it to Sagemaker with MMS BYO container to get the features of scalability and performance. In this blogpost we chose to showcase this by bringing in a model written for PaddlePaddle framework. Lets look at how to prepare a PaddlePaddle model in the following sections. The model artifact is readily available at <*TODO: Update this with the S3 link with model.tar.gz*>.' '' '### Preparing Model Artifacts' \"We are going to use [Understand Sentiment](https://github.com/PaddlePaddle/book/tree/develop/06.understand_sentiment) example that is available and published in examples section of PaddlePaddle repository. First of all we need to create a model. In order to do that we followed instructions provided in [PaddlePaddle/book](https://github.com/PaddlePaddle/book) repository: downloaded  container and ran training by the notebook that is provided as part of the example. We used 'Stacked Bidirectional LSTM' network for our training and trained the model for 100 epochs. At the end of this training exercise we get the following list of trained model artifacts.\" '' '```bash' '!ls' 'embedding_0.w_0    fc_2.w_0    fc_5.w_0    learning_rate_0    lstm_3.b_0    moment_10    moment_18    moment_25    moment_32    moment_8' 'embedding_1.w_0    fc_2.w_1    fc_5.w_1    learning_rate_1    lstm_3.w_0    moment_11    moment_19    moment_26    moment_33    moment_9' 'fc_0.b_0    fc_3.b_0    fc_6.b_0    lstm_0.b_0    lstm_4.b_0    moment_12    moment_2    moment_27    moment_34' 'fc_0.w_0    fc_3.w_0    fc_6.w_0    lstm_0.w_0    lstm_4.w_0    moment_13    moment_20    moment_28    moment_35' 'fc_1.b_0    fc_3.w_1    fc_6.w_1    lstm_1.b_0    lstm_5.b_0    moment_14    moment_21    moment_29    moment_4' 'fc_1.w_0    fc_4.b_0    fc_7.b_0    lstm_1.w_0    lstm_5.w_0    moment_15    moment_22    moment_3    moment_5' 'fc_1.w_1    fc_4.w_0    fc_7.w_0    lstm_2.b_0    moment_0    moment_16    moment_23    moment_30    moment_6' 'fc_2.b_0    fc_5.b_0    fc_7.w_1    lstm_2.w_0    moment_1    moment_17    moment_24    moment_31    moment_7' '```' '' 'These artifacts constitute a PaddlePaddle model. We copy these artifacts from within training container to localhost so that it will be easier to begin preparation of the model for production hosting. To learn more on how to copy files from inside a docker container to location outside of it please refer to [Docker CLI](https://docs.docker.com/engine/reference/commandline/cp/).' '' '### Writing Custom Service Code' \"We now have model files required to host the model in production. We can now define a custom service file which knows how to use these files and also knows how to 'preprocess' the raw request coming into the server and how to 'postprocess' the responses coming out of the PaddlePaddle framework's 'infer' method. For this we modified the notebook example written to test the trained model *<TODO: supply link to what was the source of the example notebook>*. Let's look at some code. \" '' \"We created a custom service file called 'paddle_sentiment_analysis.py'. Here we first define a class called 'PaddleSentimentAnalysis' which contains methods to initialize the model and also defines pre-processing post-processing and inference methods. Refer [Custom Service Code](https://github.com/awslabs/mxnet-model-server/blob/master/docs/custom_service.md) document to learn how to write your custom-service code. The skeleton of this file is as follows:\" '' '```bash' '$ cat paddle_sentiment_analysis.py' '```' '```python' '' 'from __future__ import print_function' 'import paddle' 'import paddle.fluid as fluid' 'import paddle.dataset as dataset' 'from functools import partial' '' '  ' 'class PaddleSentimentAnalysis(object):' '    def __init__(self):' '    ...' '' '    def initialize(self context):' '    \"\"\"' '    This method is used to initialize the network and read other artifacts.' '    \"\"\"' '    ...' '    ' '    def preprocess(self data):' '    \"\"\"' '    This method is used to convert the string requests coming from client ' '    into tensors. ' '    \"\"\"' '    ...' '' '    def inference(self input):' '    \"\"\"' '    This method runs the tensors created in preprocess method through the ' \"    DL framework's infer method.\" '    \"\"\"' '    ...' '' '    def postprocess(self output data):' '    \"\"\"' '    Here the values returned from the inference method is converted to a ' '    human understandable response.' '    \"\"\"' '    ...' '    ' '' '_service = PaddleSentimentAnalysis()' '' '' 'def handle(data context):' '\"\"\"' 'This method is the entrypoint \\\\\"handler\\\\\" method that is used by MMS.' 'Any request coming in for this model will be sent to this method.' '\"\"\"' '    if not _service.initialized:' '        _service.initialize(context)' '' '    if data is None:' '        return None' '' '    pre = _service.preprocess(data)' '    inf = _service.inference(pre)' '    ret = _service.postprocess(inf data)' '    return ret' '```']\n",
      "['# PyTorch Cifar10 local training  ' '' '## Pre-requisites' '' \"This notebook shows how to use the SageMaker Python SDK to run your code in a local container before deploying to SageMaker's managed training or hosting environments.  This can speed up iterative testing and debugging while using the same familiar Python SDK interface.  Just change your estimator's `train_instance_type` to `local` (or `local_gpu` if you're using an ml.p2 or ml.p3 notebook instance).\" '' \"In order to use this feature you'll need to install docker-compose (and nvidia-docker if training with a GPU).\" '' '**Note you can only run a single local notebook at one time.**']\n",
      "['# MNIST Training using PyTorch']\n",
      "['# Word-level language modeling using PyTorch']\n",
      "['# MNIST Training using PyTorch']\n",
      "['# Inference Pipeline with Scikit-learn and Linear Learner' 'Typically a Machine Learning (ML) process consists of few steps: data gathering with various ETL jobs pre-processing the data featurizing the dataset by incorporating standard techniques or prior knowledge and finally training an ML model using an algorithm. ' 'In many cases when the trained model is used for processing real time or batch prediction requests the model receives data in a format which needs to pre-processed (e.g. featurized) before it can be passed to the algorithm. In the following notebook we will demonstrate how you can build your ML Pipeline leveraging the Sagemaker Scikit-learn container and SageMaker Linear Learner algorithm & after the model is trained deploy the Pipeline (Data preprocessing and Lineara Learner) as an Inference Pipeline behind a single Endpoint for real time inference and for batch inferences using Amazon SageMaker Batch Transform.' '' \"We will demonstrate this using the Abalone Dataset to guess the age of Abalone with physical features. The dataset is available from [UCI Machine Learning](https://archive.ics.uci.edu/ml/datasets/abalone); the aim for this task is to determine age of an Abalone (a kind of shellfish) from its physical measurements. We'll use Sagemaker's Scikit-learn container to featurize the dataset so that it can be used for training with Linear Learner.\" '' '### Table of contents' '* [Preprocessing data and training the model](#training)' ' * [Upload the data for training](#upload_data)' ' * [Create a Scikit-learn script to train with](#create_sklearn_script)' ' * [Create SageMaker Scikit Estimator](#create_sklearn_estimator)' ' * [Batch transform our training data](#preprocess_train_data)' ' * [Fit a LinearLearner Model with the preprocessed data](#training_model)' '* [Inference Pipeline with Scikit preprocessor and Linear Learner](#inference_pipeline)' ' * [Set up the inference pipeline](#pipeline_setup)' ' * [Make a request to our pipeline endpoint](#pipeline_inference_request)' ' * [Delete Endpoint](#delete_endpoint)']\n",
      "['# Iris Training and Prediction with Sagemaker Scikit-learn' 'This tutorial shows you how to use [Scikit-learn](https://scikit-learn.org/stable/) with Sagemaker by utilizing the pre-built container. Scikit-learn is a popular Python machine learning framework. It includes a number of different algorithms for classification regression clustering dimensionality reduction and data/feature pre-processing. ' '' 'The [sagemaker-python-sdk](https://github.com/aws/sagemaker-python-sdk) module  makes it easy to take existing scikit-learn code which we will show by training a model on the IRIS dataset and generating a set of predictions. For more information about the Scikit-learn container see the [sagemaker-scikit-learn-containers](https://github.com/aws/sagemaker-scikit-learn-container) repository and the [sagemaker-python-sdk](https://github.com/aws/sagemaker-python-sdk) repository.' '' 'For more on Scikit-learn please visit the Scikit-learn website: <http://scikit-learn.org/stable/>.' '' '### Table of contents' '* [Upload the data for training](#upload_data)' '* [Create a Scikit-learn script to train with](#create_sklearn_script)' '* [Create the SageMaker Scikit Estimator](#create_sklearn_estimator)' '* [Train the SKLearn Estimator on the Iris data](#train_sklearn)' '* [Using the trained model to make inference requests](#inferece)' ' * [Deploy the model](#deploy)' ' * [Choose some data and use it for a prediction](#prediction_request)' ' * [Endpoint cleanup](#endpoint_cleanup)' '* [Batch Transform](#batch_transform)' ' * [Prepare Input Data](#prepare_input_data)' ' * [Run Transform Job](#run_transform_job)' ' * [Check Output Data](#check_output_data)']\n",
      "['## Develop Train Optimize and Deploy Scikit-Learn Random Forest' '' '* Doc https://sagemaker.readthedocs.io/en/stable/using_sklearn.html' '* SDK https://sagemaker.readthedocs.io/en/stable/sagemaker.sklearn.html' '* boto3 https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker.html#client' '' 'In this notebook we show how to use Amazon SageMaker to develop train tune and deploy a Scikit-Learn based ML model (Random Forest). More info on Scikit-Learn can be found here https://scikit-learn.org/stable/index.html. We use the Boston Housing dataset present in Scikit-Learn: https://scikit-learn.org/stable/datasets/index.html#boston-dataset' '' '' 'More info on the dataset:' '' \"The Boston house-price data of Harrison D. and Rubinfeld D.L. 'Hedonic prices and the demand for clean air' J. Environ. Economics & Management vol.5 81-102 1978. Used in Belsley Kuh & Welsch 'Regression diagnostics ...' Wiley 1980. N.B. Various transformations are used in the table on pages 244-261 of the latter.\" '' 'The Boston house-price data has been used in many machine learning papers that address regression problems.' 'References' '' \" * Belsley Kuh & Welsch 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity' Wiley 1980. 244-261.\" ' * QuinlanR. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning 236-243 University of Massachusetts Amherst. Morgan Kaufmann.' ' ' ' ' ' ' ' ' '**This sample is provided for demonstration purposes make sure to conduct appropriate testing if derivating this code for your own use-cases!**']\n",
      "['# Train an ML Model using Apache Spark in EMR and deploy in SageMaker' 'In this notebook we will see how you can train your Machine Learning (ML) model using Apache Spark and then take the trained model artifacts to create an endpoint in SageMaker for online inference. Apache Spark is one of the most popular big-data analytics platforms & it also comes with an ML library with a wide variety of feature transformers and algorithms that one can use to build an ML model. ' '' 'Apache Spark is designed for offline batch processing workload and is not best suited for low latency online prediction. In order to mitigate that we will use [MLeap](https://github.com/combust/mleap) library. MLeap provides an easy-to-use Spark ML Pipeline serialization format & execution engine for low latency prediction use-cases. Once the ML model is trained using Apache Spark in EMR we will serialize it with `MLeap` and upload to S3 as part of the Spark job so that it can be used in SageMaker in inference.' '' 'After the model training is completed we will use SageMaker **Inference** to perform predictions against this model. The underlying Docker image that we will use in inference is provided by [sagemaker-sparkml-serving](https://github.com/aws/sagemaker-sparkml-serving-container). It is a Spring based HTTP web server written following SageMaker container specifications and its operations are powered by `MLeap` execution engine. ' '' 'In the first segment of the notebook we will work with `Sparkmagic (PySpark)` kernel while performing operations on the EMR cluster and in the second segment we need to switch to `conda_python2` kernel to invoke SageMaker APIs using `sagemaker-python-sdk`.']\n",
      "['# TensorFlow Eager Execution with Amazon SageMaker Script Mode and Automatic Model Tuning' '' \"Starting with TensorFlow version 1.11 you can use SageMaker's prebuilt TensorFlow containers with TensorFlow training scripts similar to those you would use outside SageMaker. This feature is named Script Mode.\" '' \"In this notebook we will use Script Mode in conjunction with TensorFlow's Eager Execution mode which is the default execution mode of TensorFlow 2 onwards.  Eager execution is an imperative interface where operations are executed immediately rather than building a static computational graph. Advantages of Eager Execution include a more intuitive interface with natural Python control flow and less boilerplate easier debugging and support for dynamic models and almost all of the available TensorFlow operations. It also features close integration with tf.keras to make rapid prototyping even easier.  \" '' \"To demonstrate Script Mode this notebook focuses on presenting a relatively complete workflow. The workflow includes local training and hosted training in SageMaker as well as local inference and SageMaker hosted inference with a real time endpoint. Additionally Automatic Model Tuning in SageMaker will be used to tune the model's hyperparameters.  This workflow will be applied to a straightforward regression task predicting house prices based on the well-known Boston Housing dataset. More specifically this public dataset contains 13 features regarding housing stock of towns in the Boston area including features such as average number of rooms accessibility to radial highways adjacency to the Charles River etc.  \" '' \"To begin we'll import some necessary packages and set up directories for training and test data.  \"]\n",
      "['# Migrating scripts from Framework Mode to Script Mode' '' 'This notebook focus on how to migrate scripts using Framework Mode to Script Mode. The original notebook using Framework Mode can be find here https://github.com/awslabs/amazon-sagemaker-examples/blob/4c2a93114104e0b9555d7c10aaab018cac3d7c04/sagemaker-python-sdk/tensorflow_distributed_mnist/tensorflow_local_mode_mnist.ipynb']\n",
      "['# Horovod Distributed Training with SageMaker TensorFlow script mode.']\n",
      "['# Horovod Distributed Training with SageMaker TensorFlow script mode.']\n",
      "['# TensorFlow Script Mode with Pipe Mode Input' '' '' 'SageMaker Pipe Mode is an input mechanism for SageMaker training containers based on Linux named pipes. SageMaker makes the data available to the training container using named pipes which allows data to be downloaded from S3 to the container while training is running. For larger datasets this dramatically improves the time to start training as the data does not need to be first downloaded to the container. To learn more about pipe mode please consult the AWS documentation at: https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-training-algo.html#your-algorithms-training-algo-running-container-trainingdata.' '' \"In this tutorial we show you how to train a TensorFlow estimator using data read with SageMaker Pipe Mode. We use the SageMaker PipeModeDataset class - a special TensorFlow Dataset built specifically to read from SageMaker Pipe Mode data. This Dataset is available in our TensorFlow containers for TensorFlow versions 1.7.0 and up. It's also open-sourced at https://github.com/aws/sagemaker-tensorflow-extensions and can be built into custom TensorFlow images for use in SageMaker.\" '' \"Although you can also build the PipeModeDataset into your own containers in this tutorial we'll show how you can use the PipeModeDataset by launching training from the SageMaker Python SDK. The SageMaker Python SDK helps you deploy your models for training and hosting in optimized production-ready containers in SageMaker. The SageMaker Python SDK is easy to use modular extensible and compatible with TensorFlow and many other deep learning frameworks.\" '' 'Different collections of S3 files can be made available to the training container while it\\'s running. These are referred to as \"channels\" in SageMaker. In this example we use two channels - one for training data and one for evaluation data. Each channel is mapped to S3 files from different directories. The SageMaker PipeModeDataset knows how to read from the named pipes for each channel given just the channel name. When we launch SageMaker training we tell SageMaker what channels we have and where in S3 to read the data for each channel.' '' '' '## Setup' \"The following code snippet sets up some variables we'll need later on.\"]\n",
      "['# Using TensorFlow Scripts in SageMaker - Quickstart' '' \"Starting with TensorFlow version 1.11 you can use SageMaker's TensorFlow containers to train TensorFlow scripts the same way you would train outside SageMaker. This feature is named **Script Mode**. \" '' 'This example uses ' '[Multi-layer Recurrent Neural Networks (LSTM RNN) for character-level language models in Python using Tensorflow](https://github.com/sherjilozair/char-rnn-tensorflow). ' 'You can use the same technique for other scripts or repositories including ' '[TensorFlow Model Zoo](https://github.com/tensorflow/models) and ' '[TensorFlow benchmark scripts](https://github.com/tensorflow/benchmarks/tree/master/scripts/tf_cnn_benchmarks).']\n",
      "['# TensorFlow script mode training and serving' '' \"Script mode is a training script format for TensorFlow that lets you execute any TensorFlow training script in SageMaker with minimal modification. The [SageMaker Python SDK](https://github.com/aws/sagemaker-python-sdk) handles transferring your script to a SageMaker training instance. On the training instance SageMaker's native TensorFlow support sets up training-related environment variables and executes your training script. In this tutorial we use the SageMaker Python SDK to launch a training job and deploy the trained model.\" '' 'Script mode supports training with a Python script a Python module or a shell script. In this example we use a Python script to train a classification model on the [MNIST dataset](http://yann.lecun.com/exdb/mnist/). In this example we will show how easily you can train a SageMaker using TensorFlow 1.x and TensorFlow 2.0 scripts with SageMaker Python SDK. In addition this notebook demonstrates how to perform real time inference with the [SageMaker TensorFlow Serving container](https://github.com/aws/sagemaker-tensorflow-serving-container). The TensorFlow Serving container is the default inference method for script mode. For full documentation on the TensorFlow Serving container please visit [here](https://github.com/aws/sagemaker-python-sdk/blob/master/src/sagemaker/tensorflow/deploying_tensorflow_serving.rst).']\n",
      "['# TensorFlow script mode training and serving' '' \"Script mode is a training script format for TensorFlow that lets you execute any TensorFlow training script in SageMaker with minimal modification. The [SageMaker Python SDK](https://github.com/aws/sagemaker-python-sdk) handles transferring your script to a SageMaker training instance. On the training instance SageMaker's native TensorFlow support sets up training-related environment variables and executes your training script. In this tutorial we use the SageMaker Python SDK to launch a training job and deploy the trained model.\" '' 'Script mode supports training with a Python script a Python module or a shell script. In this example we use a Python script to train a classification model on the [MNIST dataset](http://yann.lecun.com/exdb/mnist/). In addition this notebook demonstrates how to perform real time inference with the [SageMaker TensorFlow Serving container](https://github.com/aws/sagemaker-tensorflow-serving-container). The TensorFlow Serving container is the default inference method for Script Mode. For full documentation on the TensorFlow Serving container please visit [here](https://github.com/aws/sagemaker-python-sdk/blob/master/src/sagemaker/tensorflow/deploying_tensorflow_serving.rst).']\n",
      "['# TensorFlow Script Mode - Using Shell scripts' '' 'Starting from TensorFlow version 1.11 you can use a shell script as' 'your training entry point. Shell scripts are useful for many use cases including:' '' '- Invoking Python scripts with specific parameters' '- Configuring framework dependencies' '- Training using different programming languages' '' 'For this example we use [a Keras implementation of the Deep Dream algorithm](https://github.com/keras-team/keras/blob/2.2.4/examples/deep_dream.py). We can use the same technique for other scripts or repositories including [TensorFlow Model Zoo](https://github.com/tensorflow/models) and [TensorFlow benchmark scripts](https://github.com/tensorflow/benchmarks/tree/master/scripts/tf_cnn_benchmarks).']\n",
      "['# Using the SageMaker TensorFlow Serving Container' '' 'The [SageMaker TensorFlow Serving Container](https://github.com/aws/sagemaker-tensorflow-serving-container) makes it easy to deploy trained TensorFlow models to a SageMaker Endpoint without the need for any custom model loading or inference code.' '' 'In this example we will show how deploy one or more pre-trained models from [TensorFlow Hub](https://www.tensorflow.org/hub/) to a SageMaker Endpoint using the [SageMaker Python SDK](https://github.com/aws/sagemaker-python-sdk) and then use the model(s) to perform inference requests.']\n",
      "['# Using Amazon Elastic Inference with a pre-trained TensorFlow Serving model on SageMaker' '' 'This notebook demonstrates how to enable and use Amazon Elastic Inference with our predefined SageMaker TensorFlow Serving containers.' '' 'Amazon Elastic Inference (EI) is a resource you can attach to your Amazon EC2 instances to accelerate your deep learning (DL) inference workloads. EI allows you to add inference acceleration to an Amazon SageMaker hosted endpoint or Jupyter notebook for a fraction of the cost of using a full GPU instance. For more information please visit: https://docs.aws.amazon.com/sagemaker/latest/dg/ei.html' '' \"This notebook's main objective is to show how to create an endpoint backed by an Elastic Inference to serve our pre-trained TensorFlow Serving model for predictions. With a more efficient cost per performance Amazon Elastic Inference can prove to be useful for those looking to use GPUs for higher inference performance at a lower cost.\" '' '1. [The model](#The-model)' '1. [Setup role for SageMaker](#Setup-role-for-SageMaker)' '1. [Load the TensorFlow Serving Model on Amazon SageMaker using Python SDK](#Load-the-TensorFlow-Serving-Model-on-Amazon-SageMaker-using-Python-SDK)' '1. [Deploy the trained Model to an Endpoint with EI](#Deploy-the-trained-Model-to-an-Endpoint-with-EI)' '    1. [Using EI with a SageMaker notebook instance](#Using-EI-with-a-SageMaker-notebook-instance)' '    1. [Invoke the Endpoint to get inferences](#Invoke-the-Endpoint-to-get-inferences)' '    1. [Delete the Endpoint](#Delete-the-Endpoint)' '' 'If you are familiar with SageMaker and already have a trained model skip ahead to the [Deploy the trained Model to an Endpoint with an attached EI accelerator](#Deploy-the-trained-Model-to-an-Endpoint-with-an-attached-EI-accelerator)' '' 'For this example we will use the SageMaker Python SDK which helps deploy your models to train and host in SageMaker. In this particular example we will be interested in only the hosting portion of the SDK.' '' '1. Set up our pre-trained model for consumption in SageMaker' '2. Host the model in an endpoint with EI' '3. Make a sample inference request to the model' \"4. Delete our endpoint after we're done using it\"]\n",
      "['# SageMaker PySpark Custom Estimator MNIST Example' '' '1. [Introduction](#Introduction)' '2. [Setup](#Setup)' '3. [Loading the Data](#Loading-the-Data)' '4. [Create a custom SageMakerEstimator](#Create-a-custom-SageMakerEstimator)' '5. [Inference](#Inference)' '6. [Clean-up](#Clean-up)' '7. [More on SageMaker Spark](#More-on-SageMaker-Spark)' '' '## Introduction' 'This notebook will show how to cluster handwritten digits through the SageMaker PySpark library. ' '' 'We will manipulate data through Spark using a SparkSession and then use the SageMaker Spark library to interact with SageMaker for training and inference. ' 'We will use a custom estimator to perform the classification task and train and infer using that custom estimator.' '' \"You can visit SageMaker Spark's GitHub repository at https://github.com/aws/sagemaker-spark to learn more about SageMaker Spark.\" '' 'This notebook was created and tested on an ml.m4.xlarge notebook instance.']\n",
      "['# SageMaker PySpark K-Means Clustering MNIST Example' '' '1. [Introduction](#Introduction)' '2. [Setup](#Setup)' '3. [Loading the Data](#Loading-the-Data)' '4. [Training with K-Means and Hosting a Model](#Training-with-K-Means-and-Hosting-a-Model)' '5. [Inference](#Inference)' '8. [Re-using existing endpoints or models to create a SageMakerModel](#Re-using-existing-endpoints-or-models-to-create-SageMakerModel)' '9. [Clean-up](#Clean-up)' '10. [More on SageMaker Spark](#More-on-SageMaker-Spark)' '' '## Introduction' 'This notebook will show how to cluster handwritten digits through the SageMaker PySpark library. ' '' 'We will manipulate data through Spark using a SparkSession and then use the SageMaker Spark library to interact with SageMaker for training and inference. ' 'We will first train on SageMaker using K-Means clustering on the MNIST dataset. Then we will see how to re-use models from existing endpoints and from a model stored on S3 in order to only run inference. ' '' \"You can visit SageMaker Spark's GitHub repository at https://github.com/aws/sagemaker-spark to learn more about SageMaker Spark.\" '' 'This notebook was created and tested on an ml.m4.xlarge notebook instance.']\n",
      "['# SageMaker PySpark PCA and K-Means Clustering MNIST Example' '' '1. [Introduction](#Introduction)' '2. [Setup](#Setup)' '3. [Loading the Data](#Loading-the-Data)' '4. [Create a  pipeline with  PCA and  K-Means on SageMaker](#Create-a--pipeline-with--PCA-and--K-Means-on-SageMaker)' '5. [Inference](#Inference)' '6. [Clean-up](#Clean-up)' '7. [More on SageMaker Spark](#More-on-SageMaker-Spark)' '' '## Introduction' 'This notebook will show how to cluster handwritten digits through the SageMaker PySpark library. ' '' 'We will manipulate data through Spark using a SparkSession and then use the SageMaker Spark library to interact with SageMaker for training and inference. ' \"We will create a pipeline consisting of a first step to reduce the dimensionality using SageMaker's PCA algorithm followed by the final K-Means clustering step on SageMaker. \" '' \"You can visit SageMaker Spark's GitHub repository at https://github.com/aws/sagemaker-spark to learn more about SageMaker Spark.\" '' 'This notebook was created and tested on an ml.m4.xlarge notebook instance.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['# SageMaker PySpark PCA on Spark and K-Means Clustering on SageMaker MNIST Example' '' '1. [Introduction](#Introduction)' '2. [Setup](#Setup)' '3. [Loading the Data](#Loading-the-Data)' '4. [Create a hybrid pipeline with Spark PCA and SageMaker K-Means](#Create-a-hybrid-pipeline-with-Spark-PCA-and-SageMaker-K-Means)' '5. [Inference](#Inference)' '6. [Clean-up](#Clean-up)' '7. [More on SageMaker Spark](#More-on-SageMaker-Spark)' '' '## Introduction' 'This notebook will show how to cluster handwritten digits through the SageMaker PySpark library. ' '' 'We will manipulate data through Spark using a SparkSession and then use the SageMaker Spark library to interact with SageMaker for training and inference. ' 'We will create a pipeline consisting of a first step to reduce the dimensionality using Spark MLLib PCA algorithm followed by the final K-Means clustering step on SageMaker. ' '' \"You can visit SageMaker Spark's GitHub repository at https://github.com/aws/sagemaker-spark to learn more about SageMaker Spark.\" '' 'This notebook was created and tested on an ml.m4.xlarge notebook instance.' '' '## Why use Spark MLLib algorithms? ' '' 'The use of Spark MLLib PCA in this notebook is meant to showcase how you can use different pre-processting steps ranging from data transformers to algorithms with tools such as Spark MLLib that are well suited for data pre-processing. You can then use SageMaker algorithms and features through the SageMaker-Spark SDK. Here in our case PCA is in charge of reducing the feature vector as a pre-processing step and K-Means responsible for clustering the data. ']\n",
      "['# SageMaker PySpark XGBoost MNIST Example' '' '1. [Introduction](#Introduction)' '2. [Setup](#Setup)' '3. [Loading the Data](#Loading-the-Data)' '4. [Training and Hosting a Model](#Training-and-Hosting-a-Model)' '5. [Inference](#Inference)' '6. [More on SageMaker Spark](#More-on-SageMaker-Spark)']\n",
      "['# Amazon SageMaker Batch Transform: Associate prediction results with their corresponding input records' \"_**Use SageMaker's XGBoost to train a binary classification model and for a list of tumors in batch file predict if each is malignant**_\" '' '_**It also shows how to use the input output joining / filter feature in Batch transform in details**_' '' '---' '' '' '' '## Background' \"This purpose of this notebook is to train a model using SageMaker's XGBoost and UCI's breast cancer diagnostic data set to illustrate at how to run batch inferences and how to use the Batch Transform I/O join feature. UCI's breast cancer diagnostic data set is available at https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29. The data set is also available on Kaggle at https://www.kaggle.com/uciml/breast-cancer-wisconsin-data. The purpose here is to use this data set to build a predictve model of whether a breast mass image indicates benign or malignant tumor. \" '' '' '' '---' '' '## Setup' '' \"Let's start by specifying:\" '' '* The SageMaker role arn used to give training and batch transform access to your data. The snippet below will use the same role used by your SageMaker notebook instance. Otherwise specify the full ARN of a role with the SageMakerFullAccess policy attached.' '* The S3 bucket that you want to use for training and storing model objects.']\n",
      "['# Amazon SageMaker Batch Transform: Associate prediction results with their corresponding input records' \"_**Use SageMaker's XGBoost to train a binary classification model and for a list of tumors in batch file predict if each is malignant**_\" '' '_**It also shows how to use the input output joining / filter feature in Batch transform in details**_' '' '---' '' '' '' '## Background' \"This purpose of this notebook is to train a model using SageMaker's XGBoost and UCI's breast cancer diagnostic data set to illustrate at how to run batch inferences and how to use the Batch Transform I/O join feature. UCI's breast cancer diagnostic data set is available at https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29. The data set is also available on Kaggle at https://www.kaggle.com/uciml/breast-cancer-wisconsin-data. The purpose here is to use this data set to build a predictve model of whether a breast mass image indicates benign or malignant tumor. \" '' '' '' '---' '' '## Setup' '' \"Let's start by specifying:\" '' '* The SageMaker role arn used to give training and batch transform access to your data. The snippet below will use the same role used by your SageMaker notebook instance. Otherwise specify the full ARN of a role with the SageMakerFullAccess policy attached.' '* The S3 bucket that you want to use for training and storing model objects.']\n",
      "['# Amazon SageMaker Batch Transform' '_**Generating Machine Learning Model Predictions from a Batch Transformer versus from a Real Time Endpoint**_' '' '---' '' '---' '' '' '## Contents' '' '1. [Background](#Background)' '1. [Setup](#Setup)' '1. [Data](#Data)' '1. [Dimensionality reduction](#Dimensionality-reduction)' '  1. [Train PCA](#Train-PCA)' '  1. [Batch prediction PCA](#Batch-prediction-PCA)' '  1. [Real-time prediction comparison](#Real-time-prediction-comparison)' '  1. [Batch prediction on new data](#Batch-prediction-on-new-data)' '1. [Clustering](#Clustering)' '  1. [Prepare BYO](#Prepare-BYO)' '  1. [Train DBSCAN](#Train-DBSCAN)' '  1. [Batch prediction DBSCAN](#Batch-prediction-DBSCAN)' '1. [Evaluate](#Evaluate)' '1. [Wrap-up](#Wrap-up)' '' '---' '' '## Background' '' \"This notebook provides an introduction to the Amazon SageMaker batch transform functionality.  Deploying a trained model to a hosted endpoint has been available in SageMaker since launch and is a great way to provide real-time predictions to a service like a website or mobile app.  But if the goal is to generate predictions from a trained model on a large dataset where minimizing latency isn't a concern then the batch transform functionality may be easier more scalable and more appropriate.  This can be especially useful for cases like:\" '' '- **One-off evaluations of model fit:** For example we may want to compare accuracy of our trained model on new validation data that we collected after our initial training job. ' '- **Using outputs from one model as the inputs to another:** For example we may want use a pre-processing step like word embeddings principal components clustering or TF-IDF before training a second model to generate predictions from that information.' '- **When predictions will ultimately be served outside of Amazon SageMaker:** For example we may have a large but finite set of predictions to generate which we then store in a fast-lookup datastore for serving.' '' 'Functionally batch transform uses the same mechanics as real-time hosting to generate predictions.  It requires a web server that takes in HTTP POST requests a single observation or mini-batch at a time.  However unlike real-time hosted endpoints which have persistent hardware (instances stay running until you shut them down) batch transform clusters are torn down when the job completes.' '' \"The example we'll walk through in this notebook starts with Amazon movie review [data](https://s3.amazonaws.com/amazon-reviews-pds/readme.html) performs on principal components on the large user-item review matrix and then uses DBSCAN to cluster movies in the reduced dimensional space.  This allows us to split the notebook into two parts as well as showcasing how to use batch with SageMaker built-in algorithms and the bring your own algorithm use case.\" '' 'If you are only interested in understanding how SageMaker batch transform compares to hosting a real-time endpoint you can stop running the notebook before the clustering portion of the notebook.' '' '---' '' '## Setup' '' '_This notebook was created and tested on an ml.m4.xlarge notebook instance._' '' \"Let's start by specifying:\" '' \"- The S3 bucket and prefix that you want to use for training and model data.  This should be within the same region as the Notebook Instance training and hosting.  We've specified the default SageMaker bucket but you can change this.\" '- The IAM role arn used to give training and hosting access to your data. See the AWS SageMaker documentation for information on how to setup an IAM role.  Note if more than one role is required for notebook instances training and/or hosting please replace `sagemaker.get_execution_role()` with the appropriate full IAM role arn string(s).']\n",
      "['#  Highly Performant TensorFlow Batch Inference and Training  ' '' \"For use cases involving large datasets particularly those where the data is images it often is necessary to perform distributed training on a cluster of multiple machines. Similarly when it is time to set up an inference workflow it also may be necessary to perform highly performant batch inference using a cluster.  In this notebook we'll examine how to do these tasks with TensorFlow in Amazon SageMaker with emphasis on batch inference. \" '' \"For training a model we'll use a basic Convolutional Neural Network (CNN) based on [the Keras examples](https://github.com/keras-team/keras/blob/master/examples/cifar10_cnn.py) but using the tf.Keras API rather than the separate reference implementation of Keras.  We'll train the CNN to classify images using the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html) a well-known computer vision dataset. It consists of 60000 32x32 images belonging to 10 different classes with 6000 images per class. Here is a graphic of the classes in the dataset as well as 10 random images from each:\" '' '![cifar10](https://maet3608.github.io/nuts-ml/_images/cifar10.png)']\n",
      "['#  Highly Performant TensorFlow Batch Inference on Image Data Using the SageMaker CLI' '' \"In this notebook we'll show how to use SageMaker batch transform to get inferences on a large datasets. To do this we'll use a TensorFlow Serving model to do batch inference on a large dataset of images. We'll show how to use the new pre-processing and post-processing feature of the TensorFlow Serving container on Amazon SageMaker so that your TensorFlow model can make inferences directly on data in S3 and save post-processed inferences to S3.\" '' 'The dataset we\\'ll be using is the [“Challenge 2018/2019\"](https://github.com/cvdfoundation/open-images-dataset#download-the-open-images-challenge-28182019-test-set)” subset of the [Open Images V5 Dataset](https://storage.googleapis.com/openimages/web/index.html). This subset consists of 10000 images in .jpg format for a total of 10GB. For demonstration the [model](https://github.com/tensorflow/models/tree/master/official/resnet#pre-trained-model) we\\'ll be using is an image classification model based on the ResNet-50 architecture that has been trained on the ImageNet dataset and which has been exported as a TensorFlow SavedModel.' '' \"We will use this model to predict the class that each model belongs to. We'll write a pre- and post-processing script and package the script with our TensorFlow SavedModel and demonstrate how to get inferences on large datasets with SageMaker batch transform quickly efficiently and at scale on GPU-accelerated instances.\"]\n",
      "['#  Highly Performant TensorFlow Batch Inference on Image Data Using the SageMaker Python SDK ' '' \"In this notebook we'll show how to use SageMaker batch transform to get inferences on a large datasets. To do this we'll use a TensorFlow Serving model to do batch inference on a large dataset of images. We'll show how to use the new pre-processing and post-processing feature of the TensorFlow Serving container on Amazon SageMaker so that your TensorFlow model can make inferences directly on data in S3 and save post-processed inferences to S3.\" '' 'The dataset we\\'ll be using is the [“Challenge 2018/2019\"](https://github.com/cvdfoundation/open-images-dataset#download-the-open-images-challenge-28182019-test-set)” subset of the [Open Images V5 Dataset](https://storage.googleapis.com/openimages/web/index.html). This subset consists of 10000 images in .jpg format for a total of 10GB. For demonstration the [model](https://github.com/tensorflow/models/tree/master/official/resnet#pre-trained-model) we\\'ll be using is an image classification model based on the ResNet-50 architecture that has been trained on the ImageNet dataset and which has been exported as a TensorFlow SavedModel.' '' \"We will use this model to predict the class that each model belongs to. We'll write a pre- and post-processing script and package the script with our TensorFlow SavedModel and demonstrate how to get inferences on large datasets with SageMaker batch transform quickly efficiently and at scale on GPU-accelerated instances.\"]\n",
      "['#  Highly Performant TensorFlow Batch Inference on TFRecord Data Using the SageMaker Python SDK ' '' \"In this notebook we'll show how to use SageMaker batch transform to get inferences on a large datasets. To do this we'll use a TensorFlow Serving model to do batch inference on a large dataset of images encoded in TFRecord format using the SageMaker Python SDK. We'll show how to use the new pre-processing and post-processing feature of the TensorFlow Serving container on Amazon SageMaker so that your TensorFlow model can make inferences directly on data in S3 and save post-processed inferences to S3.\" '' 'The dataset we\\'ll be using is the [“Challenge 2018/2019\"](https://github.com/cvdfoundation/open-images-dataset#download-the-open-images-challenge-28182019-test-set)” subset of the [Open Images V5 Dataset](https://storage.googleapis.com/openimages/web/index.html). This subset consists of 10000 images in .jpg format for a total of 10GB. For demonstration the [model](https://github.com/tensorflow/models/tree/master/official/resnet#pre-trained-model) we\\'ll be using is an image classification model based on the ResNet-50 architecture that has been trained on the ImageNet dataset and which has been exported as a TensorFlow SavedModel.' '' \"We will use this model to predict the class that each model belongs to. We'll write a pre- and post-processing script and package the script with our TensorFlow SavedModel and demonstrate how to get inferences on large datasets with SageMaker batch transform quickly efficiently and at scale on GPU-accelerated instances.\"]\n",
      "['#  Highly Performant TensorFlow Batch Inference on TFRecord Data Using the SageMaker CLI' '' \"In this notebook we'll show how to use SageMaker batch transform to get inferences on a large datasets. To do this we'll use a TensorFlow Serving model to do batch inference on a large dataset of images encoded in TFRecord format using the AWS command-line interface. We'll show how to use the new pre-processing and post-processing feature of the TensorFlow Serving container on Amazon SageMaker so that your TensorFlow model can make inferences directly on data in S3 and save post-processed inferences to S3.\" '' 'The dataset we\\'ll be using is the [“Challenge 2018/2019\"](https://github.com/cvdfoundation/open-images-dataset#download-the-open-images-challenge-28182019-test-set)” subset of the [Open Images V5 Dataset](https://storage.googleapis.com/openimages/web/index.html). This subset consists of 10000 images in .jpg format for a total of 10GB. For demonstration the [model](https://github.com/tensorflow/models/tree/master/official/resnet#pre-trained-model) we\\'ll be using is an image classification model based on the ResNet-50 architecture that has been trained on the ImageNet dataset and which has been exported as a TensorFlow SavedModel.' '' \"We will use this model to predict the class that each model belongs to. We'll write a pre- and post-processing script and package the script with our TensorFlow SavedModel and demonstrate how to get inferences on large datasets with SageMaker batch transform quickly efficiently and at scale on GPU-accelerated instances.\"]\n",
      "['# Working with TFRecord Datasets' '' '1. [Introduction](#Introduction)' '1. [Prerequisites](#Prerequisites)' '1. [Converting a dataset from CSV to TFrecords](#Converting-a-dataset-from-CSV-to-TFrecords)' ' 1. [Upload dataset to S3](#Upload-dataset-to-S3)' '1. [Construct a DNNClassifier](#Construct-a-DNNClassifier)' '1. [Train a Model](#Train-a-Model)' '1. [Run Batch Transform](#Run-Batch-Transform)' ' 1. [Build a container for transforming TFRecord input](#Build-a-container-for-transforming-TFRecord-input)' ' 1. [Push container to ECR](#Push-container-to-ECR)' ' 1. [Create a model with an inference pipeline](#Create-a-model-with-an-inference-pipeline)' ' 1. [Run a batch transform job](#Run-a-batch-transform-job)' ' 1. [Inspect batch transform output](#Inspect-batch-transform-output)']\n",
      "['# Enable Amazon SageMaker Model Monitor' '' 'Amazon SageMaker provides the ability to monitor machine learning models in production and detect deviations in data quality in comparison to a baseline dataset (e.g. training data set). This notebook walks you through enabling data capture and setting up continous monitoring for an existing Endpoint.' '' 'This Notebook helps with the following:' '* Update your existing SageMaker Endpoint to enable Model Monitoring' '* Analyze the training dataset to generate a baseline constraint' '* Setup a MonitoringSchedule for monitoring deviations from the specified baseline' '' '---']\n",
      "['# Amazon SageMaker Model Monitor' 'This notebook shows how to:' '* Host a machine learning model in Amazon SageMaker and capture inference requests results and metadata ' '* Analyze a training dataset to generate baseline constraints' '* Monitor a live endpoint for violations against constraints' '' '---' '## Background' '' 'Amazon SageMaker provides every developer and data scientist with the ability to build train and deploy machine learning models quickly. Amazon SageMaker is a fully-managed service that encompasses the entire machine learning workflow. You can label and prepare your data choose an algorithm train a model and then tune and optimize it for deployment. You can deploy your models to production with Amazon SageMaker to make predictions and lower costs than was previously possible.' '' 'In addition Amazon SageMaker enables you to capture the input output and metadata for invocations of the models that you deploy. It also enables you to analyze the data and monitor its quality. In this notebook you learn how Amazon SageMaker enables these capabilities.' '' '---' '## Setup' '' 'To get started make sure you have these prerequisites completed.' '' '* Specify an AWS Region to host your model.' '* An IAM role ARN exists that is used to give Amazon SageMaker access to your data in Amazon Simple Storage Service (Amazon S3). See the documentation for how to fine tune the permissions needed. ' '* Create an S3 bucket used to store the data used to train your model any additional model data and the data captured from model invocations. For demonstration purposes you are using the same bucket for these. In reality you might want to separate them with different security policies.']\n",
      "['# SageMaker Model Monitor - visualizing monitoring results' '' '' 'The prebuilt container from SageMaker computes a variety of statistics and evaluates constraints out of the box. This notebook demonstrates how you can visualize them. You can grab the ProcessingJob arn from the executions behind a MonitoringSchedule and use this notebook to visualize the results.' '' \"Let's import some python libraries that will be helpful for visualization\"]\n",
      "['# Compile and Deploy a TensorFlow model on Inf1 instances' '' '' 'Amazon SageMaker now supports Inf1 instances for high performance and cost-effective inferences. Inf1 instances are ideal for large scale machine learning inference applications like image recognition speech recognition natural language processing personalization and fraud detection. In this example we train a classification model on the MNIST dataset using TensorFlow compile it using Amazon SageMaker Neo and deploy the model on Inf1 instances on a SageMaker endpoint and use the Neo Deep Learning Runtime to make inferences in real-time and with low latency. ' '' '### Inf 1 instances ' 'Inf1 instances are built from the ground up to support machine learning inference applications and feature up to 16 AWS Inferentia chips high-performance machine learning inference chips designed and built by AWS. The Inferentia chips are coupled with the latest custom 2nd generation Intel® Xeon® Scalable processors and up to 100 Gbps networking to enable high throughput inference. With 1 to 16 AWS Inferentia chips per instance Inf1 instances can scale in performance to up to 2000 Tera Operations per Second (TOPS) and deliver extremely low latency for real-time inference applications. The large on-chip memory on AWS Inferentia chips used in Inf1 instances allows caching of machine learning models directly on the chip. This eliminates the need to access outside memory resources during inference enabling low latency without impacting bandwidth. ']\n",
      "['# GluonCV SSD Mobilenet training and optimizing using Neo' '' '1. [Introduction](#Introduction)' '2. [Setup](#Setup)' '3. [Data Preparation](#Data-Preparation)' '  1. [Download data](#Download-Data)' '  2. [Convert data into RecordIO](#Convert-data-into-RecordIO)' '  3. [Upload to S3](#Upload-to-S3)' '4. [Training](#Training)' '5. [Hosting](#Hosting)' '6. [Deploy the trained model using Neo](#Deploy-the-trained-model-using-Neo)' '  1. [Inference](#Inference)']\n",
      "['# Model Optimization with an Image Classification Example' '1. [Introduction](#Introduction)' '2. [Prerequisites and Preprocessing](#Prequisites-and-Preprocessing)' '3. [Training the model](#Training-the-model)' '4. [Inference with the vanilla model](#Inference-with-the-vanilla-model)' '5. [Inference with optimized model](#Inference-with-the-optimized-model)']\n",
      "['## MNIST Training Compilation and Deployment with MXNet Module and Sagemaker Neo' '' 'The **SageMaker Python SDK** makes it easy to train and deploy MXNet models. In this example we train a simple neural network using the Apache MXNet [Module API](https://mxnet.apache.org/api/python/module/module.html) and the MNIST dataset. The MNIST dataset is widely used for handwritten digit classification and consists of 70000 labeled 28x28 pixel grayscale images of hand-written digits. The dataset is split into 60000 training images and 10000 test images. There are 10 classes (one for each of the 10 digits). The task at hand is to train a model using the 60000 training images and subsequently test its classification accuracy on the 10000 test images. ' '' '### Setup' '' 'First we need to define a few variables that will be needed later in the example.']\n",
      "['# Deploying pre-trained PyTorch vision models with Amazon SageMaker Neo']\n",
      "['# TensorFlow BYOM: Train with Custom Training Script Compile with Neo and Deploy on SageMaker' '' 'This notebook can be compared to [TensorFlow MNIST distributed training notebook](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/sagemaker-python-sdk/tensorflow_distributed_mnist/tensorflow_distributed_mnist.ipynb) in terms of its functionality. We will do the same classification task but this time we will compile the trained model using the Neo API backend to optimize for our choice of hardware. Finally we setup a real-time hosted endpoint in SageMaker for our compiled model using the Neo Deep Learning Runtime.']\n",
      "['# Customer Churn Prediction with XGBoost' '_**Using Gradient Boosted Trees to Predict Mobile Customer Departure**_' '' '---' '' '---' '' '## Contents' '' '1. [Background](#Background)' '1. [Setup](#Setup)' '1. [Data](#Data)' '1. [Train](#Train)' '1. [Host](#Host)' '  1. [Evaluate](#Evaluate)' '  1. [Relative cost of errors](#Relative-cost-of-errors)' '1. [Extensions](#Extensions)' '' '---' '' '## Background' '' '_This notebook has been adapted from an [AWS blog post](https://aws.amazon.com/blogs/ai/predicting-customer-churn-with-amazon-machine-learning/)_' '' 'Losing customers is costly for any business.  Identifying unhappy customers early on gives you a chance to offer them incentives to stay.  This notebook describes using machine learning (ML) for the automated identification of unhappy customers also known as customer churn prediction. ML models rarely give perfect predictions though so this notebook is also about how to incorporate the relative costs of prediction mistakes when determining the financial outcome of using ML.' '' 'We use an example of churn that is familiar to all of us–leaving a mobile phone operator.  Seems like I can always find fault with my provider du jour! And if my provider knows that I’m thinking of leaving it can offer timely incentives–I can always use a phone upgrade or perhaps have a new feature activated–and I might just stick around. Incentives are often much more cost effective than losing and reacquiring a customer.' '' '---' '' '## Setup' '' '_This notebook was created and tested on an ml.m4.xlarge notebook instance._' '' \"Let's start by specifying:\" '' '- The S3 bucket and prefix that you want to use for training and model data.  This should be within the same region as the Notebook Instance training and hosting.' '- The IAM role arn used to give training and hosting access to your data. See the documentation for how to create these.  Note if more than one role is required for notebook instances training and/or hosting please replace the boto regexp with a the appropriate full IAM role arn string(s).']\n",
      "['# Feature transformation with Amazon SageMaker Processing and SparkML' '' 'Typically a machine learning (ML) process consists of few steps. First gathering data with various ETL jobs then pre-processing the data featurizing the dataset by incorporating standard techniques or prior knowledge and finally training an ML model using an algorithm.' '' \"Often distributed data processing frameworks such as Spark are used to pre-process data sets in order to prepare them for training. In this notebook we'll use Amazon SageMaker Processing and leverage the power of Spark in a managed SageMaker environment to run our preprocessing workload. Then we'll take our preprocessed dataset and train a regression model using XGBoost.\"]\n",
      "['## Amazon SageMaker Processing jobs' '' 'With Amazon SageMaker Processing jobs you can leverage a simplified managed experience to run data pre- or post-processing and model evaluation workloads on the Amazon SageMaker platform.' '' 'A processing job downloads input from Amazon Simple Storage Service (Amazon S3) then uploads outputs to Amazon S3 during or after the processing job.' '' '<img src=\"Processing-1.jpg\">' '' 'This notebook shows how you can:' '' '1. Run a processing job to run a scikit-learn script that cleans pre-processes performs feature engineering and splits the input data into train and test sets.' '2. Run a training job on the pre-processed training data to train a model' \"3. Run a processing job on the pre-processed test data to evaluate the trained model's performance\" '4. Use your own custom container to run processing jobs with your own Python libraries and dependencies.' '' 'The dataset used here is the [Census-Income KDD Dataset](https://archive.ics.uci.edu/ml/datasets/Census-Income+%28KDD%29). You select features from this dataset clean the data and turn the data into features that the training algorithm can use to train a binary classification model and split the data into train and test sets. The task is to predict whether rows representing census responders have an income greater than `$50000` or less than `$50000`. The dataset is heavily class imbalanced with most records being labeled as earning less than `$50000`. After training a logistic regression model you evaluate the model against a hold-out test dataset and save the classification evaluation metrics including precision recall and F1 score for each label and accuracy and ROC AUC for the model.']\n",
      "['# A Scientific Deep Dive Into SageMaker LDA' '' '1. [Introduction](#Introduction)' '1. [Setup](#Setup)' '1. [Data Exploration](#DataExploration)' '1. [Training](#Training)' '1. [Inference](#Inference)' '1. [Epilogue](#Epilogue)']\n",
      "['# Train faster more flexible models with Amazon SageMaker Linear Learner']\n",
      "['# Build multiclass classifiers with Amazon SageMaker linear learner']\n",
      "['# Amazon SageMaker Neural Topic Model now supports auxiliary vocabulary channel new topic evaluation metrics and training subsampling']\n",
      "['# Streaming Algorithms in Machine Learning' '' 'In this notebook we will use an extremely simple \"machine learning\" task to learn about streaming algorithms. We will try to find the median of some numbers in batch mode random order streams and arbitrary order streams.' 'The idea is to observe first hand the advantages of the streaming model as well as to appreciate some of the complexities involved in using it.' '' 'The task at hand will be to approximate the median (model) of a long sequence of numbers (the data). This might seem to have little to do with machine learning. We are used to thinking of a median $m$ of number $x_1\\\\ldotsx_n$ in the context of statistics as the number $m$ which is smaller than at most half the values $x_i$ and larger than at most half the values $x_i$.' '' 'Finding the median however also solves a proper machine learning optimization problem (albeit a simple one). The median minimizes the following clustering-like objective function' '$$m = \\\\min_x \\\\frac1n\\\\sum_i|x - x_i|.$$' 'In fact the median is the solution to the well studied k-median clustering problem in one dimension and $k=1$. Moreover the extension to finding all quantiles is common in feature transformations and an important ingedient in speeding up decission tree training.']\n",
      "['# Automate Model Retraining & Deployment Using the AWS Step Functions Data Science SDK' '' '1. [Introduction](#Introduction)' '1. [Setup](#Setup)' '1. [Create Resources](#Create-Resources)' '1. [Build a Machine Learning Workflow](#Build-a-Machine-Learning-Workflow)' '1. [Run the Workflow](#Run-the-Workflow)' '1. [Clean Up](#Clean-Up)']\n",
      "['# AWS Step Functions Data Science SDK - Hello World' '1. [Introduction](#Introduction)' '1. [Setup](#Setup)' '1. [Create steps for your workflow](#Create-steps-for-your-workflow)' '1. [Define the workflow instance](#Define-the-workflow-instance)' '1. [Review the Amazon States Language code for your workflow](#Review-the-Amazon-States-Language-code-for-your-workflow)' '1. [Create the workflow on AWS Step Functions](#Create-the-workflow-on-AWS-Step-Functions)' '1. [Execute the workflow](#Execute-the-workflow)' '1. [Review the execution progress](#Review-the-execution-progress)' '1. [Review the execution history](#Review-the-execution-history)']\n",
      "['# Build a machine learning workflow using Step Functions and SageMaker' '' '1. [Introduction](#Introduction)' '1. [Setup](#Setup)' '1. [Build a machine learning workflow](#Build-a-machine-learning-workflow)']\n",
      "['# MNIST Training using PyTorch and Step Functions']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-120-81a3e41584b8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mget_refs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnotebooks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mget_description\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnotebooks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mnb_csv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwrite_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnotebooks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-119-750a64609ebf>\u001b[0m in \u001b[0;36mwrite_csv\u001b[1;34m(notebooks)\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mnb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnotebooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnb_csv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~Users\\eslesar\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~Users\\eslesar\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~Users\\eslesar\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~Users\\eslesar\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1014\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1015\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~Users\\eslesar\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1708\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: I/O operation on closed file."
     ]
    }
   ],
   "source": [
    "notebooks = get_urls()\n",
    "get_refs(notebooks)\n",
    "get_description(notebooks)\n",
    "write_csv(notebooks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
